\documentclass[a4paper]{article}

\def\npart{IB}

\def\ntitle{Geometry}
\def\nlecturer{A.\ G.\ Kovalev}

\def\nterm{Lent}
\def\nyear{2018}

\input{header}

\DeclareMathOperator{\Isom}{Isom}
\DeclareMathOperator{\mesh}{mesh}

\makeindex

\begin{document}

\input{titlepage}

\tableofcontents

\section{Eucldiean Geometry}

Let \((\cdot, \cdot)\) be the standard inner product, a.k.a.\ dot product on the Euclidean space \(\R^n\) where for \(x, y \in \R^n\),
\[
  (x, y) = x \cdot y = \sum_{i = 1}^{n}x_iy_i.
\]
This induces the Euclidean norm
\[
  \norm x = \sqrt{(x, x)}.
\]
Also define the Euclidean distance function
\[
  d(x, y) = \norm{x - y}
\]
which makes \(\R^n\) a metric space.

\begin{definition}[Isometry]\index{isometry}
  A map \(f: \R^n \to \R^n\) is an \emph{isometry} of \(\R^n\) if
  \[
    \forall P, Q \in \R^n,\, d(f(P), f(Q)) = d(P, Q).
  \]
\end{definition}

Recall that an \(n \times n\) matrix \(A\) is \emph{orthogonal} if
\[
  A^TA = AA^T = I.
\]
For any square matrix \(A\) we have
\[
  (Ax, Ay) = (Ax)^T(Ay) = x^TA^TAy = (x, A^TAy)
\]
so we find that \(A\) is orthogonal if and only if \((Ax, Ay) = (x, y)\) for all \(x, y \in \R^n\).

Another point of view:
\[
  (x, y) = \frac{1}{2}(\norm{x + y}^2 -  \norm x^2 - \norm y^2)
\]
so \(A\) is orthogonal if and only if \(\norm{Ax} = \norm x\) for all \(x \in \R^n\).

An example of isometry: let \(f(x) = Ax + b\) where \(b \in \R^n\), then
\[
  d(f(x), f(y)) = \norm{A(x - y)}.
\]
So \(f\) is an isometry if and only if \(A\) is orthogonal.

Surprisingly, it turns out all isometries have this form:

\begin{theorem}
  Every isometry \(f: \R^n \to \R^n\) is of the form \(f(x) = Ax + b\) for some orthogonal matrix \(A\) and some vector \(b \in \R^n\).
\end{theorem}

\begin{proof}
  Let \(e_1, \dots, e_n \in \R^n\) be the standard basis of \(\R^n\). Let \(b = f(0)\), \(a_i = f(e_i) - b\) for \(i = 1, \dots, n\). We want to show that \(a_i\)'s form an orthonormal basis. Firstly
  \[
    \norm{a_i} = \norm{f(e_i) - f(0)} = d(f(e_i), f(0)) = d(e_i, 0) = \norm{e_i} = 1
  \]
  so they have unit length. For \(i \neq j\),
  \begin{align*}
    (a_i, a_j) &= -\frac{1}{2}(\norm{a_i - a_j}^2 - \norm{a_i}^2 - \norm{a_j}^2) \\
               &= -\frac{1}{2}(\norm{f(e_i) - f(e_j)}^2 - 2 \\
               &= -\frac{1}{2}(\norm{e_i - e_j}^2 - 2) \\
               &= 0
  \end{align*}
  Thus \(a_i\)'s form an orthonormal basis of \(\R^n\) and it follows that the matrix \(A\) with columns \(a_i, \dots, a_n\) is orthogonal.

  Let \(g(x) = Ax + b\) which is an isometry. We have \(g(x) = f(x)\) for \(x = 0, e_1, \dots, e_n\). In addition,
  \[
    g^{-1}(x) = A^{-1}(x - b) = A^T(x - b)
  \]
  is an isometry so the composition \(h = g^{-1} \compose f\) is an isometry fixing \(0, e_1, \dots, e_n\). It then suffices to show \(h = \id\). Consider \(x = \sum_{i = 1}^n x_ie_i \in \R^n\). Let \(y = h(x) = \sum_{i = 1}^n y_ie_i\). Then
\begin{align*}
  d(x, e_i)^2 &= \norm x^2 + 1 - 2x_i \\
  d(x, 0)^2 &= \norm x^2 \\
  d(y, e_i)^2 &= \norm y^2 + 1 - 2y_i \\
  d(y, 0)^2 &= \norm y^2
\end{align*}
Since \(h\) is an isometry, \(h(0) = 0\), \(h(e_i) = e_i\) and \(h(x) = y\), we have \(\norm x = \norm y\) so \(x_i = y_i\) for all \(i\). Thus \(h(x) = x\) for all \(x \in \R^n\).
\end{proof}

\begin{remark}
  \[
    \Isom(\R^n) = \{\text{all isometries of } \R^n\}
  \]
  is a group by composition. This is also known as the group of rigid motions of \(\R^n\).
\end{remark}

\begin{eg}[Reflections in an affine hyperplane \(H \subset \R^n\)]
  Let
  \[
    H = \{x \in \R^n: u \cdot x = c\}
  \]
  where \(\norm u = 1\) and \(c \in \R\). Observe that \(u\) is perpendicular to \(H\) and so is a normal vector. The reflection in \(H\) is defined to be
  \[
    R_H: x \mapsto x - 2(x \cdot u - c)u.
  \]
  It is an exercise in example sheet to show that this is an isometry. Observe that if \(x \in H\) then \(R_H(x) = x\). If \(a \in H, t \in \R\) then
  \[
    R_H(a + tu) = (a + tu) - 2tu = a - tu.
  \]
  Thus \(R_h\) fixes exactly the points in \(H\).

  Conversely, suppose \(S \in \Isom(\R^n)\) and \(S\) fixes every point in \(H\). Let \(a \in H\) and defind translation by \(a\) as
  \[
    T_a(x) = x + a
  \]
  which is clearly an isometry. Conjugate \(S\) by \(T_a\), we get
  \[
    R = T_{-a}ST_a \in \Isom(\R^n)
  \]
  and \(R\) fixes \(H' = T_{-a}(H)\). We choose to work with \(H'\) since \(0 \in H'\), making it a subspace of \(\R^n\). Explicitly, if \(H = \{x: x\cdot u = c\}\) then \(H' = \{x: x \cdot u = 0\}\). Then for all \(x \in H'\),
  \[
    (Ru, x) = (Ru, Rx) = (u, x) = 0.
  \]
  Thus \(Ru\) is orthogonal to \(H'\), i.e.\ lies in the orthogonal complement of \(H'\) in \(\R^n\). Thus \(Ru = \lambda u\) for some \(\lambda \in R\) such that \(\lambda^2 = 1\). So \(\lambda = \pm 1\).

  Since \(R\) fixes \(0 \in \R^n\), \(R\) is linear by the previous theorem and either \(R = \id\) or \(R\) is given by the matrix
  \[
    \begin{pmatrix}
      -1 & & \\
      & 1 & \\
      & & \ddots \\
      & & & 1
    \end{pmatrix}
  \]
  i.e.\ \(R_{H'}\). If \(R = \id\) then \(S = \id\). If \(R = R_{H'}\) then \(S = T_aR_{H'}T_{-a}\). Check that
  \[
    S: x \mapsto x - a \mapsto (x - a) - 2(x \cdot u - a \cdot u) u \mapsto x - 2(x \cdot u - c)u
  \]
  is a reflection. Thus if \(S \in \Isom(\R^n)\) fixing \(H\) and \(S \neq \id \) then \(R\) is the reflection in \(H\).
\end{eg}

\begin{remark}
  One can show that every isometry of \(\R^n\) is a composition of at most \(n + 1\) reflections (see example sheet 1).
\end{remark}

From the previous theorem, the subgroup
\[
  \{f \in \Isom(\R^n): f(0) = 0\} = \{f(x) = Ax: AA^T = I\}
\]
is naturally isomorphic to \(O(n)\), the \emph{orthogonal group}\index{orthogonal group}.

As for every \(A \in O(n)\), \((\det A)^2 = 1\), we must have \(\det A = \pm 1\). We call \(\{A \in O(n): \det A = 1\}\) the \emph{special orthgonal group}\index{orthogonal group!special}, denoted \(SO(n)\).

\begin{eg}[\(O(2)\)]
  \[
    A =
    \begin{pmatrix}
      a & c \\
      b & d
    \end{pmatrix}
    \in O(2) \Leftrightarrow a^2 + c^2 = 1, b^2 + d^2 = 1, ab + cd = 0
  \]
  Set \(a = \cos \theta, c = \sin \theta\) and \(b = - \sin \varphi, d = \cos \varphi\) for some \(0 \leq \theta, \varphi \leq 2\pi\). Then we deduce
  \[
    \tan \theta = \tan \varphi \in \R \cup \{\infty\}
  \]
  so
  \[
    \theta = \varphi \text{ or } \theta = \varphi \pm \pi.
  \]
  The first case corresponds to
  \[
    A =
    \begin{pmatrix}
      \cos \theta & -\sin \theta \\
      \sin \theta & \cos \theta
    \end{pmatrix}
  \]
  which is the rotation through \(\theta\) about \(0\). As \(\det A = 1\), \(A \in SO(2)\). The second case gives
  \[
    A =
    \begin{pmatrix}
      \cos \theta & \sin \theta \\
      \sin \theta & - \cos \theta
    \end{pmatrix}
  \]
  which we claim is a relfection: it fixes the line \(\ell\) which passes through the origin and forms an angle \(\theta/2\) with the positive \(x\)-axis. \(\det A = -1\) so \(A \notin SO(2)\).
\end{eg}

\begin{remark}[Orientation]\index{orientation}
  For a finite-dimensional vector space, its \emph{orientation} is an equivalence class of bases --- let \(v_1, \dots, v_n\) and \(v_1', \dots, v_n'\) be two bases, and \(A = (A_{ij})\) be the respective change-of-basis from \(\{v_i\}\) to \(\{v_i'\}\). These bases are equivalent, i.e.\ give the \emph{same orientation}, if \(\det A > 0\).
\end{remark}

\begin{definition}
  An isometry \(f(x) = Ax + b\) is said to be \emph{orientation-preserving} if \(\det A = 1\), and \emph{orientation-reversing} if \(\det A = -1\).
\end{definition}

\begin{eg}{\(O(3)\)}
Let's study \(O(3)\) in detail. Consider first the case \(\det A = 1\), then
\[
  \det(A - I) = \det(A^T -I) = \det(A(A^T - I)) = \det(I - A).
\]
Since \(A\) is a \(3 \times 3\) matrix, we must have \(\det (A - I) = 0\) so \(+1\) is an eigenvalue. Thus there exists \(v_1 \in \R^3, \norm{v_1} = 1\) such that \(Av_1 = v_1\). Set \(W = \generation{v_1}^\perp\), a plane. Then for \(w \in W\),
\[
  (Aw, v_1) = (Aw, Av_1) = (w, v_1) = 0
\]
so \(A\) is \(W\)-stable. Thus \(A|_W\) is a \emph{rotation} of the \(2\) dimensional space \(W\). Choose \(v_2, v_3\) to be an orthonormal basis of \(W\), then \(A\) has matrix representation with respect to \(v_1, v_2, v_3\)
\[
  \begin{pmatrix}
    1 & 0 & 0 \\
    0 & \cos \theta & -\sin \theta \\
    0 & \sin \theta & \cos \theta
  \end{pmatrix}
\]

Now suppose \(\det A = -1\). Then \(-A\) in some basis is of the above matrix form. Thus \(A\) is of the form
\[
  \begin{pmatrix}
    -1 & 0 & 0 \\
    0 & \cos \varphi & -\sin \varphi \\
    0 & \sin \varphi & \cos \varphi
  \end{pmatrix}
\]
where \(\varphi = \theta + \pi\). This is a \emph{rotated reflection} (in particular a pure reflection when \(\varphi = 0\)).
\end{eg}

\section{Curves in \texorpdfstring{\(\R^n\)}{‚Ñù\^{}n}}

\begin{definition}[Curve]\index{curve}
  A \emph{curve} \(T\) in \(\R^n\) is a continuous map \(\Gamma: [a, b] \to \R^n\).
\end{definition}

A \emph{dissection} \(\mathcal D\) is a sequence
\[
  a = t_0 < t_1 < \dots, t_N = b \in [a, b].
\]
Set \(P_i = T(t_i)\) and let
\[
  s_{\mathcal D} = \sum_i \norm{P_iP_{i + 1}}.
\]

\begin{definition}[Length]\index{length}
  The \emph{length} of a curve \(\Gamma\) is
  \[
    \ell = \sup_{\mathcal D} s_{\mathcal D}
  \]
  if this supremum exists (i.e.\ finite).
\end{definition}

If \(\mathcal D'\) is a refinement of \(\mathcal D\) (has extra points added), then \(s_{\mathcal D} \leq s_{\mathcal D'}\) by triangle inequality. Let
\[
  \mesh \mathcal D = \max_i(t_i - t_{i - 1}).
\]
Then if \(\ell\) exists, we have
\[
  \ell = \lim_{\mesh \mathcal D \to 0} s_{\mathcal D}.
\]

\begin{note}
  In fact we have
  \[
    \ell = \min\{\tilde \ell: \tilde \ell \geq s_{\mathcal D} \text{ for all } \mathcal D\}.
  \]
\end{note}

\begin{proposition}
  If \(\Gamma\)  is continuously differentiable, then
  \[
    \ell(\Gamma) = \int_a^b \norm{\Gamma'(t)} dt.
  \]
\end{proposition}

\begin{proof}
  Assume \(n = 3\) to avoid excessive notation. Let
  \[
    \Gamma(t) = (f_1(t), f_2(t), f_3(t)).
  \]
  If \(s \neq t \in [a, b]\), applying Mean Value Theorem to each \(f_i\) gives us
  \[
    \frac{f_i(t) - f_i(s)}{t - s} = f'_i(\xi_i)
  \]
  for some \(s < \xi_i < t\). \(f_i'\) are uniformly continuous on \([a, b]\) so for all \(\varepsilon > 0\) there exists \(\delta > 0\) such that
  \[
    |t - s| < \delta \implies |f_i'(\xi_i) - f_i'(\xi)| < \frac{\varepsilon}{3} \, \forall \xi \in (s, t).
  \]
  So for all \(\xi \in (s, t)\),
  \begin{align*}
    \norm*{\frac{\Gamma(s) - \Gamma(t)}{s - t} - \Gamma'(\xi)} &= \norm{(f_1'(\xi_1), f_2'(\xi_2), f_3'(\xi_3)) - (f_1'(\xi), f_2'(\xi), f_3'(\xi))} \\
                                                               &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} +\frac{\varepsilon}{3} \\
                                                               &= \varepsilon
  \end{align*}
  i.e.
  \[
    \norm{(\Gamma(t) - \Gamma(s)) - (t - s)\Gamma'(\xi)} < \varepsilon(t - s)
  \]
  for all \(\xi \in (s, t)\). Specialise to \(t = t_i, s= t_{i - 1}, \xi = \frac{t_i + t_{i - 1}}{2}\) and sum over \(i\), we get
  \[
    \sum_i \norm*{(\Gamma(t_i) - \Gamma(t_{i - 1})) - (t_i - t_{i - 1}) \Gamma'\left(\frac{t_i + t_{i - 1}}{2}\right)} < \sum_i \varepsilon(t_i - t_{i - 1}) = \varepsilon(b - a).
  \]
  Now if \(\mesh \mathcal D < \delta\) then the reverse triangle inequality gives
  \[
    \left|s_{\mathcal D}  - \sum_i (t_i - t_{i - 1}) \norm*{\Gamma'\left(\frac{t_i + t_{i - 1}}{2}\right)}\right| < \varepsilon (b - a).
  \]
\end{proof}





\printindex

\iffalse
Other courses that might be useful: topology, part of analysis II (differentiability in R^n and inverse function theorem)

Leads to: IID Differential Geometry

Reading List

P.\ Wilson, Curverd Spaces, CUP 2008
From classical geometries to elementary differential geometry
\fi


\end{document}
