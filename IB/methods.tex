\documentclass[a4paper]{article}

\def\npart{IB}

\def\ntitle{Methods}
\def\nlecturer{C.\ P.\ Caulfield}

\def\nterm{Michaelmas}
\def\nyear{2017}

\input{header}

\renewcommand*\L{\mathcal{L}}

\begin{document}

\input{titlepage}

\tableofcontents

% part 1 Self-adjoint ODEs

\section{Fourier Series}

\subsection{Periodic functions}

A function $f(t)$ is \emph{periodic} with period $T$ if $f(t+T) = f(t)$. Consider $A \sin\omega t$, where $A$ is the amplitude, $\omega$ is the frequency and $2\pi/\omega=T$ is the period. Sines and cosines have an orthogonality property:
\begin{align*}
  \cos(A\pm B) &= \cos A\cos B \mp \sin A\sin B \\
  \cos A \cos B &= \frac{1}{2}[\cos(A-B)+\cos(A+B)] \\
  \sin A \sin B &= \frac{1}{2}[\cos(A-B)-\cos(A+B)]
\end{align*}

Consider $\sin\frac{n\pi x}{L}, \sin\frac{m\pi x}{L}$ where $n,m$ are non-negative integers. These functions are periodic with period $2L$.
\begin{align*}
  ss_{m,n} &:= \int_0^{2L}\sin\frac{m\pi x}{L}\sin\frac{n\pi x}{L} dx \\
  &= \frac{1}{2}\int_0^{2L}\cos\frac{(m-n)\pi x}{L} - \cos\frac{(m+n)\pi x}{L} dx \\
          &= \frac{L}{2\pi}\Bigg[\frac{\sin\frac{(m-n)\pi x}{L}}{m-n} - \frac{\sin\frac{(m+n)\pi x}{L}}{m+n}\Bigg]_0^{2L}\\
           &=
             \begin{cases}
               0 & \text{if } m\neq n \\
               L & \text{if } m=n\neq 0 \\
               0 & \text{if } m=n=0
             \end{cases}
\end{align*}
Thus
\[
  ss_{m,n}=
  \begin{cases}
    L \delta_{mn} &\text{if } n\neq 0 \\
    0 &\text{if } m=0 \text{ or } n=0
  \end{cases}
\]
Similarly
\[
  cc_{m,n} := \int_0^{2L}\cos\frac{m\pi x}{L}\cos\frac{n\pi x}{L} dx =
  \begin{cases}
    2L &\text{if } m=n=0 \\
    L\delta_{mn} &\text{otherwise}
  \end{cases}
\]
Finally,
\begin{align*}
  cs_{mn} &:= \int_0^{2L}\cos\frac{m\pi x}{L}\sin\frac{n\pi x}{L} dx \\
          &= \frac{1}{2}\int_0^{2L}\frac{\sin (m+n)\pi x}{L} - \frac{\sin (m-n)\pi x}{L} dx \\
          &= 0
\end{align*}

By analogy with vectors (these integrals are \emph{inner products}), $\sin \frac{n\pi x}{L}$ and $\cos\frac{n\pi x}{L}$ are said to be \emph{orthogonal} on the interval $[0,2L]$. Actually they constitute an \emph{orthogonal basis}, i.e. it is possible to represent an arbitray (but sufficiently well-behaved) function in terms of an infinite series (Fourier series) formed as a sum of sines and cosines.

\subsection{Definition of Fouries Series}

Any ``well-behaved'' (to be defined later) periodic function $f(x)$ with period $2L$ can be written as a Fourier series:
\begin{equation}
  \label{eqn:fourier coefficients}
  \frac{f(x_+)+f(x_-)}{2} = \frac{1}{2}a_0 + \sum_{n=1}^\infty \Big(a_n\cos\frac{n\pi x}{L} +b_n\sin\frac{n\pi x}{L}\Big)
  \tag{$\ast$}
\end{equation}
where $a_n$ and $b_n$ are the \emph{Fourier coefficients} and $f(x_+)$ and $f(x_-)$ are the right limit approaching from above and the left limit approaching from below respectively.

\begin{enumerate}
\item If $f(x)$ is continuous at $x_c$, the LHS is just $f(x)$.
  \item if $f(x)$ has a \emph{bounded} discontinuity at $x_d$, i.e., $|f(x_d^-)-f(x_d^+)|$ is non-zero but finite, the Fourier series tends to the mean value of the two limits.
\end{enumerate}

\subsection{Coefficient Construction}

Multiply RHS of equation~\eqref{eqn:fourier coefficients} by $\sin \frac{m\pi x}{L}$, integrate over $[0, 2\pi]$. Assume we can exchange summation and integration,
\begin{align*}
  \int_0^{2L} f(x)\sin\frac{m\pi x}{L} dx &= \int_0^{2L} \Bigg[ \frac{1}{2}a_0 + \sum_{n=1}^\infty \Big(a_n\cos\frac{n\pi x}{L} +b_n\sin\frac{n\pi x}{L}\Big) \Bigg] \sin\frac{m\pi x}{L} dx \\
    &= 0 + \sum_{n=1}^\infty a_n \int_0^{2L} \cos\frac{n\pi x}{L} \sin\frac{m\pi x}{L} dx +  \sum_{n=1}^\infty b_n \int_0^{2L} \sin\frac{n\pi x}{L} \sin\frac{m\pi x}{L} dx\\
  &= 0 + 0 + L b_m
    \end{align*}
Thus
\[
  b_m = \frac{1}{L}\int_0^{2L} f(x) \sin\frac{m\pi x}{L} dx
\]

Similarly, multiply by $\cos \frac{m\pi x}{L}$ and integrate (include $m=0$), we get
\[
  \int_0^{2L} f(x)\cos\frac{m\pi x}{L} dx = \int_0^{2L} \Bigg[ \frac{1}{2}a_0 + \sum_{n=1}^\infty \Big(a_n\cos\frac{n\pi x}{L} +b_n\sin\frac{n\pi x}{L}\Big) \Bigg] \cos\frac{m\pi x}{L} dx
\]
The first term is non-zero only when $m=0$. Therefore
\[
  \frac{a_0}{2} \cdot 2L = \int_0^{2L} f(x) dx
\]
so
\[
\frac{a_0}{2} = \frac{1}{2L}\int_0^{2L} f(x) dx.
\]
The second term gives
\[
  a_m = \frac{1}{L} \int_0^{2L} f(x) \cos\frac{m\pi x}{L} dx.
\]

The range of integration is one period so it is also permissible to choose $-L$ and $L$ as the limit of integration. A particularly neat case is when $L=\pi$:
\begin{align*}
  a_m &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \cos mx dx, m\geq0 \\
  b_m &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \sin mx dx, m\geq1
\end{align*}

\subsection{Dirichlet Conditions}

If $f(x)$ is a periodic function with period $2L$ such that
\begin{enumerate}
\item it is absolutely integrable, i.e.$\int_0^{2L}|f(x)| dx$ is well-defined,
\item it has a finite number of extrema (i.e. maxima and minima) in $[0,2L]$,
  \item it has a finite number of \emph{bounded} discontinuities in $[0,2L]$,
\end{enumerate}
then the Fourier series converges to $f(x)$ for all points where $f(x)$ is continuous and at points $x_d$ where $f(x)$ is discontinuous, the series converges to the average value of the left and right limit, i.e. $(f(x_d^+)+f(x_d^-))/2$.

These conditions are satisfied if the function is of \emph{bounded variation}.

\begin{rmk}
  The Fourier series converges but not necessarily uniformly converges. This gives rises to some weird behaviour.
\end{rmk}

\subsubsection{Smoothness and Order of Fourier Coefficients}

If the $p$th derivative is the lowest derivative which is discontinuous somewhere (including the endpoints), then the Fourier coefficients are $O(n^{-(p+1)})$ as $n \to \infty$.

For example, if a function has a bouned discontinuity, the $0$th derivative is discontinuous: coefficients are of order $\frac{1}{n}$ as $n \to \infty$.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item The sawtooth function $f(x) = x$ for $-L \leq x < L$.
    \begin{center}
      \begin{tikzpicture}
        \begin{axis}[
          xtick={-4,4},
          xticklabels={$-2L$,$2L$},
          ytick={-2,2},
          yticklabels={$-L$,$L$},
          axis lines=center,
          axis equal image,
          xmin=-8,
          xmax=8,
          ymin=-3,
          ymax=3,
          xlabel=$x$,
          ylabel=$f(x)$]
          \addplot[domain=-2:2,color=red]{x};
          \addplot[domain=2:6,color=red]{x-4};
          \addplot[domain=-6:-2,color=red]{x+4};
        \end{axis}
      \end{tikzpicture}
    \end{center}
    The function is odd so
\begin{align*}
  a_m &= \frac{1}{L}\int_{-L}^L x \cos\frac{m\pi x}{L} dx = 0 \\ 
  b_m  &= \frac{1}{L}\int_{-L}^L x \sin\frac{m\pi x}{L} dx \\
      &= \frac{1}{L}\Big[x \frac{L}{m\pi}(-\cos\frac{m\pi x}{L})\Big]_{-L}^L - \frac{1}{L}\frac{L}{m\pi} \int_{-L}^L -\cos\frac{m\pi x}{L} dx \\
      &= \frac{1}{m\pi}\Big( L(-\cos m\pi) - (-L)(-\cos m\pi) \Big) + \frac{1}{m\pi} \Big[ \frac{L}{m\pi} \sin\frac{m\pi x}{L} \Big]_{-L}^L \\
  &= \frac{2L}{m\pi}(-1)^{m+1}
\end{align*}

So
\[
  \frac{f(x_+)+f(x_-)}{2} = \frac{2L}{\pi}\Big[\sin\frac{\pi x}{L} - \frac{1}{2}\sin\frac{2\pi x}{L} + \cdots \Big].
\]
and we observe that
\begin{enumerate}
\item $f_N(x) = \sum_{n=1}^N b_n\sin\frac{n\pi x}{L} \to f(x)$ almost everywhere but the convergence is \emph{not} uniform.
\item Persistent overshooting at $x=L$: Gibbs phenomenon.
\item $f(L) = 0$, the average of right and left hand limit.
\item Coefficients are $O(\frac{1}{n})$ as $n\to \infty$.
\end{enumerate}

\item The integral of the sawtooth function, $f(x) = \frac{x^2}{2}$ for $-L \leq x < L$.
    \begin{center}
      \begin{tikzpicture}
        \begin{axis}[
          xtick={-4,4},
          xticklabels={$-2L$,$2L$},
          ytick={-2,2},
          yticklabels={$-L/2$,$L/2$},
          axis lines=center,
          axis equal image,
          xmin=-8,
          xmax=8,
          ymin=-3,
          ymax=3,
          xlabel=$x$,
          ylabel=$f(x)$]
          \addplot[domain=-2:2,color=red]{x^2/2};
          \addplot[domain=2:6,color=red]{(x-4)^2/2};
          \addplot[domain=-6:-2,color=red]{(x+4)^2/2};
        \end{axis}
      \end{tikzpicture}
    \end{center}
  Exercise: $f(x) = L^2 \big[ \frac{1}{6} + 2\sum_{n=1}^\infty \frac{(-1)^n}{(n\pi)^2} \cos\frac{n\pi x}{L} \big]$.

  Note at $x=0$,
  \begin{align*}
    & 0 = L^2 \Big[\frac{1}{6} + 2\sum_{n=1}^\infty \frac{(-1)^n}{(n\pi)^2} \Big] \\
    \Rightarrow & \frac{\pi^2}{12} = \sum_{n=1}^\infty\frac{(-1)^{n+1}}{n^2}
  \end{align*}
  \end{enumerate}
\end{eg}

\section{Properties of Fourier Series}

\subsection{Integration \& Differentiation}

\subsubsection{Integration\protect\footnote{Don't panic: it's always OK.}}

Fourier series \emph{can} be integrated term by term. Suppose $f(x)$ with period $2L$ has a Fourier series (so it satisfies the Direichlet condition):
\[
  \frac{f(x_+)+f(x_-)}{2} = \frac{1}{2}a_0 + \sum_{n=1}^\infty \Big(a_n\cos\frac{n\pi x}{L} +b_n\sin\frac{n\pi x}{L}\Big).
\]
Consider
\begin{align*}
  F(x) & = \int_{-L}^x f(u) du \\
       &= \frac{a_0(x+L)}{2} + \sum_{n=1}^\infty \frac{a_n L}{n\pi}\sin\frac{n\pi x}{L} + \sum_{n=1}^\infty \frac{b_n L}{n\pi} \Big[(-1)^n - \cos\frac{n\pi x}{L} \Big] \\
       &= \frac{a_0 L}{2} + L \sum_{n=1}^\infty (-1)^n \frac{b_n}{n\pi} - L \sum_{n=1}^\infty \frac{b_n}{n\pi} \cos\frac{n\pi x}{L} \\
       &+ L \sum_{n=1}^\infty \frac{a_n-(-1)^n a_0}{n\pi}\sin\frac{n\pi x}{L}
\end{align*}

If $a_n, b_n$ are Fourier coefficients, then series involving $\frac{a_n}{n}, \frac{b_n}{n}$ (multiplied by sine or cosine) must also converge, so they are part of a Fourier series. Fourier series of $f(x)$ exists so $b_n$ is at least of $O(\frac{1}{n})$ as $n\to\infty$. Thus $\frac{b_n}{n}$ is at least of order $O(\frac{1}{n^2})$ as $n\to \infty$ and so by comparison test with $\sum \frac{M}{n^2}$ the second term converges, so $F(x)$ has a Fourier series.

\begin{note}
  Integration smoothes.
  The proof relies on discontinuity being bounded ($f(x)$ satisfies the Dirichlet condition).
\end{note}

\subsubsection{Differentiation\protect\footnote{Do panic, it doesn't always work!}}

Let $f(x)$ be a periodic function with period $2$ such that
\[
  f(x) =
  \begin{cases}
    1 & 0 < x < 1\\
    -1 & -1 < x < 0 
  \end{cases}
\]
This is an odd function so
\begin{align*}
  a_m &= 0 \\
  b_m &= -\int_{-1}^0 \sin m\pi x dx + \int_{-1}^0 \sin m\pi x dx \\
  &= \frac{\cos m\pi x}{m\pi} \Big|_{-1}^0 - \frac{\cos m\pi x}{m\pi} \Big|_0^{-1} \\
  &= \frac{1}{m\pi} \big(1- (-1)^m - (-1)^m + 1 \big) \\
  & =
  \begin{cases}
    \frac{4}{m\pi} & m \text{ is odd} \\
    0 & m \text{ is even}
  \end{cases}
\end{align*}
Thus
\[
  \frac{f(x_+)+f(x_-)}{2} = \frac{4}{\pi} \sum_{n=1}^\infty \frac{\sin(2n-1)\pi x}{2n-1}.
  \]
Apply differentiation rules
\[
  f'(x) = 4 \sum_{n=1}^\infty \cos(2n-1)\pi x
\]
This is clearly divergent even though $f'(x) = 0$ for all $x \neq 0$. The extra factor of $2n-1$ is the problem, which is related to the discontinuity. $f'(x)$ \emph{does not} satisfy the Dirichlet condition.

\begin{note}
  Intuitively, this behaviour can be explained by noticing that Dirac delta function is the derivative of Heaviside function.
\end{note}

\subsubsection{Differentiation Under Certain Circumstances}

Fourier series can be differentiated under certain circumstances: 
\begin{eg}
  Assume \(f(x)\) is continuous and is extended as a \(2L\)-periodic function, piecewise continuously differentiable on \((-L,L)\). Let \(g(x)=\frac{df}{dx}\). \(g(x)\) satisfies the Dirichlet condition as it has at worst a finite number of bounded discontinuities.
  \begin{align*}
    f(x) &= \frac{a_0}{2} + \sum_{n=1}^{\infty} a_n \cos \frac{n\pi x}{L}+ b_n \sin \frac{n\pi x}{L} \\
    \frac{g(x_+)+g(x_-)}{2} &=\frac{A_0}{2} + \sum_{n=1}^{\infty} A_n \cos \frac{n\pi x}{L} + B_n \sin \frac{n\pi x}{L}
  \end{align*}
  Then
  \begin{align*}
    A_0 &= \frac{1}{L}\int_{0}^{2L}g(x) dx \\
        &= \frac{f(2L)-f(0)}{L} \\
        &= 0
  \end{align*}
  by periodicity.
  \begin{align*}
    A_n &=\frac{1}{L} \int_{0}^{2L}\frac{df}{dx}\cos \frac{n\pi x}{L}dx \\
        &= \frac{1}{L}\Big[f(x)\cos \frac{n\pi x}{L} \Big] \Big|_0^{2L} + \frac{n\pi}{L^2} \int_{0}^{2L} f(x)\sin \frac{n\pi x}{L} dx \\
        &= 0 + \frac{n\pi b_n}{L}
      \end{align*}
      Similarly, \(B_n=-\frac{n\pi a_n}{L}\).

      This reduces differentiation to multiplication by \(\pm \frac{n\pi}{L}\).
      \end{eg}

\subsection{Alternate Representation: Complex Form}

Recall
\begin{align*}
  \cos \frac{n\pi x }{L} &= \frac{1}{2} (e^{i\frac{n\pi x}{L}} + e^{-i\frac{n\pi x}{L}}) \\
  \sin \frac{n\pi x }{L} &= \frac{1}{2i} (e^{i\frac{n\pi x}{L}} - e^{-i\frac{n\pi x}{L}})
\end{align*}
so
\begin{align*}
  \frac{f(x_+)+f(x_-)}{2} &= \frac{a_0}{2} + \sum_{n=1}^{\infty} \frac{a_n}{2} (e^{i \frac{n\pi x}{L}} + e^{-i \frac{n \pi x}{L}}) - \sum_{n=1}^{\infty} \frac{b_n}{2} (e^{i \frac{n\pi x}{L}} - e^{-i \frac{n \pi x}{L}})\\
                          &= \frac{a_0}{2} + \sum_{n=1}^{\infty} \big( \frac{a_n-i b_n}{2} e^{i \frac{n\pi x}{L}} \big) + \sum_{n=1}^{\infty} \big( \frac{a_n+i b_n}{2} e^{-i \frac{n\pi x}{L}} \big) \\
                          &= \sum_{n=-\infty}^{\infty} c_n e^{i\frac{n\pi x}{L}}
\end{align*}
with
\begin{align*}
  c_0 &= \frac{a_0}{2}, \\
  c_n &= \frac{a_n-ib_n}{2}, n>0, \\
  c_n &= \frac{a_n+ib_n}{2}, n<0.
\end{align*}

Note that \(c_n^* = c_{-n}\). It can be easily shown that complex exponentials are orthogonal:
\begin{align*}
  \int_{0}^{2L} e^{i\frac{n\pi x}{L}} e^{-i\frac{m\pi x}{L}}dx &= \int_{0}^{2L}\cos \frac{(n-m)\pi x}{L}dx + i \int_{0 }^{2L}\sin \frac{(n-m)\pi x}{L} dx \\
  &= 2L \delta_{n,m} + 0
\end{align*}
so
\[
  c_m = \frac{1}{2L} \int_{0}^{2L}f(x)e^{-i\frac{m\pi x}{L}} dx = \frac{1}{2L} \int_{0}^{2L} \Big( \sum_{n=-\infty}^{\infty} c_n e^{i\frac{n\pi x}{L}} \Big) e^{i\frac{-m\pi x}{L}} dx.
\]

Now assume \(g(x) = \frac{df}{dx} = \sum_{n=-\infty}^{\infty} c_n e^{i\frac{n\pi x}{L}}\). Then
\begin{align*}
  c_n &= \frac{1}{2L}\int_{0}^{2L} \frac{df}{dx }e^{-i\frac{n\pi x}{L}}dx \\
      &= \frac{1}{2L} \Big[ f(x) e^{-i\frac{n\pi x}{L}} \Big]_0^{2L} + \frac{in\pi}{2L^2} \int_{0}^{2L}f(x) e^{-i\frac{n\pi x}{L}} dx \\
      &= \frac{in\pi}{L}c_n
\end{align*}
by periodicity.



\subsection{Half-range Series}

Consider a function defined \emph{only} on \(0 \leq x \leq L\). There are two possible ways to extend this function to a \(2L\)-periodic function that can be represented as a Fourier series.

\subsubsection{Odd function: Fourier Sine Series}

\(f(x)\) can be extended as an \emph{odd} function \(f(x)=-f(-x)\) on \(-L \leq x \leq L\) and then extended as a \(2L\)-periodic function. In this case \(a_n=0\) we can define the \emph{Fourier sine series}:
\[
  \frac{f(x_+)+f(x_-)}{2} = \sum_{n=1}^{\infty}b_n \sin \frac{n\pi x}{L}
\]
where
\[
  b_n = \frac{2}{L} \int_{0}^{L} f(x) \sin \frac{n\pi x}{L} dx.
\]
Note the range of integration.

\begin{eg}[Sawtooth function]
  
\end{eg}

\subsubsection{Even function: Fourier Cosine Series}

\(f(x)\) can also be extended as an even function on \(-L\leq x\leq L\), i.e. \(f(x) = f(-x)\) and then extended as a \(2L\)-periodic function. \(b_n=0\) for all \(n\). The Fourier cosine series is
\[
  \frac{f(x)+f(x)}{2} = \frac{a_0}{2} + \sum_{n-1}^{\infty}a_n \cos \frac{n\pi x}{L}
\]
where
\[
  a_n = \frac{2}{L}\int_{0}^{L}f(x)\cos \frac{n\pi x}{L}.
\]

\subsection{Parseval's Theorem}

``Energy'' of a periodic signal is often of interest, i.e. \(E = \int_{0}^{2L}f^2(x) dx \). Consider the general case
\[
  f(x) = \sum_{n=-\infty}^{\infty}c_n e^{\frac{in\pi x}{L}}, g(x) = \sum_{m=-\infty}^{\infty}d_m e^{\frac{im\pi x}{L}};
\]
\begin{align*}
  \int_{0}^{2L} f(x) g(x) dx &= \sum_{n=-\infty}^{\infty} \sum_{m=-\infty}^{\infty} c_n d_m \int_{0}^{2L} \exp \Big [\frac{i\pi x}{L} (n+m) \Big] dx \\
  &= \sum_{n=-\infty}^{\infty} \sum_{m=\infty}^{\infty} c_n d_m (2L \delta_{n,-m}) \\
  &= 2L \sum_{n=-\infty}^{\infty} c_n d_{-n} \\
  &= 2L \sum_{n=-\infty}^{\infty} c_n d_n*
  \end{align*}
so if \(g=f\),
\[
  \int_{0}^{2L} f^2(x) dx = 2L \sum_{n=-\infty}^{\infty}|c_n|^2 = L \Big[ \frac{a_0^2}{2} + \sum_{n=1}^{\infty}(a_n^2+b_n^2) \Big]
\]

\begin{eg}[Sawtooth function]
  Remember \(f(x)=x\) for \(-L\leq x\leq L\).
  \[
    b_n = \frac{2L}{m\pi}(-1)^{m+1}
  \]
  so
  \[
    \int_{-L}^{L} x^2 dx = \frac{2L^3}{3} = L \sum_{m=1}^{\infty}\frac{4L^2}{m^2\pi^2}
  \]
  so
  \[
    \sum_{m=1}^{\infty}\frac{1}{m^2} = \frac{\pi^2}{6}.
  \]
\end{eg}

\begin{ex}
  From the Fourier series of \(x^2/2\) show that
  \[
    \sum_{m=1}^{\infty}\frac{1}{m^4} = \frac{\pi^4}{90}.
  \]
\end{ex}

\section{Sturm-Liouville Theory}

\subsection{Second Order ODEs}

Consider a general second order ordinary partical differential equation
\[
  \L y(x) = \alpha(x) \frac{d^2y}{dx^2} + \beta(x) \frac{dy}{dx} + \gamma(x) y = f(x).
\]

\(\alpha,\beta,\gamma\) are continuous, with \(\alpha\) non-zero except perhaps at a finite number of isolated points. \(f(x)\) is bounded, defined on \(a\leq x\leq b\) (\(a\) or \(b\) may be infinity).
tary function is \[
  y_c=Ay_1+By_2.
\]
\emph{Inhomogeneous} or \emph{forced} equation \(\L y = f(x)\) where \(f\) is the forcing, has a particular integral \(y_p(x)\). The general solution is \(y=y_c(x)+y_p(x)\) where \(A,B\) are determined in a problem by applying condition.

\subsection{Hermitian Matrices: an Analogy}

Remember the problem: find \(\V x \) such that
\[
A \V x = \V b.
\]
If \(A\) is an Hermitian matrix, \(A\) is \(N \times N\), i.e. \(A^\dag A\) where the \(\dag\) denotes complex conjugate transpose. It has \(4\) properties:\footnote{Recall an eigenvector and eigenvalue are defined such that \(A \V y_n = \lambda_n \V y_n\) where \(\lambda_n\) is the eigenvalue and \(y_n\) is the eigenvector.}
\begin{enumerate}
\item \(\lambda_n\) are real,
\item if \(\lambda_m\neq\lambda_n\) then \(\V y_m\cdot\V y_n=0\),
\item the eigenvectors form, on scaling, an orthonormal basis and so specially \(\V b \in \C^N\) can be described by a linear combination of eigenvectors,
\item if \(A\) is non-singular, i.e. all eigenvalues are non-zero, the solution to \(A\V x = \V b\) can be written as a sum of eigenvector.
\end{enumerate}

\subsubsection{Gaussian Elimination}

From property \(3\) above we can write
\begin{align*}
  \V b &= \sum_{n=1}^{N}b_n y_n \\
  \V x &=\sum_{n=1}^{N}C_n y_n
\end{align*}

Since \(A\) is linear,
\[
  A \V x = \sum_{n=1}^{N}c_n A \V y_n = \sum_{n=1}^{N}c_n \lambda_n \V y_n = \sum_{n=1}^{N}b_n \V y_n = \V b.
\]
For simplicity assuming the \(\lambda_n\) are distinct and non-zero. From property \(2\),
\[
\V y_m \cdot \big( \sum_{n=1}^{N}c_n \lambda_n \V y_n \big) = c_m \lambda_m = \V y_m \cdot \big( \sum_{n=1}^{N}c_n \lambda_n \V y_n \big) = b_m
\]
Therefore
\begin{align*}
  c_m &= \frac{b_m}{\lambda_m} \\
  x &= \sum_{n=1}^{N}\frac{b_n}{\lambda_n}y_n
\end{align*}

\begin{question}
  Can this be generalised to differential operators?
\end{question}

\subsection{Motivating Example: Fourier Series}
\label{subsec:motivating}

For continuous forcing functions \(f(x)\), we want to find \(y(x)\) on a finite interval such that
\[
  -\frac{d^2y}{dx^2} = f(x), 0 \leq x \leq L, \: f(0) = f(L) = y(0) = y(L) = 0,
\]
satisfies the Dirichlet conditions and so we can write a Fourier sine series if we extend \(f\) to be a \(2L\)-periodic odd function:
\begin{align*}
  f(x) &= \sum_{n=1}^{\infty}b_n \sin \frac{n\pi x}{L} \\
  b_n &= \frac{2}{L} \int_{0}^{L} f(\xi) \sin \frac{n\pi \xi}{L} d\xi
\end{align*}

Let \(\L = - \frac{d^2}{dx^2}\), can we find solutions to
\[
\L y_n = \lambda_n y_n,\: y_n(0) = y_n(L) = 0?
\]

Indeed, we can solve the equations
\[
  \frac{d^2}{dx^2} y_n = - \lambda_n y_n,
\]
and obtain the solutions
\begin{align*}
  y_n &= \sin \frac{n\pi x}{L}, \\
  \lambda_n &= \frac{n^2\pi^2}{L^2}.
\end{align*}
In particular, the boundary value quantises the \(\lambda_n\).

\begin{note}
  \(\lambda_n\) are real and strictly positive and so \(y_n\) is an eigenfunction with associated eigenvalue \(\lambda_n\).
\end{note}

Note \(\lambda_n = \frac{n^2\pi^2}{L^2}\) has property \(1\) and we have already met the orthogonality property \(2\), i.e. \(\int_{0}^{L} y_ny_m dx=\frac{L}{2}\delta_{m,n} \). There is also a generalisation of property \(3\): sines and cosines form a complete (infinite-dimensional) basis for functions that satisfy Dirichlet condition.

For this problem \(y(x)\) must be sufficiently smooth so that its \emph{second derivative} satisfies the Dirichlet condition.

\(y(x)\) has a Fourier sine series:
\begin{align*}
  y(x) &= \sum_{n=1}^{\infty}c_n \sin \frac{n\pi x}{L} \\
  -\frac{d^2}{dx^2} y &= \L y = \sum_{n=1}^{\infty} \frac{n^2\pi^2}{L^2}c_n \sin \frac{n\pi x}{L} = \sum_{n=1}^{\infty} \lambda_n c_n \sin \frac{n\pi x}{L} \\
       &= \sum_{n=1}^{\infty}b_n \sin \frac{n\pi x}{L}
\end{align*}

The orthogonality property tell us that
\[
\lambda_n c_n = b_n.
\]
Thus
\begin{align*}
  y(x) &= \sum_{n=1}^{\infty} \frac{b_n}{\lambda_n} \sin \frac{n\pi x}{L}, \: \lambda_n = \frac{n^2\pi^2}{L^2} \\
       &= \frac{2}{L} \int_{0}^{L} \sum_{n=1}^{\infty} \frac{1}{\lambda_n} \sin \frac{n\pi x}{L}\sin\frac{n\pi\xi}{L} f(\xi) d\xi \\
        &= \int_{0}^{L} G(x; \xi) f(\xi) d\xi\end{align*}
where \(G(x;\xi)\) is the \emph{Green's function}.

Note the loose analogy between Hermitian matrices and self-adjoint operators:
\begin{align*}
  A\V x = \V b &\Rightarrow \V x = A^{-1}\V b \\
  \L y = f &\Rightarrow y = \L^{-1} f
\end{align*}

\section{Self-adjoint Operators}

\subsection{Definition of Self-adjoint Form}

Consider a second order linear differential operator where the eigenvalue problem is to determine eigenfunction \(y\) and associated eigenvalue \(\lambda\) such that
\begin{equation}
  \label{eqn:self-adjoint}
\alpha(x) \frac{d^2y}{dx^2} + \beta(x) \frac{dy}{dx} + \gamma(x) y = \L y = -\lambda \kappa(x) y, a \leq x\leq b
\tag{\(\ast\)}
\end{equation}
where \(\kappa\) and \(\alpha\) are real and positive on \([a,b]\). (In the previous example, \(\kappa = 1 = \alpha, \beta=\gamma=0\).) This general differential operator can \emph{always} be written in \emph{Sturm-Liouville} or \emph{self-adjoint} form
\[
\L y = - \frac{d}{dx} \Big[ p(x) \frac{dy}{dx} \Big] + q(x) y =\lambda w(x) y
\]
where \(w(x)\) is called the \emph{weight} function, wlog real and positive on \([a,b]\) except possibly on isolated points where \(w=0\).

Multiply \eqref{eqn:self-adjoint} by \(-\phi(x)\) where
\[
\phi(x) = \frac{1}{\alpha(x)}\exp \Big(\int_{ }^{x} \frac{\beta(u)}{\alpha(u)} du \Big),
\]
the result is
\begin{align*}
  p(x) &= \exp \Big( \int^x \frac{\beta(u)}{\alpha(u)}du \Big) \\
  q(x) &= -\frac{\gamma(x)}{\alpha(x)} \Big( \int^x \frac{\beta(u)}{\alpha(u)}du \Big) \\
  w(x) &= -\frac{\kappa(x)}{\alpha(x)} \Big( \int^x \frac{\beta(u)}{\alpha(u)}du \Big)
\end{align*}
where \(p, q, w\) are all real and positive on \([a,b]\).

\subsection{Definition of Self-adjointness}

Consider a linear \(2\)nd order differential operator \(\L\) defined on \([a,b]\). The \emph{adjoint} of \(\L\), denoted by \(\L^\dag\) has the property that for all pairs of functions \(y_1\) and \(y_2\) satisfying appropriate boundary conditions, which shall be defined below,
\[
\int_a^b y_1^* \L y_2 dx = \int_a^b y_2 (\L^\dag y_1)^* dx.
\]
If \(\L = \L^\dag\) (with appropriate boundary conditions) then \(\L\) is said to be \emph{self-adjoint} or \emph{Hermitian}.

\subsubsection{Self-adjointness of Sturm-Liouville Operator}

To derive the necessary and sufficient condition for the Sturm-Liouville operator to be self-adjoint, we consider the real case here:
\begin{align*}
  \int_{a}^{b} y_1\L y_2 dx &= \int_{a}^{b} y_1 \Big[ -\frac{d}{dx} \big(p \frac{dy_2}{dx} \big) + qy_2 \Big] dx \\
                         &= \Big[-y_1 p\frac{dy_2}{dx} \Big]^b_a + \int_{a}^{b} qy_1y_2  dx + \int_{a}^{b} p\frac{dy_2}{dx} \frac{dy_1}{dx} dx \\
                         &= \Big[-y_1p \frac{dy_2}{dx} \Big]^b_a + \int_{a}^{b} y_2\Big(-\frac{d}{dx} \big(p \frac{dy_1}{dx} \big)+ qy_1 \Big) dx + \Big[ y_2p \frac{dy_1}{dx} \Big]^b_a \\
                         &= \int_{a}^{b} y_2\L y_1 dx + \underbrace{\Big[ p(y_2 \frac{dy_1}{dx} - y_1 \frac{dy_2}{dx})\Big]^b_a}_{T_1} 
\end{align*}
Note the Wronskian in \(T_1\).

The operator
\[
  \L = -\frac{d}{dx}(p \frac{d}{dx}) + q
\]
is thus self-adjoint if and only if \(T_1=0\).

In the previous example, \(y=0\) at \(x=a,b\). Other simple examples satisfying \(T_1=0\) include:
\begin{itemize}
\item \(y'=0\) at \(x=a,b\),
\item \(y+ky'=0\) with \(k\) constant at \(x=a,b\).
\item Periodic boundary conditions satisfying
\[
y(a) = y(b) \text{ or } y'(a) = y'(b).
\]
\item \(p=0\) at \(x=a,b\).
\end{itemize}

\subsubsection{Properties of Self-adjoint Operators}

\begin{enumerate}
\item The eigenvalues are real: assume that \(\lambda_n\) is an eigenvalue and \(y_n\) is the associated eigenfunction. Then
  \[
\L y_n = \lambda_ny_n w, \: (\L y_n)^* = \lambda_n^*y_n^*w^*.
  \]
  But here \(w\) and \(\L\) are real by assumption (unlike in quantum mechanics, for example) so
  \begin{align*}
    \L y_n^* &= \lambda_n^* y_n^* w \\
    \int_{a}^{b} y_n(\L y_n^*) dx &=  \int_{a}^{b} y_n(\lambda_n^*wy_n^*) dx = \lambda_n^* \int_{a}^{b} w |y_n|^2 dx \\
    \int_{a}^{b} y_n^* (\L y_n) dx &= \int_{a}^{b} y_n^*(\lambda_ny_nw) dx = \lambda_n \int_{a}^{b} w |y_n|^2 dx
  \end{align*}
  By self-adjointness,
  \begin{align*}
    0 &= \int_{a}^{b} y_n (\L y_n)^* dx - \int_{a}^{b} y_n^* (\L y_n) dx \\
      &= (\lambda_n^* - \lambda_n) \int_{ }^{ } w |y_n|^2 dx
  \end{align*}
  so \(\lambda_n^* = \lambda_n\).
\item The eigenfunctions of distinct eigenvalues are orthogonal: assume that \(y_n\) and \(y_m\) are eigenfunctions with distinct eigenvalues \(\lambda_n \neq \lambda_m\):
  \[
\L y_n = \lambda_n w y_n, \: \L y_m = \lambda_m wy_m.
\]
By self-adjointness
\begin{align*}
  0 &= \int_{a}^{b} y_m\L y_n dx - \int_{a}^{b} y_n\L y_m dx \\
    &= \int_{a}^{b} y_m \lambda_nwy_n dx - \int_{a}^{b} y_n\lambda_mwy_m dx \\
    &= (\lambda_n - \lambda_m) \int_{a}^{b} wy_ny_m dx \\
  \Rightarrow &\int_{a}^{b} wy_ny_m dx = 0
\end{align*}

Note the weight function in the integral.
\item There is an orthonormal set of eigenfunctions: let
  \[
    Y_n(x) = \frac{y_n(x)}{\big(\int_{a}^{b} wy_n^2 dx \big)^{1/2}}
  \]
  so
  \[
\delta_{m,n}=\int_{a}^{b} w(x)Y_m(x)Y_n(x) dx.
  \]
\item The set of eigenfunctions form a complete basis: suppose a function \(f(x)\) satisfying the boundary condition as eigenfunction. \emph{Completeness} means that any such \(f(x)\) can be expressed as
  \[
f(x) = \sum_{n=1}^{\infty}a_ny_n(x) = \sum_{n=1}^{\infty} A_n Y_n(x).
  \]
  where \(Y_n(x)\) is an orthonormal basis.
\item These coefficients can always be determined using orthogonality:
  \[
\int_{a}^{b} f(x)wY_m(x) dx = \sum_{n=1}^{\infty}A_n \int_{a}^{b} wY_n(x)Y_m(x) dx = A_m
\]
\item A corollary of the property of completeness is that there is always a \emph{countably infinite} number of eigenvalues which satisfy the underlying self-adjoint problem.
\item Parseval's Theorem for such self-adjoint operators: consider
  \begin{align*}
    I &= \int_{a}^{b} w \underbrace{\Big[ f(x) - \sum_{n=1}^{\infty}A_nY_n(x) \Big]^2} dx \\
      &= \int_{a}^{b} w f^2(x) dx - 2 \sum_{n=1}^{\infty}A_n \int_{a}^{b} w fY_n dx + \sum_{n=1}^{\infty}\sum_{m=1}^{\infty} A_nA_m \int_{a}^{b} wY_nY_m dx \\
      &=\int_{a}^{b} w f^2 dx -2 \sum_{n=1}^{\infty}A_n^2 + \sum_{n=1}^{\infty}A_n^2 \\
      &= \int_{a}^{b} wf^2 dx - \sum_{n=1}^{\infty} A_n^2
  \end{align*}
  \begin{itemize}
  \item If the eigenfunctions are complete, \(I=0\) and so there is a Parseval's relation
  \[
\int_{a}^{b} wf^2 dx = \sum_{n=1}^{\infty}A_n^2.
  \]
\item If the eigenfunctions are not complete, e.g. if \(\L\) is \emph{not} self-adjoint, then square bracket term is positive, \(w\) is positive by construction. Therefore we get \emph{Bessel's inequaility}:
  \[
\int_{a}^{b} wf^2 dx \geq \sum_{n=1}^{\infty}A_n^2.
  \]
  \end{itemize}
\item Eigenfunction series representation are the ``best'' such representation in a particular sense: define the partial sum
  \[
    s_N(x) = \sum_{n=1}^{N}A_nY_n.
  \]
  Completeness implies that \(f(x) = \lim_{N\to \infty}s_N(x)\) except at points of discontinuity of \(f(x)\). For simplicity consider continuous \(f(x)\). The mean square error \(\varepsilon_N\) in approximating \(f(x)\) by \(s_N(x)\) is
  \[
\varepsilon_N = \int_{a}^{b} w(f-s_N(x))^2 dx \to 0 \text{ as } N\to \infty.
\]
Differentiate,
\begin{align*}
  \frac{\partial\varepsilon_n}{\partial A_m} &= -2 \int_{a}^{b} w \Big(f- \sum_{n=1}^{N}A_nY_n \Big) Y_m dx \\
                                             &= -2 \int_{a}^{b} wfY_m dx + 2 \sum_{n=1}^{N}A_n \int_{a}^{b} wY_nY_m dx \\
                                             &= -2A_m + 2A_m \\
                                             &= 0
\end{align*}
Therefore the coefficients extremise (in this case, minimise) the error in the mean square sense and so the best partial sum representation is the partial representation using the eigenfunctions of the underlying Sturm-Liouville operator.
  
\subsubsection{Example with Non-trivial Weight}

Problem: find \(y(x)\) on \([0,\pi]\) such that
\begin{align*}
  y'' + y' + (\frac{1}{4} + \lambda)y &=0 \\
  y(0) &= 0 \\
  y(\pi) - 2y'|_\pi &=0
\end{align*}

Write in self-adjoint form:
\[
  - \frac{d}{dx}\Big( e^x \frac{dy}{dx} \Big)- \frac{e^xy}{4} = \lambda e^xy.
\]
The auxillary equation \(y \propto e^{\sigma x}\) is
\[
  \sigma^2 + \sigma + \frac{1}{4} + \lambda = 0
\]
so
\[
  \sigma = -\frac{1}{2} \pm i \sqrt{\lambda}.
\]
The homogeneous solution is
\[
  y(x) = A e^{-x/2}\cos\mu x + B e^{-x/2}\sin\mu x
\]
with \(\mu^2=\lambda\), satisfying
\begin{align*}
  y(0) &= 0, \\
  y(\pi) - 2y'(\pi) &= Be^{-\pi/2}\big( \sin\mu\pi + \sin\mu\pi - 2\mu\cos\mu\pi \big)=0.
\end{align*}
Therefore
\begin{align*}
  A &= 0, \\
  \tan\mu\pi &= \mu.
\end{align*}
A simple plot shows that there are countably infinite eigenvalues that satisfy this equation. As \(n\to \infty,\mu_n \approx \frac{2n+1}{2}\).

Notice that the eigenfucntions are proportional to \(e^{-x/2}\sin\mu_nx\) so
\begin{align*}
  I_{mn} &\propto \alpha\int_{0}^{\pi} wy_n(x)y_m(x) dx \\
         &= \int_{0}^{\pi} e^x e^{-x/2}\sin\mu_nx e^{-x/2}\sin\mu_mx dx \\
         &= \int_{0}^{\pi} \sin\mu_nx \sin\mu_mx dx \\
         &= 0 \text{ if } n \neq m
\end{align*}
\end{enumerate}

\subsubsection{Application in Inhomogeneous Boundary Value Problems}

Consider this inhomogeneous problem:
\[
  (\L - \hat \lambda w)y = f(x) = wF(x) = w(x) \sum_{n=0}^{\infty} A_nY_n(x).
\]
By completeness, \(y = \sum_{n=1}^{\infty} B_nY_n(x) \) where \(B_n\) is the unknown.
\begin{align*}
  w \sum_{n=1}^{\infty}A_nY_n &= \sum_{n=1}^{\infty}B_n (\L Y_n - \hat \lambda w Y_n) \\
  &= \sum_{n=1}^{\infty}B_n(\lambda_n-\hat \lambda)wY_n
\end{align*}
Multiply across by \(Y_m\) and use property 4: \(\delta_{mn} = \int_{a}^{b} wY_nY_m dx \):
\[
  A_m = B_m(\lambda_m-\hat \lambda)
\]
so
\begin{align*}
  B_m &= \frac{A_m}{\lambda_m-\hat\lambda} \\
      &= \frac{\int_{a}^{b} w(\xi)Y_m(\xi)F(\xi) d\xi}{\lambda_m-\hat\lambda} \\
      &= \frac{\int_{a}^{b} Y_m(\xi)f(\xi) d\xi}{\lambda_m-\hat\lambda} \\ 
  y(x) &= \int_{a}^{b}  \sum_{n=1}^{\infty} \frac{Y_n(\xi)Y_n(x)}{\lambda_n-\hat \lambda} f(\xi) d\xi \\
      &= \int_{a}^{b} G(x;\xi)f(\xi) d\xi
\end{align*}
which is the general form of the example in section~\ref{subsec:motivating}.

% Part II: Seperation of Variables

\section{Wave Equation}

Wave equation is a canonical second order PDE: an example of \emph{hyperbolic equation}. Whenever you have a system with low dissipation of energy and a restoring force you have a wave.

The linear wave equation takes the form
\[
\frac{\p^2\phi}{\p t^2} = c^2\nabla^2\phi
\]
where \(c\) is the (phase) speed, i.e. speed of propagation of crests.

\subsection{Physical Derivation}

The simplest example is a heavy ``massive'' elastic string suspended between \(x=0\) and \(x=L\). Assume those points are at \(y=0\) and assume all deflections are sufficiently small that we can consider them to be vertical. Therefore \(y(x,t)\) describes the deflections.

Tension \(T(x)\) in the string, restoring forces horizontally and vertically:

The horizontal forces satisfy
\[
  T(x)\cos\theta_1 = T(x+\delta x)\cos\theta_2,\, |\theta_1|,|\theta_2| \ll 1,
\]
so
\[
T(\theta) \approx T(x+\delta x)
\]
so \(T\) is a constant.

We further assume that there is no horizontal motion and the mass of string per unit length is \(\mu\). The vertical force
\[
\mu\delta x \frac{\p^2 y}{\p t^2} = T\sin \theta_2 -T\sin\theta_1 - \mu g\delta x
\]
For small angles,
\begin{align*}
  \sin \theta_2 &\approx \tan\theta_2 = \frac{\p y}{\p x}\Big|_{x+\delta x} \approx \frac{\p y}{\p x}\Big|x + \delta x \frac{\p^2 y}{\p x^2}\Big|x \\
  \sin \theta_1 &\approx \tan\theta_1 = \frac{\p y}{\p x}\Big|_x
\end{align*}
so
\[
  \mu\delta x \frac{\p^2 y}{\p x^2} = T\delta x \frac{\p^2 y}{\p x^2} - \mu g\delta x + O(\delta x^2).
\]
We now assume that the weight of the string plays no role:
\[
  g\to 0 \text{ or } \frac{T\p^2 y}{\mu\p x^2} \gg g
\]
so
\[
  \frac{\p^2 y}{\p x^2} = \frac{T}{\mu} \frac{\p^2 y}{\p x^2} = c^2\frac{\p^2 y}{\p x^2}
\]

\subsection{Example: Wave on a Finite String}

We want to  find the displacement \(y(x,t)\) such that
\begin{align*}
  \frac{\p^2 y}{\p x^2} &= c^2 \frac{\p^2 y}{\p x^2} \\
  y(0,t) &= y(L,t) = 0 \\
  y(x,0) &= \phi(x) \\
  \frac{\p y(x,0)}{\p x} &= \psi(x)
\end{align*}

We use \emph{seperation of variables}. At its heart there is an existence and uniqueness proof. If we can find a solution by \emph{any means} it is the unique solution.

Suppose
\[
y(x,t) = X(x)T(t),
\]
substitute
\begin{align*}
  X \ddot{T} &= c^2X''T \\
  \frac{1}{c^2} \frac{\ddot{T}}{T} &= \frac{X''}{X} = -\lambda
\end{align*}
so we have two equations:
\begin{align*}
  X'' &= -\lambda X \\
  \ddot{T} &= -\lambda c^2 Y \\
  X(0) &= 0 \\
  X(L) &= L
\end{align*}
\(\lambda\geq0\) as otherwise \(X\) has at most \(1\) zero. Solve \(X\) to get
\[
  X = \alpha \cos \sqrt\lambda x + \beta \sin\sqrt\lambda x \\
\]
so
\[
  \lambda_n = \frac{n^2\pi^2}{L^2}, \, n \in \N.
\]
Note that these are real eigenvalues of the Sturm-Liouville system
\[
  -\frac{d}{dx} \big(\frac{dX}{dx} \big) = \lambda X.
\]
The associated eigenfunctions are the \emph{normal modes}:
\[
  X_n(x) = \beta_n \sin \frac{n\pi x}{L}.
\]
The lowest mode, i.e. \(n=1\), is the \emph{fundamental mode} while \(n=2,3,\dots\) are the \emph{overtones}.

Note how the eigenvalues \emph{quantise} the admissible solutions. For each of the \(X_n\) there is an associated \(T_n(t)\):
\[
  \ddot{T}_n = -\frac{n^2\pi^2c^2}{L^2}T_n
\]
which has solution
\[
  T_n = \gamma_n \cos \frac{n\pi ct}{L} + \delta_n \sin \frac{n\pi ct}{L}.
\]
Combining the two parts,
\[
  y_n(x,t) = X_n(x)T_n(t) = \sin \frac{n\pi x}{L} \Big( A_n \cos \frac{n\pi ct}{L} + B_n \sin \frac{n\pi ct}{L} \Big).
\]

The wave equation is linear so we can add all these solutions together
\begin{align*}
  y(x,t) &= \sum_{n=1}^{\infty} \sin \frac{n\pi x}{L} \Big( A_n \cos \frac{n\pi ct}{L} + B_n \sin \frac{n\pi ct}{L} \Big) \\
         &= \sum_{n=1}^{\infty} b_n(t) \sin \frac{n\pi x}{L}
\end{align*}
which is naturally a Fourier sine series. The \(A_n\) and \(B_n\) are determined from initial conditions:
\begin{align*}
  &y(x,0) = \phi(x) = \sum_{n=1}^{\infty} A_n \sin \frac{n\pi x}{L} \\
  \Rightarrow & A_n = \frac{2}{L} \int_{0}^{L} \phi(x) \sin \frac{n\pi x}{L} dx \\
  & \frac{\p y(x,0)}{\p t} = \psi(x) = \sum_{n=1}^{\infty} \frac{n\pi cB_n}{L} \sin \frac{n\pi x}{L} \\
  \Rightarrow & B_n = \frac{2}{n\pi c} \int_{0}^{L} \psi(x) \sin \frac{n\pi x}{L} dx
\end{align*}

\subsection{Algorithm for Seperation of Variables}

The algorithm for seperation of variables is clear:
\begin{enumerate}
\item seperate the variables: write \(y(x,t)=X(x)T(t)\),
\item determine the admissable form for eigenvalues and associated eigenfunctions from boundary conditions (i.e. conditions on \(x\)),
\item determine the form of the other seperated function using the eigenvalues and find a particular set of solution \(y_n\),
\item sum over all \(y_n\) to form a series representation,
\item determine the coefficients from the initial condititions (i.e. conditions on \(t\)).
\end{enumerate}

\begin{ex}
  Determine the full solution for a plucked string
  \[
    \psi(x) =0, \phi(z) =
    \begin{cases}
      \phi_0\frac{x}{d} & 0 \leq x \leq d \\
      \phi_0\frac{L-x}{L-d} & d \leq x \leq L
    \end{cases}
  \]
\end{ex}

\section{Bessel's Equation}

\subsection{Derivation of Bessel's Equation}

\label{subsec:derivation of Bessel}

Consider the wave equation on the unit disc
\[
  \frac{\partial^2 u}{\partial t^2} = c^2 \frac{\partial^2 u}{\partial x^2} + c^2 \frac{\partial^2 u}{\partial y^2} = c^2\nabla^2u, \, x^2+y^2\leq 1
\]
As usual, use seperation of varaibles:
\begin{enumerate}%remove
\item \(u(x,y,t) = V(x,y)T(t)\), \(\ddot T = -\lambda c^2T, \nabla^2V = -\lambda V\) with \(\lambda \geq 0\), since we are in the unit disc,
  \[
    V(x,y) = R(r) \Theta(\theta)
  \]
  so
  \begin{align*}
    \frac{\partial^2 V}{\partial r^2} + \frac{1}{r^2} \frac{\partial^2 V}{\partial \theta^2} + \frac{1}{r}\frac{\partial V}{\partial r} + \lambda V &= 0 \\
    R''\Theta + \frac{1}{r^2} R\Theta'' + \frac{1}{r}R'\Theta+\lambda R\theta &= 0 \\
    r^2R''\Theta+rR'\Theta+\lambda r^2R\Theta &= -R\Theta''
  \end{align*}
  Divide by \(R\Theta\), we get
  \[
    f_2(r) = f_1(\theta) = \mu
  \]
  Due to circular gemoetry \(\Theta\) must be periodic with period \(2\pi\). Thus \(\mu = m^2\), where \(m\) is an integer. This implies that
  \[
    r^2R'' + rR' + (\lambda r^2-m^2)R = 0.
  \]
  Now dividing across by \(-r\) to put this in Sturm-Liouville form:
  \[
    -\frac{d}{dr}\big( r \frac{d R}{d r} \big) + \frac{m^2}{r}R = \lambda r R, \, r\leq 1
  \]
  which has non-trivial weigtht. Furthermore let \(z = \sqrt\lambda r\) this can be reposed as
  \[
    z^2 \frac{d^2 R}{dz^2} + z \frac{d R}{d z} + (z^2-m^2)R = 0.
  \]
  This is \emph{Bessel's equation}.
\end{enumerate}

Solution to this equation are called \emph{Bessel functions of the first kind and second kind}.

\subsection{Properties of Bessel Functions}

\begin{enumerate}
\item \(J_m(z)\), the Bessel function of the frist kind of order \(m\) which is regular at the origin (and is \(0\) there for \(m>0\)) \(m=0\) for axis symmetric solution (i.e. solutions independent of \(\Theta\)).
\item \(Y_m(z)\) the Bessel function of the second kind which are singular at the origin.\footnote{Note \(Y_m(z)\) here is \emph{not} orthonormal.} Sometimes called Neumann function \(N_m\) or Weber function.
\end{enumerate}
    
Some properities of the Bessel functions include:

\begin{itemize}
\item \(J_\nu(z)\) has a series expansion (\(\nu\) not an integer in general):
  \[
    J_\nu(z) = \Big( \frac{z}{2} \Big)^\nu \sum_{n=0}^{\infty} \frac{(-z^2/4)^k}{k!\Gamma(\nu+k+1)}
  \]
  where \(\Gamma\) is the Gamma function.

\item \(J_\nu\) and \(J_{-\nu}\) are linearly independent for non-integer \(\nu\).
\item \(Y_\nu(z)\) is defined by
  \[
    \frac{J_\nu(z)\cos\nu\pi - J_{-\nu}(z)}{\sin\nu\pi}.
  \]

\item For integer \(\nu=m\):
  \begin{align*}
    J_{-m}(z) &= (-1)^m J_m(z) \\
    Y_{-m}(z) &= (-1)^m Y_m(z) \\
    Y_m(z) &= \lim_{\nu\to m} \frac{J_\nu(z)\cos\nu\pi - J_{-\nu}}{\sin \nu\pi}.
  \end{align*}
\item \(Y_0(z) \approx \frac{2}{\pi} \log z, \, J_0\approx 1 \text{ as } z\to 0 \).
\item \(Y_m(z) \approx - \frac{1}{\pi} \Big( \frac{2}{\pi} \Big)^{-m} (m-1)!,\, J_m \approx \frac{(z/2)^m}{m!} \to 0\) for \(m>0\).
\item As \(z\to \infty\),
  \begin{align*}
    J_\nu(z) &= \Big( \frac{2}{\pi z} \Big)^{1/2} \cos \Big(z - \frac{i\pi}{2} - \frac{\pi}{4} \Big) + \bigO(z^{-3/2}) \\
    Y_\nu(z) &= \Big( \frac{2}{\pi z} \Big)^{1/2} \sin \Big(z - \frac{i\pi}{2} - \frac{\pi}{4} \Big) + \bigO(z^{-3/2})
  \end{align*}
\end{itemize}

\subsection{Application to a Simple Drum Problem}

From the problem in Section~\ref{subsec:derivation of Bessel} it is clear \(J_m(\sqrt{\lambda_{mn}}r)\) and \(Y_m(\sqrt{\lambda_{mn}}r)\) are appropriate eigenfunctions for \(R(r)\) in Bessel's equation.

To solve a problem we need boundary conditions. Let use consider
\[
  \frac{\partial^2 u}{\partial t^2} = c^2\nabla^2u \text{ on } r\leq1
\]
such that \(u=0\) when \(r=1\) and \(u\) is finite when \(r=0\). Thus the solution cannot be \(Y_m\).

The eigenvalues \(\lambda_{mn}\) are solutions of \(J_m(\sqrt{\lambda_{mn}})=0\) there is clearly a countably infinite number such that
\[
  0 < \lambda_{m1} < \lambda_{m2} < \dots < \lambda_{mn} = j_{mn}^2
\]
so the general form for the spherically varying part:
\[
  V(r_1\theta) = V_{mn}(r,\theta) = J_n(j_{mn}r) (A_n\cos n\theta + B_n \sin n\theta)
\]
so we can see that the general solution is
\begin{align*}
  u(r,\theta,t) &= \sum_{n=1}^{\infty}J_0(j_{0n}r) (A_{0n}\cos j_{0n}ct + B_{0n}\sin j_{0n}ct) \\
                &+ \sum_{m=1}^{\infty} \sum_{n=1}^{\infty} J_m(j_{mn}r) (A_{mn}\cos m\theta + B_{mn} \sin m\theta ) \cos j_{mn}ct \\
                &+ \sum_{m=1}^{\infty} \sum_{n=1}^{\infty}J_m(j_{mn}r) (A_{mn}\cos m\theta + B_{mn} \sin m\theta ) \sin j_{mn}ct
\end{align*}

The orthogonality condition for Bessel functions is
\[
  \int_{0}^{1} J_k(j_{kn}r)J_k(j_{km}r)r dr = \frac{1}{2} \big(J_k'(j_{kn}) \big)^2 \delta_{mn} = \frac{1}{2} \big( J_{k+1}(j_{kn}) \big)^2 \delta_{mn}
\]
and so all the coefficients can be determined using orthogonality of sinces, cosines and Bessel functions.

\section{Wave Property}

Let us return to the Cartesian problem of wave equation
\[
  \frac{\partial^2 y}{\partial t^2} = c^2 \frac{\partial^2 y}{\partial x^2}, \, y(0,t) = y(L,t) = 0, \, y(x,0) = \phi(x), \, \frac{\partial y(x,0)}{\partial t} = \psi(x)
\]
which has general solution
\[
  y(x,t) = \sum_{n=1}^{\infty} \Big( a_n \cos \frac{n\pi ct}{L} + b_n \sin \frac{n\pi ct}{L} \Big) \sin \frac{n\pi x}{L}
\]
where
\begin{align*}
  a_n &= \frac{2}{L} \int_{0}^{L} \phi(x)\sin\frac{n\pi x}{L} dx \\
  b_n &= \frac{2}{n\pi c} \int_{0}^{L} \psi(x)\sin \frac{n\pi x}{L} dx
\end{align*}

\subsection{Wave Energy}

Suppose the mass per unit length is \(\mu\). The total kinetic energy is thus
\[
  K = \int_{0}^{L} \frac{1}{2} \mu \Big(\frac{\partial y}{\partial t} \Big)^2 dx
\]
The potential energy is \(T \times \text{extenstion} = T(\delta s - \delta x)\) which equals to
\[
  T \Bigg(\sqrt{1+ \Big( \frac{\partial y}{\partial x} \Big)^2} -1 \Bigg) \delta x.
\]
Thus the total potential energy is
\begin{align*}
  V &= T \int_{0}^{L} \sqrt{1+ \Big( \frac{\partial y}{\partial x}^2 \Big)} -1 dx \\
    &\approx \frac{T}{2} \int_{0}^{L} \Big(\frac{\partial y}{\partial x} \Big)^2 dx
\end{align*}
using a binomial expansion and noting that since \(\partial y /\partial x\) is small
\[
  \Big(\frac{\partial y}{\partial x} \Big)^4 \ll \Big(\frac{\partial y}{\partial x} \Big)^2
\]
Thus the total energy is
\[
  E = K + V = \frac{\mu}{2} \int_{0}^{L} \Big( \frac{\partial y}{\partial t} \Big)^2 + c^2 \Big( \frac{\partial y}{\partial x} \Big)^2 dx
\]
The solution is
\begin{align*}
  \frac{\partial y}{\partial t} &= \sum_{n=1}^{\infty} \frac{n\pi c}{L} \Big( b_n \cos \frac{n\pi ct}{L} - a_n \sin \frac{n\pi ct}{L} \Big) \sin \frac{n\pi x}{L} \\
  \frac{\partial y}{\partial x} &= \sum_{n=1}^{\infty} \frac{n\pi }{L} \Big( a_n \sin \frac{n\pi ct}{L} + b_n \cos \frac{n\pi ct}{L} \Big) \cos \frac{n\pi x}{L} \\ 
  K &= \frac{\mu}{2} \int_{0}^{L} \sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \sin \frac{n\pi x}{L } \sin \frac{m\pi x}{L } \\
                                &\times \Big[ \frac{n\pi c}{L} \Big( b_n \cos \frac{n\pi ct}{L} - a_n \sin \frac{n\pi ct}{L} \Big) \Big] \\
                                &\times \Big[ \frac{m\pi c}{L} \Big( b_m \cos \frac{m\pi ct}{L} - a_m \sin \frac{m\pi ct}{L} \Big) \Big] dx\\
                                &= \frac{\mu L}{4} \sum_{n=1}^{\infty} \frac{n^2\pi^2c^2}{L^2} \Big( a_n^2 \sin^2 \frac{n\pi ct}{L} +b_n^2 \cos^2 \frac{n\pi ct}{L} \\
                                & \quad -2a_nb_n \cos \frac{n\pi ct}{L} \sin \frac{n\pi ct}{L} \Big) \\
  V &= \frac{TL}{4} \sum_{n=1}^{\infty} \frac{n^2\pi^2}{L^2} \Big( a_n^2 \cos^2 \frac{n\pi ct}{L} + b_n^2\sin^2 \frac{n\pi ct}{L} \\
                                & \quad +2a_nb_n \sin \frac{n\pi ct}{L} \cos \frac{n\pi ct}{L} \Big)
\end{align*}

Since \(T^2 = \mu c^2\), these expression yield
\[
  E = \frac{\mu c^2\pi^2}{4L} \sum_{n=1}^{\infty} n^2(a_n^2+b_n^2)
\]
which is, surpringly (assuming you don't have trust in physicists), independent of time.

The period of oscillation is \(\frac{2\pi}{\omega} = \frac{2\pi L}{\pi c} =\frac{2L}{c}\) so the average kinetic energy over a period is
\[
  \overline K = \frac{c}{2L} \int_{0}^{2L/c} K dt = \frac{\mu L}{4} \sum_{n=1}^{\infty} \frac{n^2\pi^2c^2}{L^2} \Big( \frac{a_n^2}{2} + \frac{b_n^2}{2} \Big) = \frac{E}{2}
\]
similarly
\[
  \overline V = \frac{c}{2L} \int_{0}^{2L/c} V dt = \frac{E}{2}
\]
i.e. over a period there is an equipartition between kinetic and potential energy.

\subsection{Reflection and Transmission}

If the medium through which the waves are travelling has different properties then the properties of the waves will change and there may be \emph{reflections} and \emph{transmissions}.

Consider a string with mass per unit length
\[
  \mu =
  \begin{cases}
    \mu_- & x< 0 \\
    \mu_+ & x>0
  \end{cases}
\]
The horizontal forces between is still horizontal. Wave speed on either side of \(x=0\) is
\[
  c_\pm = \sqrt{\frac{\tau}{\mu_\pm}}.
\]

The incident wave
\begin{align*}
  w_I &= \Re \Bigg(I \exp \Big( i\omega \Big(t- \frac{x}{c_-} \Big) \Big) \Bigg) \\
      &= I_r \cos \omega \Big(t - \frac{x}{c_-} \Big) - I_i \sin\omega \Big(t- \frac{x}{c_-} \Big) \\
      &= A_I \sin \Big(\omega \Big(t-\frac{x}{c_-} \Big) + \phi_I\Big)
\end{align*}
where \(I = I_r + i I_i\) and we define amplitude
\[
  A_I = \sqrt{I_r^2+I_i^2} = |I| 
\]
and phase
\[
  \phi_I = \arccos \frac{I_r}{|I|} = \arcsin \frac{I_i}{|I|}
\]
Similarly the transmitted wave is
\[
  w_T = \Re \Bigg(T \exp \Big(i\omega \Big(t- \frac{x}{c_+} \Big)\Big)\Bigg)
\]
and the reflected wave is
\[
  w_R = \Re \Bigg(R\exp\Big(i\omega\Big(t+ \frac{x}{c_-}\Big)\Big)\Bigg)
\]
notice the plus sign.

We determine the coefficients by matching conditions at the origin. The displacement at \(x=0\) must be continuous for all time:
\begin{align*}
  w_I\big|_{x=0^-} + w_R\big|_{x=0^-} = w_T\big|_{x=0^+} \\
  \Re \Big(I \exp(i\omega_-t \Big) + R \exp(i\omega_-t) \Big) &= \Re (T\exp(i\omega_+t))
\end{align*}
Thus \(\omega_- = \omega_+\). Also
\begin{align*}
  I + R &= T \\
  I_r + R_r &= T_r \\
  I_i + R_i &= T_i
\end{align*}
i.e. coefficients of cosines and sines are the same.

In the absence of inertia at \(x=0\), the vertical forces are continuous
\[
  \tau \frac{\partial y}{\partial x}\Big|_{x=0^-} = \tau \frac{\partial y}{\partial x}\Big|_{x=0^+}
\]
so
\begin{align*}
  \frac{R}{c_-} - \frac{I}{c_-} &= - \frac{T}{c_+} \\
  \frac{R_r}{c_-} - \frac{I_r}{c_-} &= - \frac{T_r}{c_+} \\
  \frac{R_i}{c_-} - \frac{I_i}{c_-} &= - \frac{T_i}{c_+} \\
\end{align*}
Solve to get
\begin{align*}
  R &= \Big( \frac{c_+-c_-}{c_++c_-} \Big) I \\
  T &= \Big( \frac{2c_+}{c_++c_-} \Big) I
\end{align*}
\end{document}