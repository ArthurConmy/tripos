\documentclass[a4paper]{article}

\def\npart{II}

\def\ntitle{Logic and Set Theory}
\def\nlecturer{I.\ B.\ Leader}

\def\nterm{Lent}
\def\nyear{2018}

\input{header}

\DeclareMathOperator{\dom}{dom}%domain of a function
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\card}{card}

\newcommand*{\biject}{\leftrightarrow}

\begin{document}

\input{titlepage}

\tableofcontents

\section{Propositional Logic}

Let \(P\) be a set of \emph{primitive propositions}. Unless otherwise stated, \(P = \{p_1, p_2, \dots \}\).

\begin{definition}[Language]\index{language}
  The \emph{language} or \emph{set of propositions} \(L = L(P)\) is defined inductively by
  \begin{enumerate}
  \item for every \( p \in P\), \(p \in L\),
  \item \(\bot \in L\) (reads ``false''),
  \item if \(p, q \in L\) then \((p \implies q) \in L\).
  \end{enumerate}
\end{definition}

\begin{eg}
  \((p_1 \implies \bot)\), \(((p_1 \implies p_2) \implies (p_1 \implies p_3))\), \(((p_1 \implies \bot) \implies \bot)\) are elements of \(L\).
\end{eg}

\begin{note}\leavevmode
  \begin{enumerate}
  \item Each proposition is a finite string of symbols from the alphabet \((, ), \implies, p_1, p_2, \dots\).
  \item ``Inductively defined'' means more precisely that we set
    \begin{align*}
      L_1 &= P \cup \{\bot\} \\
      L_{n + 1} &= L_n \cup \{(p \implies q): p, q \in L_n\}
    \end{align*}
    and then set \(L = L_1 \cup L_2 \cup \dots\). \(L_n\) can be seen as ``things born by time \(n\)''.
  \item Each proposition is built up \emph{uniquely} from (1), (2) and (3). For example, \(((p_1 \implies p_2) \implies (p_1 \implies p_3))\) came from \((p_1 \implies p_2)\) and \((p_1 \implies p_3)\).
  \end{enumerate}
\end{note}

Note that we often omit outer brackets or use different brackets for clarity.

We can now define for example, \(\neg p\) (reads ``not \(p\)'') as an abbreviation for \(p \implies \bot\), \(p \lor q\) (reads ``\(p\) or \(q\)'') for \((\neg p) \implies q\), \(p \land q\) (reads ``\(p\) and \(q\)'') for \(\neg (p \implies (\neg q))\).

\subsection{Semantic Entailment}

\begin{definition}[Valuation]\index{valuation}
  A \emph{valuation} is a function \(v: L \to \{0, 1\}\) such that
  \begin{enumerate}
  \item \(v(\bot) = 0\),
  \item \(v(p \implies q) = \begin{cases} 0 & \text{if } v(p) = 1, v(q) = 0 \\ 1 & \text{otherwise} \end{cases}\) for all \(p, q \in L\).
  \end{enumerate}
\end{definition}

\begin{remark}
  On \(\{0, 1\}\), we could define a constant \(\bot\) by \(\bot = 0\) and an operation \(\implies\) by
  \[
    (a \implies b) =
    \begin{cases}
      0 & \text{if } a = 1, b = 0 \\
      1 & \text{otherwise}
    \end{cases}
  \]
  Then a valuation is a function \(L \to \{0, 1\}\) that preserves the structure (\(\bot\) and \(\implies\)), i.e.\ it is a homomorphism.
\end{remark}

\begin{proposition}\leavevmode
  \begin{enumerate}
  \item If \(v\) and \(v'\) are valuations with \(v(p) = v'(p)\) for all \(p \in P\), then \(v = v'\).
  \item For any \(w: P \to \{0, 1\}\), there exists a valuation \(v\) with \(v(p) = w(p)\) for all \(p \in P\).
  \end{enumerate}
\end{proposition}

In other words, a valuation is determined by its values on \(P\) and any values will do.

\begin{proof}\leavevmode
  \begin{enumerate}
  \item We have for all \(p \in L_1\), \(v(p) = v'(p)\). But if \(v(p) = v'(p)\) and \(v(q) = v'(q)\) then \(v(p \implies q) = v'(p \implies q)\) so \(v = v'\) on \(L_2\). Continue inductively, we have \(v = v'\) on \(L_n\) for all \(n\).
  \item Set \(v(p) = w(p)\) for all \(p \in P\) and \(v(\bot) = 0\). This defines \(v\) on \(L_1\). Having defined \(v\) on \(L_2\), use \(v(p \implies q) = \begin{cases} 0 & \text{if } v(p) = 1, v(q) = 0 \\ 1 & \text{otherwise} \end{cases}\) to define \(v\) on \(L_{n + 1}\).
  \end{enumerate}
\end{proof}

\begin{eg}
  In a valuation given by
  \begin{align*}
    v(p_1) &= 1 \\
    v(p_2) &= 1 \\
    v(p_n) &= 0 \text{ for all } n \geq 3
  \end{align*}
  we have \(v(\underbrace{(p_1 \implies p_2)}_{1} \implies \underbrace{p_3}_{0}) = 0\).
\end{eg}

\begin{definition}[Tautology]\index{tautology}
  \(p\) is a \emph{tautology}, written \(\models p\) if \(v(p) = 1\) for all valuations \(v\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(p \implies (q \implies p)\). ``A true statement is implied by anything''. To show this we could write donw a truth table
    \begin{table}[h]
      \centering
      \begin{tabular}{c|c|c|c}
        \(v(p)\) & \(v(q)\) & \(v(q \implies p)\) & \(v(p \implies (q \implies p))\) \\\hline
        1 & 1 & 1 & 1 \\
        1 & 0 & 1 & 1 \\
        0 & 1 & 0 & 1 \\
        0 & 0 & 1 & 1
      \end{tabular}
    \end{table}
  \item \((\neg \neg p) \implies p\), i.e.\ \(((p \implies \bot) \implies \bot) \implies p\). ``Law of excluded middle''.
  \item \((p \implies (q \implies r)) \implies ((p \implies q) \implies (p \implies r))\). This is an example where writing down a truth table is not so desirable. Instead, this is not a tautology only if we have \(v\) with
    \begin{align*}
      v(p \implies (q\implies r)) &= 1 \\
      v((p \implies q) \implies (p \implies r)) &= 0
    \end{align*}
    so \(v(p \implies q) = 1, v(p \implies r) = 0\) whence \(v(p) = 1, v(r) = 0\), so also \(v(q) = 1\). But then \(v(q \implies r) = 0\) so \(v(p \implies (q \implies r)) = 0\). Absurd.
  \end{enumerate}
\end{eg}

\begin{definition}[Semantic entailment]\index{semantic entailment}
  For \(S \subseteq L, t \in L\), we say \(S\) \emph{entails} or \emph{semantically implies} \(t\), written \(S \models t\), if \(v(s) = 1\) for all \(s \in S\) then \(v(t) = 1\) for each valuation \(v\).
\end{definition}

This says whenever all of \(S\) is true, \(t\) is true as well.

\begin{eg}
  \(\{p \implies q, q \implies r\} \models (p \implies r)\). Indeed, suppose not. So have \(v\) with \(v(p \implies q) = v(q \implies r) = 1, v(p \implies r) = 0\). Then \(v(p) = 1, v(r) = 0\), whence \(v(q) = 0\) (from \(v(q \implies r) = 1\)), so \(v(p \implies q) = 0\). Absurd.
\end{eg}

\begin{definition}[Model]\index{model}
  If \(v(t) = 1\), we say \(t\) is \emph{true in \(v\)} or that \(v\) is a \emph{model} of \(t\).

  For \(S \subseteq L\), \(v\) is a \emph{model} of \(S\) if \(v(s) = 1\) for all \(s \in S\).
\end{definition}

Using this terminology, \(S \models t\) says that every model of \(S\) is a model of \(t\).

\begin{note}
  \(\models t\) is equivalent to \(\emptyset \models t\).
\end{note}

\subsection{Syntactic Implication}

For a notion of ``proof'', we'll need axioms and deduction rules. As axioms, we'll take
\begin{enumerate}
\item \(p \implies (q \implies p)\) for all \(p, q \in L\).
\item \((p \implies (q \implies r)) \implies ((p \implies q) \implies (p \implies r))\) for all \(p, q, r \in L\).
\item \((\neg \neg p) \implies p\) for all \(p \in L\).
\end{enumerate}

\begin{note}
  We have already checked that these are all tautologies. Sometimes we say 3 axiom schemes to mean 3 infinite sets of axioms.
\end{note}

As deduction rules, we'll take just \emph{modus ponens}\index{modus ponens}: from \(p\) and \((p \implies q)\) we can deduce \(q\).

\begin{definition}[Proof]\index{proof}\index{hypothesis}\index{premise}\index{conclusion}
  For \(S \subseteq L\) and \(t \in L\), a \emph{proof} of \(t\) from \(S\) consists of a finite sequence \(t_1, \dots, t_n\) of propositions, with \(t_n = t\) such that for every \(i\), the proposition \(t_i\) is an axiom, or a member of \(S\), or there exists \(j, k < i\) with \(t_j = (t_k \implies t_i)\).

  We say \(S\) is the \emph{hypotheses} or \emph{premises} and \(t\) is the \emph{conclusion}.
\end{definition}

\begin{definition}[Syntactical implication]\index{syntactical implication}
  If there is a proof of \(t\) from \(S\), say \(S\) \emph{proves} or \emph{syntactically implies} \(t\), written \(S \yields t\).
\end{definition}

\begin{definition}[Theorem]\index{theorem}
  \(t\) is a \emph{theorem} if \(\emptyset \yields t\), written \(\yields t\).
\end{definition}

\begin{eg}
  \(\{p \implies q, q \implies r\} \yields p \implies r\)
  \begin{enumerate}
  \item \((q \implies r) \implies (p \implies (q \implies r))\), A1
  \item \(q \implies r\), hypothesis
  \item \(p \implies (q \implies r)\), MP
  \item \((p \implies (q \implies r)) \implies ((p \implies q) \implies (p \implies r))\), A2
  \item \((p \implies q) \implies (p \implies r)\), MP
  \item \(p \implies q\), hypothesis
  \item \(p \implies r\), MP
  \end{enumerate}
\end{eg}

\begin{eg}
  \(\yields p \implies p\)
  \begin{enumerate}
  \item \(p \implies ((p \implies p) \implies p)\), A1
  \item \((p \implies ((p \implies p) \implies p)) \implies ((p \implies (p \implies p)) \implies (p \implies p))\), A2
  \item \((p \implies (p \implies p)) \implies (p \implies p)\), MP
  \item \(p \implies (p \implies p)\), A1
  \item \(p \implies p\), MP
  \end{enumerate}
\end{eg}

The following theorem allows us to prove things much more easily:

\begin{theorem}[Deduction theorem]\index{deduction theorem}
  Let \(S \subseteq L\) and \(p, q \in L\). Then \(S \yields p \implies q\) if and only if \(S \cup \{p\} \yields q\).
\end{theorem}

\begin{proof}\leavevmode
  \begin{itemize}
  \item \(\impliedby\): Given a proof of \(p \implies q\) from \(S\), append the lines
    \begin{enumerate}
    \item \(p\), hypothesis
    \item \(q\), MP
    \end{enumerate}
    to obtain a proof of \(q\) from \(S \cup \{p\}\).
  \item \(\implies\): Let \(t_1, \dots, t_n = q\) be a proof of \(q\) from \(S \cup \{p\}\). We'll show that \(S \yields p \implies t_i\) for all \(i\). Split into cases
    \begin{itemize}
    \item \(t_i\) is an axiom: write down
      \begin{enumerate}
      \item \(t_i \implies (p \implies t_i)\), A1
      \item \(t_i\), axiom
      \item \(p \implies t_i\), MP
      \end{enumerate}
    \item \(t_i \in S\): identical as above.
    \item \(t_i = p\): write down the proof \(p \implies p\).
    \item \(t_i\) is obtained by MP: there exist \(j, k < i\) such that \(t_k = (t_j \implies t_i)\). By induction \(S \yields p \implies t_j\) and \(S \yields p \implies t_k\). Now write down
      \begin{enumerate}
      \item \((p \implies (t_j \implies t_i)) \implies ((p \implies t_j) \implies (t \implies t_i))\), A1
      \item \(p \implies (t_j \implies t_i)\), known
      \item \((p \implies t_j) \implies (p \implies t_i)\), MP
      \item \(p \implies t_j\), known
      \item \(p \implies t_i\), MP
      \end{enumerate}
    \end{itemize}
    and we can conclude \(S \yields p \implies t_i\) for all \(i\).
  \end{itemize}
\end{proof}

\begin{eg}
  In order to show \(\{p \implies q, q \implies r\} \yields p \implies r\), it suffices to show \(\{p \implies q, q \implies r, p\} \yields r\) by deduction theorem, which is easy by using MP twice.
\end{eg}

Now we have two turnstiles \(\models\) and \(\yields\), how are they related? The aim of the rest of the chapter is to prove

\begin{theorem}[Completeness theorem]
  \(S \models t\) if and only if \(S \yields t\).
\end{theorem}

We break this down into two directions:
\begin{itemize}
\item \(\implies\): adequacy
\item \(\impliedby\): soundness
\end{itemize}

The easy part is

\begin{proposition}[Soundness]\index{soundness}
  If \(S \yields t\) then \(S \models t\).
\end{proposition}

\begin{proof}
  Given \(v\) that models \(S\) and a proof \(t_1, \dots, t_n = t\) of \(S \yields t\), we will show that \(v(t_i) = 1\) for all \(i\).

  If \(t_i\) is an axiom then \(v(t_i) = 1\) since it is tautology. If \(t_i\) is a hypothesis then \(v(t_i) = 1\) by assumption. Finally, if \(t_i\) is obtained by MP, say from \(t_j \implies t_i\), since \(v(t_j) = 1\) and \(v(t_j \implies t_i) = 1\) by induction, \(v(t_i) = 1\).
\end{proof}

Note that soundness holds whenever our axioms are tautologies.

To prove adequacy, which is a bit harder, we need a few lemmas.

\begin{definition}[Consistency]\index{consistency}
  \(S\) is \emph{inconsistent} if \(S \yields \bot\). Otherwise \(S\) is \emph{consistent}.
\end{definition}

\begin{theorem}[Model existence lemma]\index{model existence lemma}
  Let \(S \subseteq L\) be consistent, then \(S\) has a model.
\end{theorem}

The first idea is to define a valuation \(v\) by \(v(p) = 1\) if and only if \(p \in S\). As \(1\) is preserved under \(\models\) and thus \(\yields\), a more sensible aim is \(v(p) = 1\) if and only if \(S \yields p\).

But maybe neither \(S \yields p\) nor \(S \yields \neg p\). So we want to ``grow'' \(S\) to contain one of \(p\) or \(\neg p\) for each \(p \in L\) (while remaining consistent).

\begin{proof}
  Claim that for any consistent \(S \subseteq L\), \(S \cup \{p\}\) or \(S \cup \{\neg p\}\) is consistent: if not, then \(S \cup \{p\} \yields \bot\) and \(S \cup \{\neg p\} \yields \bot\). But then \(S \yields (p \implies \bot)\) by deduction theorem, i.e.\ \(S \yields \neg p\). Then \(S \yields \bot\). Absurd.

  Now as \(L\) is countable, we can list \(L\) as \(t_1, t_2, \dots \). Put \(S_0 = S\). Set \(S_1 = S_0 \cup \{t_1\}\) or \(S_0 \cup \{\neg t_1\}\) such that \(S_1\) is consistent. Then let \(S_2 = S_1 \cup \{t_2\}\) or \(S_1 \cup \{\neg t_2\}\) such that \(S_2\) is consistent and continue inductively. Let \(\cl S = S_0 \cup S_1 \cup \dots\). Then \(\cl S \supseteq S\) and \(\cl S\) is consistent (as each \(S_n\) is consistent and proofs are finite). For all \(p \in L\) either we have \(p \in \cl S\) or \(\neg p \in \cl S\). Also \(\cl S\) is \emph{deductively closed}, meaning that if \(\cl S \yields p\) then \(p \in \cl S\). Indeed if \(p \notin \cl S\) then \(\neg p \in \cl S\), so \(\cl S \yields p, \cl S \yields (\neg p)\), whence \(\cl S \yields \bot\). Absurd.

  Define a valuation
  \begin{align*}
    v: L &\to \{0, 1\} \\
    p &\mapsto
        \begin{cases}
          1 & p \in \cl S \\
          0 & \text{otherwise}
        \end{cases}
  \end{align*}
  Indeed, \(v(\bot) = 0\) as \(\bot \notin \cl S\). For \(v(p \implies q)\):
  \begin{itemize}
  \item if \(v(p) = 1, v(q) = 0\), we have \(p \in \cl S, q \notin \cl S\), and we want \(v(p \implies q) = 0\), i.e.\ \((p \implies q) \notin \cl S\). But if \((p \implies q) \in \cl S\) then \(\cl S \yields q\), \(q \in \cl S\). Absurd.
  \item if \(v(q) = 1\), we have \(q \in \cl S\), and we want \(v(p \implies q) = 1\), i.e.\ \((p \implies q) \in \cl S\). But \(\yields q \implies (p \implies q)\) so \(\cl S \yields (p \implies q)\).
  \item if \(v(p) = 0\), we have \(p \notin \cl S\). Then \((\neg p) \in \cl S\). We want \((p \implies q) \in \cl S\). Thus we need \((p \implies \bot) \yields (p \implies q)\), which by deduction theorem is equivalent to \(\{p \implies \bot, p\} \yields q\). Thus suffices to show that \(\bot \yields q\). But we have \(\yields (\neg \neg q) \implies q\), and \(\yields (\bot \implies (\neg \neg q))\). Thus \(\yields (\bot \implies q)\), i.e.\ \(\bot \yields q\). Done.
  \end{itemize}
\end{proof}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item Sometimes this is called completeness theorem as it contains the majority of the work.
  \item What would happen if \(P\) is uncountable? In fact, the result still holds. See chapter 3.
  \end{enumerate}
\end{remark}

By remark before the above theorem, we now have

\begin{corollary}[Adequacy]\index{adequacy}
  Let \(S \subseteq L, t \in L\). Then if \(S \models t\) then \(S \yields t\).
\end{corollary}

\begin{theorem}[Completeness theorem]\index{completeness theorem}
  Let \(S \subseteq L, t \in L\). Then \(S \yields t\) if and only if \(S \models t\).
\end{theorem}

\begin{proof}
  By soundness and adequacy.
\end{proof}

Some consequences:

\begin{corollary}[Compactness theorem]\index{compactness theorem}
  Let \(S \subseteq L, t \in L\) with \(S \models t\). Then there exists a finite \(S' \subseteq S\) with \(S' \models t\).
\end{corollary}

\begin{proof}
  Trivial if we replace \(\models\) with \(\yields\) as proofs are finite.
\end{proof}

Specialising to \(t = \bot\), this theorem says that if \(S\) has no model then some finite \(S' \subseteq S\) has no model. Equivalently,

\begin{corollary}[Compactness theorem, equivalent form]
  Let \(S \subseteq L\). If every finite finite subset of \(S\) has a model then \(S\) has a model.
\end{corollary}

\begin{proof}
  This is equivalent to the previous corollary because \(S \models t\) if and only if \(S \cup \{\neg t\}\) has no model and \(S' \models t\) if and only if \(S' \cup \{\neg t\}\) has no model.
\end{proof}

\begin{corollary}[Decidability theorem]\index{decidability theorem}
  There is an algorithm to determine (in finite time) whether or not, for a given \(S \subseteq L, t\in L\), we have \(S \yields t\).
\end{corollary}

\begin{remark}
  Highly non-obvious.
\end{remark}

\begin{proof}
  Trivial to decide if \(S \models t\), just by drawing a truth table.
\end{proof}

\section{Well-orderings and Ordinals}

\subsection{Definitions}

\begin{definition}[Total order]\index{total order}
  A \emph{total order} or \emph{linear order} on a set \(X\) is a relation \(<\) on \(X\) that is
  \begin{enumerate}
  \item irreflexive: for all \(x\), not \(x < x\),
  \item transitive: for all \(x, y, z\), \(x < y, y < z\) implies \(x < z\),
  \item trichotomous: for all  \(x, y\), \(x < y, x = y\) or \(y < x\).
  \end{enumerate}
\end{definition}

\begin{note}
  Any two of 3 cannot hold: if \(x < y, y < x\) then \(x < x\), absurd.
\end{note}

\begin{notation}
  We write \(x \leq y\) if \(x < y\) or \(x = y\). Write \(y > x\) if \(x < y\) etc.

  In terms of \(\leq\), a total order is
  \begin{enumerate}
  \item reflexive: for all \(x\), \(x \leq x\),
  \item transitive: for all \(x, y, z\), \(x \leq y, y \leq z\) implies \(x \leq z\),
  \item antisymmetric: for all \(x, y\), \(x \leq y, y \leq x\) implies \(x = y\),
  \item trichotomous: for all \(x, y\), \(x \leq y\) or \(y \leq x\).
  \end{enumerate}
\end{notation}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(\N\) with usual order\footnote{In this course \(0 \in \N\). Write \(\N^+\) for \(\N \setminus \{0\}\).}.
  \item \(\Q\) and \(\R\) with usual order.
  \item \(\N^+\) with divisibility is \emph{not} a total order as for example, \(2\) and \(3\) are not related.
  \item Given a set \(S\), the power set \(\powerset(S)\) with \(x \leq y\) if \(x \subseteq y\) is \emph{not} a total order for \(|S| > 1\).
  \end{enumerate}
\end{eg}

\begin{definition}[Well-ordering]\index{well-ordering}
  A total order is a \emph{well-ordering} if every non-empty subset has a least element: for all \(S \subseteq X\), if \(X \neq \emptyset\) then exists \(x \in S\) such that \(x \leq y\) for all \(y \in S\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(\N\) with usual order.
  \item \(\Z\) with usual order is \emph{not} a well-ordering. Similar for \(\Q\) and \(\R\).
  \item \(\{x \in \Q: x \geq 0\}\) is \emph{not} a well-ordering. For example, \(\{x \in \Q: x > 0\}\) does not have a least element.
  \item \(\{1 - 1/n: n = 2, 3, \dots\}\) is a well-ordering. This can be thought of \(\N\) squashed into \([0, 1]\).
  \item \(\{1 - 1/n: n = 2, 3, \dots\} \cup \{1\}\) is a well-ordering.
  \item In fact, we can take the union of 4 with any real larger than \(1\) and still have a well-ordering.
  \item \(\{1 - 1/n: n = 2, 3, \dots\} \cup \{2 - 1/n: n = 2, 3, \dots\}\), i.e.\ two copies of 4, is still a well-ordering.
  \end{enumerate}
\end{eg}

\begin{remark}
  \(X\) is well-ordered if and only if there is no \(x_1 > x_2 > x_3 > \dots\) in \(X\). Indeed, if there is such a sequence then \(S = \{x_1, x_2, \dots\}\) has no least element.
\end{remark}

\begin{corollary}
  If \(S \subseteq X\) has no least element, then for each \(x \in S\) there exists \(x' \in S\) with \(x' < x\). Thus we have \(x > x' > x'' > \dots\).
\end{corollary}

\begin{definition}[Order isomorphism]\index{order isomorphism}
  Total orders \(X\) and \(Y\) are \emph{isomorphic} if there exists a bijection \(f: X \to Y\) that is order-preserving, i.e.\ for all \(x < x'\), \(f(x) < f(x')\).
\end{definition}

\begin{eg}
  1 and 4 above are isomorphic. 5 and 6 are isomorphic. 6 and 7 are not isomorphic: for example, one has a greatest element and the other one doesn't.
\end{eg}

\begin{proposition}[Proof by induction]\index{proof by induction}
  Let \(X\) be a well-ordering and \(S \subseteq X\) be such that if \(y \in S\) for all \(y < x\) then \(x \in S\) for each \(x \in X\), then \(S = X\).

  Equivalently, if \(p(x)\) is a property such that for all \(x\), if \(p(y)\) for all \(y < x\) then \(p(x)\), then \(p(x)\) for all \(x \in X\).
\end{proposition}

\begin{proof}
  If \(S \neq X\) then let \(x\) be the least element in \(X \setminus S\). Then \(x \notin S\). But \(y \in S\) for all \(y < x\). Absurd.
\end{proof}

An application:

\begin{proposition}
  Let \(X\) and \(Y\) be isomorphic well-orderings. Then there is a \emph{unique} isomorphism from \(X\) to \(Y\).
\end{proposition}

\begin{remark}
  This is false for total orders in general. For example, From \(\Z\) to \(\Z\) we could take identity or \(x \mapsto x - 5\).
\end{remark}

\begin{proof}
  Let \(f, g\) be isomorphisms. We will show \(f(x) = g(x)\) for all \(x \in X\) by induction. Thus we may assume \(f(y) = g(y)\) for all \(y < x\) and want \(f(x) = g(x)\).

  Let \(a\) be the least element of \(Y \setminus \{f(y): y < x\}\), which is non-empty. Then we must have \(f(x) = a\): if \(f(x) > a\) then some \(x' > x\) has \(f(x') = a < f(x)\), contradicting \(f\) being order-preserving. Same holds for \(g\). Thus \(f(x) = g(x)\).
\end{proof}

\begin{definition}[Initial segment]\index{initial segment}
  In a total order \(X\), an \emph{initial segment} \(I\) is a subset of \(X\) such that \(x \in I, y < x\) implies \(y \in I\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item For any \(x \in X\), set \(I_x = \{y \in X: y < x\}\).
  \item Not every initial segment is of this form. For example, in \(\R\) take \(\{x: x \leq 3\}\), or in \(\Q\), take \(\{x: x^2 < 2 \text{ or } x < 0\}\).
  \end{enumerate}
\end{eg}

\begin{note}
  In a well-ordering, every proper initial segment \(I\) is of the form \(I_x\) for some \(x\). Indeed, let \(x\) be the least element of \(X \setminus I\). Then \(y < x\) implies \(y \in I\) (by definition of \(y\)). Also if \(y \in I\) then must have \(y < x\): if \(y = x\) or \(y > x\) then \(x \in I\) which is a contradiction.
\end{note}

The aim is to show every subset of a well-ordered \(X\) is isomorphic to an initial segment.

\begin{note}
  This is false for total orders. For example, \(\{1, 5, 9\} \subseteq \Z\), or \(\Q \subseteq \R\).
\end{note}

Given \(Y \subseteq X\), intuitively we want to map the smallest element of \(Y\) to the smallest element of \(X\) and continue this way. But how do we show every element of \(Y\) is mapped somewhere? Instead, we should work backwards: given  \(y \in Y\), map \(y\) to the smallest element in \(X\) that is not mapped to.

\begin{theorem}[Definition by recursion]\index{definition by recursion}\index{definition by recursion|seealso {definition by recursion}}
  Let \(X\) be well-ordering, \(Y\) any set and \(G: \powerset(X \times Y) \to Y\). Then there exists \(f: X \to Y\) such that \(f(x) = G(f|_{I_x})\) for all \(x \in X\). Moreover \(f\) is unique.
\end{theorem}

\begin{note}\leavevmode
  \begin{enumerate}
  \item For \(f: A \to B\) and \(C \subseteq A\), the \emph{restriction} of \(f\) to \(C\) is
    \[
      f|_C = \{(x, f(x)): x \in C\}.
    \]
  \item Slogan: to define \(f(x)\), make use of \(f|_{I_x}\), i.e.\ the values of \(f(y)\) for \(y < x\).
  \end{enumerate}
\end{note}

\begin{proof}
  First we show existence. Define ``\(h\) is an attempt'' to mean \(h: I \to Y\) where \(I \subseteq X\) is some initial segment, and for all \(x \in I\) we have \(h(x) = G(h|_{I_x})\). Note that if \(h\) and \(h'\) are both attempts defined at \(x\) then \(h(x) = h'(x)\): by induction on \(x\), if \(h(y) = h'(y)\) for all \(y < x\), then \(h(x) = h'(x)\).

  Also for all \(x \in X\) there exists an attempt defined at \(X\), by induction on \(x\). Indeed we want an attempt defined at \(x\), given that for all \(y < x\) there exists an attempt defined at \(y\). So for each \(y < x\) we have a unique attempt \(h_y\) defined on \(\{z: z\leq y\}\) (unique by what we just showed). Let
  \[
    h = \bigcup_{y < x} h(y),
  \]
  an attempt defined on \(I_x\) (which is single-valued by uniqueness) so
  \[
    h' = h \cup \{(x, G(h))\}
  \]
  is an attempt defined at \(x\). Now set \(f(x) = y\) if there exists an attempt \(h\) defined at \(x\) with \(h(x) = y\) (also single-valued).

  For uniqueness, if \(f\) and \(f'\) are both suitable then \(f(x) = f'(x)\) for all \(x \in X\) (by induction on \(X\)) --- since if \(f(y) = f'(y)\) for all \(y < x\) then \(f(x) = f'(x)\).
\end{proof}

A typical application:

\begin{proposition}[Subset collapse]\index{subset collapse}
  Let \(X\) be well-ordered, \(Y \subseteq X\). Then \(Y\) is isomorphic to an initial segment of \(X\). Moreover, the initial segment is unique.
\end{proposition}

\begin{proof}
  To have an isomorphism \(f: Y \to I \subseteq X\), we need precisely that for all \(x \in Y\), \(f(x) = \min X \setminus \{f(y): y < x\}\). So done (existence and uniqueness) by the previous theorem. Note that \(X \setminus \{f(y): y < x\} \neq \emptyset\), because \(f(y) \leq y\) for all \(y\) by induction so \(x \notin \{f(y): y < x\}\).
\end{proof}

A note to the pedantic: in proving the set \(X \setminus \{f(y): y < x\}\) is non-empty, we seem to use a circular argument by assuming \(f\) exists. But this is just a shorthand for the longer version: define
\[
  f(x) =
  \begin{cases}
    \min X \setminus \{f(y): y < x\} & \text{if } X \setminus \{f(y): y < x\} \neq \emptyset \\
    \text{cabbage} & \text{otherwise}
  \end{cases}
\]
and then proceed to show \(f(x) \neq \text{cabbage}\) for all \(x \in X\).

In particular, a well-ordered \(X\) cannot be isomorphic to a proper initial segment of \(X\), by uniqueness in subset collapse.

So far we have proved that if two well-orderings are isomorphic there is a unique isomorphism, and that a subset of a well-ordering is isomorphic to a (unique) initial segment. The question now is, how do different general well-orderings relate to each other?

\begin{definition}
  Say \(X \leq Y\) if \(X\) is isomorphic to an initial segment of \(Y\).
\end{definition}

\begin{eg}
  Let \(X = \N\), \(Y = \{1 - 1/n: n = 2, 3, \dots\} \cup \{1\}\), then \(X \leq Y\).
\end{eg}

What we would hope is that there is a total order on the set of all well-orderings. Firstly we have

\begin{theorem}
  Let \(X, Y\) be well-orderings, then \(X \leq Y\) or \(Y \leq X\).
\end{theorem}

\begin{proof}
  Suppose \(Y \nleq X\), to obtain \(f: X \to Y\) that is an isomorphic with an initial segment of \(Y\), need for all \(x \in X\),
  \[
    f(x) = \min Y \setminus \{f(y): y < x\}.
  \]
  (we can't have \(Y = \{f(y): y < x\}\) as then \(Y\) is isomorphic to \(I_x\)). Done by the theorem.
\end{proof}

\begin{proposition}
  Let \(X, Y\) be well-orderings with \(X \leq Y\) and \(Y \leq X\) then \(X\) and \(Y\) are isomorphic.
\end{proposition}

\begin{proof}
  Let \(f\) be an isomorphism from \(X\) to an initial segment of \(Y\) and \(g\) from \(Y\) to \(X\). Then \(g \compose f: X \to X\) is an initial segment of \(X\) (as an initial segment of an initial segment is an initial segment). so \(g \compose f = \id\) by uniqueness in subset collapse. Similarly \(f \compose g = \id_Y\) . Thus \(X\) is isomorphic to \(Y\).
\end{proof}

\subsection{Constructing well-orderings}

So far we have very few examples of well-orderings, so we wish to build new well-orderings from old.

\begin{notation}
  Write \(X < Y\) if \(X \leq Y\) but \(X\) is not isomorphic to \(Y\). Equivalently, \(X < Y\) if and only if \(X\) is isomorphic to a proper initial segment of \(Y\).
\end{notation}

\begin{eg}
  If \(X = \N\), \(Y = \{1 - 1/n: n = 1, \dots, \} \cup \{1\}\) then \(X < Y\).
\end{eg}

We can produce new well-orderings by
\begin{itemize}
\item add a bigger element: a simple yet bona fide way to make a bigger well-ordering is, given a well-ordering \(X\), choose \(x \notin X\) and set \(x > y\) for all \(y \in X\). This is a well-ordering on \(X \cup \{x\}\), written \(X^+\). Clearly \(X < X^+\).
\item put some together: let \((X, <_X)\) and \((Y, <_Y)\) be well-orderings. Say \(Y\) \emph{extends} \(X\) if \(X \subseteq Y\), \(<_X, <_Y\) agree on \(X\), and \(X\) is an initial segment of \((Y, <_Y)\).
\end{itemize}

A family of well-orderings \(\{X_i: i \in I\}\) are \emph{nested} if for all \(i, j \in I\), \(X_i\) extends \(X_j\) or \(X_j\) extends \(X_i\).

\begin{proposition}
  \label{prop:nested well-orderings}
  Let \(\{X_i: i \in I\}\) be a nested family of well-orderings. Then there exists well-ordering \(X\) with \(X \geq X_i\) for all \(i\).
\end{proposition}

\begin{proof}
  Let \(X = \bigcup_{i \in I} X_i\), with \(x < y\) if there exists \(i\) such that \(x, y \in X_i\) and \(x <_i y\), where \(<_i\) is the well-ordering on \(X_i\). Then \(<\) is a well-defined total order on \(X\). Given \(S \subseteq X\) non-empty, choose \(i\) with \(S \cap X_i \neq \emptyset\). Then \(S \cap X_i\) has a minimal element, which must also be a minimal element of \(S\) as \(X_i\) is an initial segment of \(X\). Also \(X \geq X_i\) for all \(i\).
\end{proof}

\subsection{Ordinals}

We have shown that well-orderings can be compared, but are they totally ordered? This is a question that is not yet very meaningful, since we can have isomorphic well-orderings that are not equal. Now we employ a technique commonly used in studying collection of abstract mathematical objects --- we identify well-orderings that are isomorphic as the same and work with equivalence classes of them.\footnote{Technically, we are working with proper classes instead of sets, for example, by considering the collection of all singletons. See later.}

\begin{definition}[Ordinal]\index{ordinal}
  An \emph{ordinal} is a well-ordered set, with two well-ordered sets regarded as the same if they are isomorphic.
\end{definition}

\begin{definition}[Order-type]\index{order-type}
  If \(X\) is a well-ordering corresponding to ordinal \(\alpha\), say \(X\) has \emph{order-type} \(\alpha\).
\end{definition}

\begin{eg}
  With slight abuse of notation, for each \(k \in \N\), write \(k\) for the order-type of the (unique) well-ordering of a set of size \(k\), and write \(\omega\) for the order-type of \(\N\). So in \(\R\), \(\{1, 3, 7\}\) has order-type \(3\), and \(\{1 - 1/n: n = 2, 3, \dots\}\) has order-type \(\omega\).
\end{eg}

\begin{notation}
  For \(X\) of order-type \(\alpha\) and \(Y\) of order-type \(\beta\), write \(\alpha \leq \beta\) if \(X \leq Y\). This is well-defined. Similarly \(\alpha < \beta\) and so on.
\end{notation}

Equipped with these definitions, we now know for all \(\alpha, \beta\), \(\alpha \leq \beta\) or \(\beta \leq \alpha\) and if \(\alpha \leq \beta, \beta \leq \alpha\) then \(\alpha = \beta\), i.e.\ ordinals are total ordered. But are they well-ordered?

\begin{theorem}
  Let \(\alpha\) be an ordinal. Then the ordinals \(< \alpha\) form a well-ordered set with order-type \(\alpha\).
\end{theorem}

For example, the ordinals \(< \omega\) are \(0, 1, 2, \dots\).

\begin{proof}
  Let \(X\) have order-type \(\alpha\). The well-orderings \(< X\) are precisely (up to isomorphisms) the proper initial segments of \(X\), i.e.\ the \(I_x\) for \(x \in X\). But these are isomorphic to \(X\) itself via \(I_x \mapsto x\).
\end{proof}

\begin{notation}
  We often write \(I_\alpha = \{\beta \text{ ordinal}: \beta < \alpha\}\) for this special well-ordered set with order-type \(\alpha\).
\end{notation}

\begin{proposition}
  \label{prop:set of ordinals is well-ordered}
  Let \(S\) be a non-empty set of ordinals. Then \(S\) has a least element.
\end{proposition}

\begin{proof}
  Choose \(\alpha \in S\). If \(\alpha\) is minimal in \(S\) then done. If not, then \(S \cap I_\alpha \neq 0\), so we have a minimal element of \(S \cap I_\alpha\), which is therefore minimal in \(S\).
\end{proof}

Given the proposition, it is very tempting to conclude that all well-orderings form a well-order. But there is one technicality that we haven't checked, that well-orders are defined on a set. Unfortunately,

\begin{theorem}[Burali-Forti paradox]\index{Burali-Forti paradox}
  The ordinals do not form a set.
\end{theorem}

\begin{proof}
  Suppose not. Let \(X\) be the set of all ordinals. Then \(X\) is a well-ordering, say of order-type \(\alpha\). So \(X\) is isomorphic to \(I_\alpha\), a \emph{proper} initial segment of \(X\). Absurd.
\end{proof}

This is saying that the collection of all well-orderings is too big to be a set, and thus to be a well-ordering. However, this does not prevent us from working locally with a set of well-orderings.

Recall the two ways of constructing well-orderings. Given \(\alpha\), we have \(\alpha^+ > \alpha\). Also if \(\{\alpha_i: i \in I\}\) is a set of ordinals, then there exists \(\alpha\) with \(\alpha \geq \alpha_i\) for all \(i\), by applying \Cref{prop:nested well-orderings} to the nested family \(\{I_{\alpha_i}: i \in I\}\).

In fact, there is a least upper bound for \(\{\alpha_i: i \in I\}\) --- by applying \Cref{prop:set of ordinals is well-ordered} to the set
\[
  \{\beta \leq \alpha: \beta \text{ an upper bound of } \alpha_i\}.
\]
This is denoted \(\sup_{i \in I} \alpha_i\).

\begin{eg}
  \(\sup \{2, 4, \dots\} = \omega\).
\end{eg}

\subsection{Some ordinals}

\Cref{tab:ordinals} shows some ordinals in increasing order. In each row from left to right, adjacent values are successors to each other. The pattern in each row is the ``obvious'' one that the reader should be able to infer. The beginning entry of a row is the supremum of all entries in the previous row.

{%localise the effect
  \renewcommand{\arraystretch}{2.5}
\begin{table}[h!]
  \centering
  \begin{tabular}{cccccccc}
    \(0\) & \(1\) & \(2\) & \(\dots\) \\
    \(\omega\) & \(\omega + 1\) & \(\omega + 2\) & \(\dots\) \\
    \(\omega 2\) & \(\omega2 + 1\) & \(\omega2 + 2\) & \(\dots\) & \(\omega3\) & \(\dots\) & \(\omega4\) & \(\dots\) \\
    \(\omega^2\) & \(\omega^2 + 1\) & \(\dots\) & \(\omega^2 + \omega\) & \(\dots\) & \(\omega^2 + \omega2\) & \(\dots\) \\
    \(\omega^22\) & \(\dots\) & \(\omega^23\) & \(\dots\) & \(\omega^24\) & \(\dots\) \\
    \(\omega^3\) & \(\dots\) & \(\omega^4\) & \(\dots\) & \(\omega^5\) & \(\dots\) \\
    \(\omega^\omega\) & \(\omega^\omega + 1\) & \(\dots\) & \(\omega^\omega + \omega\) & \(\dots\) & \(\omega^\omega2\) & \(\dots\) & \(\omega^\omega3\) \\
    \(\omega^{\omega + 1}\) & \(\dots\) & \(\omega^{\omega + 2}\) & \(\dots\) & \(\omega^{\omega + 3}\) & \(\dots\) \\
    \(\omega^{\omega2}\) & \(\dots\) & \(\omega^{\omega 3}\) & \(\dots\) \\
    \(\omega^{\omega^\omega}\) & \(\dots\) & \(\omega^{\omega^{\omega^\omega}}\) & \(\dots\) \\
    \(\varepsilon_0\) & \(\varepsilon_0 + 1\) & \(\dots\) & \(\varepsilon_0 + \omega\) & \(\dots\) & \(\varepsilon_0 + \omega^\omega\) & \(\dots\) \\
    \(\varepsilon_02\) & \(\dots\) & \(\varepsilon_0\omega\) & \(\varepsilon_0\omega^\omega\) & \(\dots\) \\
    \(\varepsilon_0^2\) & \(\dots\) & \(\varepsilon_0^3\) & \(\dots\) & \(\varepsilon_0^4\) & \(\dots\) \\
    \(\varepsilon_0^\omega\) & \(\dots\) & \(\varepsilon_0^{\omega^\omega}\) & \(\dots\) \\
    \(\varepsilon_0^{\varepsilon_0}\) & \(\dots\) & \(\varepsilon_0^{\varepsilon_0^{\varepsilon_0}}\) & \(\dots\) \\
    \(\varepsilon_1\) & \(\dots\)
  \end{tabular}
  \label{tab:ordinals}
\end{table}
}

Some points to notice:
\begin{itemize}
\item we write \(\omega2 = \sup\{\omega + 1, \omega + 2, \dots\}\). The rationale for this unconventional notation will soon be clear.
\item everything in this table so far is countable, as they are built from operations such as union, subset, cartesian product on countable sets.
\end{itemize}

Is there an uncountable ordinal? In other words, is there an uncountable well-ordered set?

For example, we can well-order \(\N\) and \(\Q\), but what about \(\R\)? Unfortunately, no. We are always going to fail if we try to put a well-ordering on \(\R\). But

\begin{theorem}
  There is an uncountable ordinal.
\end{theorem}

\begin{proof}
  The idea is to take the supremum of all countable ordinals, but first we have to check that it is a set, meaning that we can build it from existing sets using rules such as intersection, cartesian product, images of functions etc.

  Let
  \[
    R = \{A \in \powerset(\N \times \N): A \text{ is a well-ordering of a subset of } \N\}.
  \]
  Let \(S\) be the image of \(R\) under the function ``order-type'', i.e.\ \(S\) is the set of all order-types of well-orderings of \(\N\) (or subsets thereof). It is the set of all countable ordinals.

  Let \(\omega_1 = \sup S\). Then \(\omega_1\) is uncountable: if not then \(\omega_1 \in S\) so \(\omega_1\) would be the greatest member of \(S\), which contradicts \(\omega_1 < \omega_1^+\). Note that by construction \(\omega_1\) is the \emph{least uncountable ordinal}.
\end{proof}

\(\omega_1\) has some strange properties, for example
\begin{enumerate}
\item \(\omega_1\) is uncountable, but for any \(\alpha < \omega\), we have \(\{\beta: \beta < \alpha\}\) countable.\footnote{It would perhaps be less surprising if one considers the analogy that, given \(\alpha < \omega\), \(\{\beta: \beta < \alpha\}\) is finite.}
\item If \(\alpha_1, \alpha_2, \dots < \omega_1\) is a sequence, then it is \emph{bounded} in \(\omega_1\): \(\sup\{\alpha_1, \alpha_2, \dots\}\) is countable so \(< \omega_1\).
\end{enumerate}

\begin{theorem}[Hartogs' lemma]\index{Hartogs' lemma}
  For any set \(X\), there is an ordinal that does not inject into \(X\).
\end{theorem}

\begin{proof}
  Same proof as above, with \(\powerset(X, X)\) in place of \(\powerset(\N, \N)\).
\end{proof}

\begin{notation}
  We often write \(\gamma(X)\) for least such ordinal. For example, \(\gamma(\omega) = \omega_1\).
\end{notation}

\subsection{Successors and Limits}

Given an ordinal \(\alpha\), does \(\alpha\) has a greatest element?

If yes, say \(\beta\) is greatest. Then \(\gamma < \beta\) or \(\gamma = \beta\) implies \(\gamma < \alpha\) and \(\gamma < \alpha\) implies \(\gamma < \beta\) or \(\gamma = \beta\) (as we can't have \(\gamma > \beta\)). So \(\alpha = \beta^+\). Call \(\alpha\) a \emph{successor}\index{successor ordinal}.

If no, then for every \(\beta < \alpha\), then there exists \(\gamma < \alpha\) such that \(\gamma > \beta\). Thus \(\alpha = \sup\{\beta: \beta < \alpha\}\) (note that this is false in general without the absence of greatest element hypothesis, e.g.\ \(\omega + 5\)). Call \(\alpha\) a \emph{limit}\index{limit ordinal}.

\begin{eg}
  \(5\) and \(\omega + 5\) are successors. \(\omega\) and \(\omega + \omega\) are limits. \(0\) is a limit by definition.
\end{eg}

\subsection{Ordinal arithmetics}

\begin{definition}[Ordinal addition (inductive)]
  Define \(\alpha + \beta\) recursively by
  \begin{itemize}
  \item \(\alpha + 0 = \alpha\),
  \item \(\alpha + \beta^+ = (\alpha + \beta)^+\),
  \item \(\alpha + \lambda = \sup \{\alpha + \gamma: \gamma < \lambda\}\) for \(\lambda\) a non-zero limit.
  \end{itemize}
\end{definition}

Since the ordinals do not form a set, we cannot do recursion on ordinals. Instead we do it ``locally'': for each \(\beta\) we define \(\alpha + \gamma\) for \(\{\gamma: \gamma < \beta\}\) recursively. Then by uniqueness of recursion addition is well-defined.

\begin{eg}
  \begin{align*}
    \omega + 1 &= (\omega + 0)^+ = \omega^+ \\
    \omega + 2 &= (\omega + 1)^+ = \omega^{++} \\
    1 + \omega &= \sup \{1 + \gamma: \gamma < \omega\} = \sup \{1, 2, 3, \dots\} = \omega
  \end{align*}
\end{eg}

We can see that addition is not commutative. The is because in the definition of addition recursion is done on the second argument. However ordinal addition remains associative.

\begin{proposition}
  Ordinal addition is asssociative, i.e.\ for all \(\alpha, \beta, \gamma\),
  \[
    (\alpha + \beta) + \gamma = \alpha + (\beta + \gamma).
  \]
\end{proposition}

\begin{proof}
  Since addition is defined by recursion, it is natural to consider an induction proof. Fix \(\alpha\) and \(\beta\) and proceed by induction on \(\gamma\).
  \begin{itemize}
  \item \(\gamma = 0\): \(\alpha + (\beta + 0) = \alpha + \beta = (\alpha + \beta) + 0\).
  \item \(\gamma = \delta^+\) is a successor:
    \begin{align*}
      \alpha + (\beta + \delta^+)
      &= \alpha + (\beta + \delta)^+ \\
      &= (\alpha + (\beta + \delta))^+ \\
      &= ((\alpha + \beta) + \delta)^+ \\
      &= (\alpha + \beta) + \delta^+ \\
      &= (\alpha + \beta) + \gamma
    \end{align*}
  \item \(\gamma\) is a limit:
    \begin{align*}
      (\alpha + \beta) + \gamma
      &= \sup \{(\alpha + \beta) + \lambda: \lambda < \gamma\} \\
      &= \sup \{\alpha + (\beta + \lambda): \lambda < \gamma\}
    \end{align*}
    On the other hand, we need to evaluate \(\alpha + (\beta + \gamma)\). Claim \(\beta + \gamma\) is a limit, i.e.\ \(\beta + \gamma = \sup \{\beta + \lambda: \lambda < \gamma\}\): for any \(\beta + \lambda\), since \(\gamma\) is a limit, there exists \(\lambda'\) such that \(\lambda < \lambda' < \gamma\). Thus \(\beta + \lambda < \beta + \lambda'\). Thus \(\beta + \lambda\) is not the greatest element. Therefore
    \[
      \alpha + (\beta + \gamma) = \sup \{\alpha + \lambda: \lambda < \beta + \gamma\}.
    \]

    Now need to show that
    \[
      \sup \{\alpha + \lambda: \lambda < \beta + \gamma\} = \sup \{\alpha + (\beta + \lambda): \lambda < \gamma\} 
    \]
    Note that the two sets are not equal. For example, for \(\beta = 3, \gamma = \omega\), \(\alpha + 2\) is in LHS but not RHS.
    \begin{itemize}
    \item \(\geq\): by set inclusion \(\supseteq\).
    \item \(\leq\): for \(\lambda < \beta + \gamma\), we have \(\lambda < \sup \{\beta + \lambda': \lambda' < \gamma\}\). Thus \(\lambda < \beta + \lambda'\) for some \(\lambda' < \gamma\). Thus \(\alpha + \lambda < \alpha + (\beta + \lambda)\).
    \end{itemize}
  \end{itemize}
\end{proof}

Note that in the proof we assumed that \(\beta < \gamma \implies \alpha + \beta < \alpha + \gamma\), which can be shown by induction on \(\gamma\). Note that similar to the noncommutativity of ordinal addition, the does not hold for addition on the right: \(1 < 2\) but \(1 + \omega = 2 + \omega\).

The above definition is an inductive one, in which we used the recursive definition of ordinals to build addition bottom-up. Since ordinals can also be defined as order types of sets, there is an alternative definition of addition by constructing a set of the desired order type, and then declare it to be the sum of the two ordinals.

\begin{definition}[Ordinal addition (synthetic)]
  \(\alpha + \beta\) is the order type of \(\alpha \sqcup \beta\), the coproduct of the order \(\alpha\) and \(\beta\) (i.e.\ product order on \(\{0\} \times \alpha \cup \{1\} \times \beta\)).
\end{definition}

\begin{eg}
  \begin{align*}
    \omega + 1 &= \omega^+ \\
    1 + \omega &= \omega
  \end{align*}
\end{eg}

With this definition, associativity is trivial by associativity of union.

\begin{proposition}
  The inductive and synthetic definition of addition coincide.
\end{proposition}

\begin{proof}
  Write \(+\) and \(+'\) for inductive and synthetic definition respectively. We want to show that \(\alpha + \beta = \alpha +' \beta\). Induct on \(\beta\).
  \begin{itemize}
  \item \(\beta = 0\): \(\alpha + 0 = \alpha = \alpha +' 0\).
  \item successor ordinal: \(\alpha + \beta^+ = (\alpha + \beta)^+ = (\alpha +' \beta)^+ = (\alpha +' \beta^+\).
  \item limit ordinal: \(\alpha + \beta = \sup \{\alpha + \lambda: \lambda < \beta\} = \sup \{\alpha +' \lambda: \lambda < \beta\} = \alpha +' \beta\) where the second equality is becaues taking \(\sup\) is the same as union.
  \end{itemize}
\end{proof}

The synthetic definition is usually easier to work with since they provide an encapsulation of information. For example, it was easy to show associativity, and also easy to see noncommutativity. However, the inductive definition is easier if we want to do induction.

Now we define multiplication.

\begin{definition}[Ordinal multiplication (inductive)]
  Define \(\alpha\beta\) recursively by
  \begin{itemize}
  \item \(\alpha 0 = 0\),
  \item \(\alpha(\beta^+) = \alpha\beta + \alpha\),
  \item \(\alpha\lambda = \sup\{\alpha\gamma: \gamma < \lambda\}\) for \(\lambda\) a non-zero limit,
  \end{itemize}
\end{definition}

\begin{eg}
  \begin{align*}
    \omega 1 &= \omega 0 + \omega = 0 + \omega = \omega \\
    \omega 2 &= \omega 1 + \omega = \omega + \omega \\
    \omega\omega &= \sup \{\omega\gamma: \gamma < \omega\} = \sup \{0, \omega, \omega + \omega, \dots\} \\
    2 \omega &= \sup \{2\gamma: \gamma < \omega\} = \omega
  \end{align*}
  In particular this shows multiplication is not commutative.
\end{eg}

\begin{definition}[Ordinal multiplication (synthetic)]
  \(\alpha\beta\) is the order-type of \(\alpha \times \beta\), with \((x, y) < (z, w)\) if either \(y < w\) or \(y = w\) and \(x < z\).
\end{definition}

We can check that the definitions agree and associativity of multiplication etc.

\begin{definition}[Ordinal exponentiation]
  Define \(\alpha^\beta\) recursively by
  \begin{itemize}
  \item \(\alpha^0 = 1\),
  \item \(\alpha^{\beta^+} = \alpha^\beta \cdot \alpha\),
  \item \(\alpha^\lambda = \sup\{\alpha^\gamma: \gamma < \lambda\}\) for \(\lambda\) a non-zero limit.
  \end{itemize}
\end{definition}

\begin{eg}
  \begin{align*}
    \omega^1 &= \omega^0 \cdot \omega = 1 \cdot \omega = \omega \\
    \omega^2 &= \omega^1 \cdot \omega = \omega \cdot \omega \\
    2^\omega &= \sup\{2^\gamma: \gamma < \omega\} = \omega
  \end{align*}
  Note that \(2^\omega\) is countable.
\end{eg}

Similarly we can define towers and other arithmetic operations inductively. It is left as an exercise.

\section{Posets and Zorn's Lemma}

\subsection{Partial Orders}

\begin{definition}[Poset]\index{poset}
  A \emph{partially ordered set} or \emph{poset} is a pair \((X, \leq)\) where \(X\) is a set and \(\leq\) is a relation on \(X\) that is
  \begin{enumerate}
  \item reflexive: for all \(x\), \(x \leq x\),
  \item transitive: for all \(x, y, z\), \(x \leq y, y \leq z\) implies \(x \leq z\),
  \item antisymmetry: for all \(x, y\), \(x \leq y, y \leq x\) implies \(x = y\).
  \end{enumerate}
\end{definition}

\begin{notation}
  Write \(x < y\) if \(x \leq y, x \neq y\).

  In terms of \(<\), a poset is
  \begin{enumerate}
  \item irreflexive: for all \(x\), not \(x < x\),
  \item transitive: for all \(x, y, z\), \(x < y, y < z\) implies \(x < z\).
  \end{enumerate}
\end{notation}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Any total order.
  \item \(\N^+\) with ``divides''.
  \item For any set \(S\), \(\powerset(S)\) with \(x \leq y\) if \(x \subseteq y\).
  \item Any \(X \subseteq \powerset(S)\) with same relation as above. This specialises to, for example, all subspaces of a given vector space.
  \item We can draw a \emph{Hasse diagram} for a poset \(X\): it consists of a drawing of elemnents of \(X\), with an upward line from \(x\) to \(y\) if \(y\) covers \(x\), meaning \(y > x\) and no \(z\) such that \(y > z > x\). For example
    \[
      \begin{tikzcd}
        c \ar[dr, dash] & & & & e \ar[dl, dash] \\
        & b \ar[dr, dash] & & d \ar[dl, dash] \\
        & & a
      \end{tikzcd}
    \]
    Hasse diagrams can be useful to visualise a poset (e.g.\ \(\N\)), or useless (e.g.\ \(\Q\)).
  \item In
    \[
      \begin{tikzcd}
        & c \ar[dl, dash] \ar[dr, dash] \\
        b \ar[ddr, dash] & & c \ar[d, dash] \\
        & & d \ar[dl, dash] \\
        & a
      \end{tikzcd}
    \]
    \(b\) and \(d\) are unrelated so there is no sense of ``height'' or ``rank''.
  \item
    \[
      \begin{tikzcd}
        & c \ar[dl, dash] \ar[dr, dash] \\
        b \ar[d, dash] \ar[drr, dash] & & e \ar[d, dash] \ar[dll, dash] \\
        a & & d
      \end{tikzcd}
    \]
  \item A set in which no two elements are related is a poset.
  \end{enumerate}
\end{eg}

\begin{definition}[Chain]\index{chain}
  In a poset \(X\), a \emph{chain} is a set \(S \subseteq X\) that is totally ordered: for all \(x, y \in S\), \(x \leq y\) or \(y \leq x\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Any subset of 1 above.
  \item In 2, \(\{1, 2, 4, 8, 16\}\).
  \item In 5, \(\{a, b, c\}\) or \(\{a, c\}\) but not \(\{b, d\}\).
  \item In 8, only singletons and \(\emptyset\).
  \end{enumerate}
\end{eg}

\begin{note}
  Chains can be uncountable, e.g.\ \((\R, \leq)\).
\end{note}

\begin{definition}[Anti-chain]\index{anti-chain}
  Give a poset \(X\), \(S \subseteq X\) is an \emph{anti-chain} if no two elements are related: for all \(x, y \in S\), \(x \neq y\) implies that not \(x < y\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item In 2: the set of primes.
  \item In 5, \(\{c, e\}\) or \(\{c, d\}\), or \(\{b\}\).
  \item In 8, every subset.
  \end{enumerate}
\end{eg}

\begin{definition}[Upper bound]\index{upper bound}
  Give a poset \(X\), \(S \subseteq X\), an \emph{upper bound} for \(S\) is any \(x \in X\) such that \(x \geq y\) for all \(y \in S\).
\end{definition}

\begin{definition}[Least upper bound]\index{least upper bound}\index{supremum}
  Say \(X\) is a \emph{least upper bound} or \emph{supremum} for \(S\) if \(x\) is an upper bound for \(S\) and \(x \leq y\) for every upper bound \(y\) for \(S\). Write \(x = \sup S\) or \(x = \bigvee S\), the ``join'' of \(S\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item In \(\R\), \(\{x: x^2 < 2\}\) has \(7\) as an upper bound and \(\sqrt 2\) as a supremum. This shows that \(\sup S\) need not be in \(S\).
  \item In \(\R\), the set \(\Z\) has no upper bound.
  \item In \(\Q\), \(\{x: x^2 < 2\}\) has \(7\) as an upper bound but no supremum.
  \item In 5, \(\{a, b\}\) has upper bounds \(b\) and \(c\) and supremum \(b\).
  \item In 5, \(\{b, d\}\) has no upper bound.
  \item In 7, \(\{b, d\}\) has upper bounds \(c, b, e\) but no supremum.
  \end{enumerate}
\end{eg}

\begin{definition}[Completeness]\index{completeness}
  A poset is \emph{complete} if every subset has a supremum.
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \((\R, \leq)\) is not complete as \(\Z\) has no supremum. Thus completeness in posets is different to that from analysis.
  \item \([0, 1]\) is complete.
  \item \((0, 1)\) is not complete as \((0, 1)\) itself has no supremum.
  \item \(\powerset(S)\) is always complete --- \(\{A_i\}_{i \in I}\) has supremum \(\bigcup_{i \in I} A_i\).
  \end{enumerate}
\end{eg}

\begin{definition}[Order-preserving map]\index{order-preserving map}
  A function \(f: X \to X\) where \(X\) is a poset is \emph{order-preserving} if \(f(x) \leq f(y)\) for all \(x \leq y\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item On \(\N\), \(f(x) = x + 1\).
  \item On \([0, 1]\), \(f(x) = \frac{1 + x}{2}\), ``halve the distance to \(1\)''.
  \item On \(\powerset(S)\), \(f(A) = A \cup \{i\}\) for some fixed \(i \in S\).
  \end{enumerate}
\end{eg}

From above not every order-preserving function has a fixed point. But just as in Contraction Mapping Theorem, we can add condition to the space to make this happen. Unsurprisingly, this condition is completeness:

\begin{theorem}[Knaster-Tarski fixed point theorem]\index{Knaster-Tarski fixed point theorem}
  \label{thm:Knaster-Tarski}
  Let \(X\) be a complete poset. Then every order-preserving function \(f: X \to X\) has a fixed point.
\end{theorem}

\begin{proof}
  Let \(E = \{x \in X: x \leq f(x)\}\) and \(s = \sup E\). To show \(f(s) = s\), we show both \(s \leq f(s)\) and \(s \geq f(x)\).
  \begin{itemize}
  \item \(s \leq f(s)\): suffices to show \(f(s)\) is an upper bound for \(E\) (as \(s\) is the least upper bound). But
    \[
      x \in E \implies x \leq s \implies f(x) \leq f(s) \implies x \leq f(x) \leq f(s).
    \]
  \item \(s \geq f(s)\): suffices to show \(f(s) \in E\) (as \(s\) is an upper bound). We know \(s \leq f(s)\), so \(f(s) \leq f(f(s))\) since \(f\) is order preserving.
  \end{itemize}
\end{proof}

\begin{note}
  In any complete poset \(X\), we have a greatest element, namely \(\sup X\). We also have a least element, namely \(\sup \emptyset\).
\end{note}

A typical application of Knaster-Tarski is

\begin{theorem}[Schröder-Berstein theorem]\index{Schröder-Berstein theorem}
  Let \(A, B\) be sets such that there is an injection \(f: A \to B\) and injection \(g: B \to A\), then there exists a bijection from \(A\) to \(B\).
\end{theorem}

\begin{proof}
  Seek partitions \(A = P \cup Q, B = R \cup S\) such that \(f(P) = R, g(S) = Q\). Then done by seting \(h = \begin{cases} f & \text{on } R \\ g^{-1} & \text{on } Q \end{cases}\).

  Note that we are done once we fix \(P\): \(R = f(P), S = B \setminus f(P), Q = g(B \setminus f(P))\). i.e.\ we seek \(P \subseteq A\) such that
  \[
    A \setminus (g(B \setminus f(P))) = P.
  \]
  Define
  \begin{align*}
    \theta: \powerset(A) &\to \powerset(A) \\
    P &\mapsto A \setminus (g(B \setminus f(P)))
  \end{align*}
  Then since \(\powerset(A)\) is complete, \(\theta\) is order-preserving (since it takes complement twice), there exists a fixed point by Knaster-Tarski.
\end{proof}

\subsection{Zorn's Lemma}

\begin{definition}
  An element \(x\) in a poset \(X\) is \emph{maximal} if there exists no \(y \in X\) such that \(y > x\).
\end{definition}

\begin{eg}
  In example 5 before, \(c, e\) are both maximal.
\end{eg}

Posets need not have a maximal element, for example \(\N, \Q, \R\) with the ususal order. We notice something in common: in each of thoses cases, there exists a chain without an upper bound.

\begin{theorem}[Zorn's lemma]\index{Zorn's lemma}
  Let \(X\) be a (non-empty) set in which every chain has an upper bound, then \(X\) has a maximal element.
\end{theorem}

\begin{proof}
  Suppose not, then for each \(x \in X\) there exists \(x' \in X\) with \(x' > x\). Also for any chain \(C\) we have an upper bound \(u(C)\). Pick \(x \in X\). Define \(x_\alpha \in X\) for each \(\alpha \in \gamma(X)\) recursively by
  \begin{align*}
    x_0 &= x \\
    x_{\alpha + 1} &= x_\alpha' \\
    x_{\lambda} &= u(\{x_\alpha: \alpha < \lambda\}) \text{ for \(\lambda\) a nonzero limit}
  \end{align*}
  Then \(\alpha \mapsto x_\alpha\) is an injection \(\gamma(X) \to X\). Absurd.
\end{proof}

A typical application of Zorn's lemma: does every vector space \(V\) have a basis? Recall that a basis is a linearly independent (no non-trival finite relation) spanning (every element is a finite linear combination thereof) set.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Let \(V = \R[X]\) be the space of all real polynomials. Then \(\{X^i\}_{i \in \N}\) is a basis.
  \item Let \(V\) be the set of all real sequences with pointwise addition. We might guess
    \begin{align*}
      \ell_1 &= (1, 0, 0, \dots) \\
      \ell_2 &= (0, 1, 0, \dots) \\
      \vdots
    \end{align*}
    is a basis. Unfortunately they are linearly independent but not spanning, e.g.\ \((1, 1, 1, \dots)\) is not in the span. It is actually easy to check that there is no countable basis. It also turns out that there is no \emph{explicit} basis.
  \item \(\R\) as a \(\Q\)-vector space has a basis called a \emph{Hamel basis}.
  \end{enumerate}
\end{eg}

\begin{theorem}
  Every vector space has a basis.
\end{theorem}

\begin{proof}
  We seek a maximal linearly independent set. Let \(V\) be a vector space and
  \[
    X = \{A \subseteq V: A \text{ linearly independent}\}
  \]
  ordered by \(\subseteq\). If we can find a maximal element of \(X\), then done: if \(M\) is not spanning then choose \(x \notin \generation M\) and then \(M \cup \{x\}\) is linearly independent. Absurd.

  We have \(X \neq \emptyset\) as \(\emptyset \in X\). Given a chain \(\{A_i: i \in I\}\) in \(X\), put \(A = \bigcup_{i \in I} A_i\). Then \(A \supseteq A_i\) for all \(i\), so just need to check \(A \in X\), i.e.\ \(A\) is linearly independent. Suppose not, so
  \[
    \sum_{i = 1}^n \lambda_ix_i = 0
  \]
  for some \(x_i \in A\), \(\lambda_i\) not all \(0\). We have \(x_1 \in A_{i_1}, \dots, x_n \in A_{i_n}\) for some \(i_1, \dots, i_n \in I\). But \(A_{i_1}, \dots, A_{i_n} \subseteq A_{i_k}\) for some \(k\) (as \(A_{i_1}, \dots, A_{i_n}\) are nested), contradicting \(A_{i_k}\) linearly independent.
\end{proof}

\begin{note}
  The only ``actual math'' (i.e.\ linear algebra) in the proof was the ``then done'' part.
\end{note}

Another application of Zorn's lemma: completeness theorem when the primitive language is uncountable.

\begin{theorem}[Completeness theorem]\index{completeness theorem}
  Let \(S \subseteq L(P)\) where \(P\) is any set. Then \(S\) is consistent implies that \(S\) has a model.
\end{theorem}

\begin{proof}
  We seek a maximal consistent \(\cl S \supseteq S\). Then done: for each \(t \in L(P)\) haave \(\cl S \cup \{t\}\) or \(\cl S \cup \{\neg t\}\) consistent, whence \(t \in \cl S\) or \(\neg t \in \cl S\). By maximality of \(\cl S\), and now define
  \begin{align*}
    v(t) =
    \begin{cases}
      1 & \text{if } t \in \cl S \\
      0 & \text{if } t \notin \cl S
    \end{cases}
  \end{align*}

  Let
  \[
    X = \{T \subseteq L(P): T \text{ consistent}, T \supseteq S\}
  \]
  ordered by \(\subseteq\). Then \(X \neq \emptyset\) as \(S \in X\). Given a non-empty chain \(\{T_i: i \in I\}\) in \(X\), take \(T = \bigcup_{i \in I} T_i\), then \(T \supseteq T_i\) for all \(i\) so just need \(T \in X\). We have \(S \subseteq T\) (as \(I \neq \emptyset\)) and \(T\) is consistent: suppose \(T \yields \bot\). Then \(\{t_1, \dots, t_n\} \yields \bot\) for some \(t_1, \dots, t_n \in T\) (as proofs are finite). Since \(t_1 \in T_{i_1}, \dots, t_n \in T_{i_n}\) for some \(i_1, \dots, i_n \in I\), but \(T_{i_1}, \dots, T_{i_n} \subseteq T_{i_k}\) for some \(k\) (as they are nested), \(T_{i_k} \yields \bot\). Absurd.
\end{proof}

One final application:

\begin{theorem}[Well-ordering principle]\index{well-ordering principle}
  Every set can be well-ordered.
\end{theorem}

\begin{remark}
  This is very surprising for, for example, \(\R\), until you remember Hartogs' lemma.
\end{remark}

\begin{proof}
  Let \(S\) be the set. Let
  \[
    X = \{(A, R): A \subseteq S, R \text{ a well-ordering of } A\}
  \]
  ordered by
  \[
    (A, R) \leq (A', R') \text{ if } (A', R') \text{ extends } (A, R).
  \]
  \(X \neq \emptyset\) as \((\emptyset, \emptyset) \in X\). Given a chain \(\{(A_i, R_i): i \in I\}\), we have
  \[
    (\bigcup_{i \in I} A_i, \bigcup_{i \in I} R_i) \in X
  \]
  extending each \((A_i, R_i)\) (from chapter 2). Thus by Zorn's lemma, \(X\) has a maximal element \((A, R)\). Must have \(A = S\): if not, choose \(x \in S \setminus A\) and ``take successor'': well-order \(A \cup \{x\}\) by setting \(x > a\) for all \(a \in A\), contradicting the maximality of \((A, R)\).
\end{proof}

\begin{remark}
  Proof of Zorn's lemma was easy because we knew ordinals, recursion  and Hartog's lemma.
\end{remark}

\subsection{Zorn's Lemma and Axiom of Choice}

In the proof of Zorn's lemma, we chose for each \(x \in X\) an \(x' > x\) --- i.e.\ we made infinitely many arbitrary choices (note that this has nothing to do with Hartog's lemma. We made infinitely many choices even by the time we get to \(x_\omega\)). We did the same in IA Numbers and Sets, in proving that the countable union of countable sets is countable: we chose for each set in the family an ordering whereof.

In terms of ``rules for building sets'', this is appealing to \emph{axiom of choice}, which says that we may choose an element of each set in a family of non-empty sets. More precisely,

\begin{axiom}[Axiom of choice]\index{axiom of choice}
  If \(\{A_i: i \in I\}\) is a family of non-empty sets then it has a \emph{choice function}, i.e.\ a function \(f: I \to \bigcup_{i \in I} A_i\) such that \(f(i) \in A_i\) for all \(i\).
\end{axiom}

This is of different character to the other set-building rules, such as union, power set etc in that the object whose existence is asserted is not uniquely specified by its properties, unlike, for example, union of sets. Thus often one points out when one has used Axiom of choice.

\begin{remark}
  Axiom of choice is trivial if \(|I| = 1\) (\(A \neq \emptyset\) means by definition that there exists \(x \in A\)). By induction, it is true for \(I\) finite. However, it turns out that, for general \(I\), axiom of choice \emph{cannot} be deduced from the other set-theoretic rules.
\end{remark}

In Zorn's lemma, we used axiom of choice. Is there a proof of Zorn's lemma without axiom of choice? No, because we can deduce axiom of choice from Zorn's lemma.

\begin{proof}[Proof oz axiom of choice from Zorn's lemma]
  Given a family \(\{A_i: i \in I\}\) of non-empty sets, a \emph{partial choice function} is an \(f: J \to \bigcup_{i \in I} A_i\) where \(J \subseteq I\) such that \(f(j) \in A_j\) for all \(j \in J\). Let
  \[
    (J, f) \leq (J', f') \text{ if } J \subseteq J' \text{ and } f'|_J = f.
  \]
  This poset is non-empty as \((\emptyset, \emptyset)\) is an element. Given a chain \(\{(J_q, f_q)\}_{q \in Q}\), we have \(\bigcup_{q \in Q} (J_q, f_q)\) as an upper bound. Thus by Zorn's lemma there exists a maximal element \((J, f)\). We must have \(J = I\), as if not we choose \(i \in I \setminus J, x \in A_i\), and put \(J' = J \cup \{i\}, f' = f \cup \{(i, x)\}\). Absurd.
\end{proof}

In conclusion, Zorn's lemma \(\iff\) axiom of choice (in the presence of the set-building rules).

Actually, there is a three-way equivalence: we have shown Zorn's lemma implies well-ordering principle, and well-ordering principle implies axiom of choice trivially (\(\bigcup_{i \in I} A_i\) is well-ordered and let \(f(i)\) be least element of \(A_i\)). Therefore
\[
  \text{Zorn's lemma } \iff \text{ axiom of choice } \iff \text{ well-ordering principle}.
\]

\begin{ex}
  Show that axiom of choice implies well-ordering principle directly.
\end{ex}

\begin{note}
  Zorn's lemma is hard to prove from first principles because we need theory of ordinals, recursions and Hartogs' lemma, not because of its equivalence with axiom of choice.
\end{note}

\subsection{Bourbaki-Witt Theorem*}

On one hand we have Zorn's lemma, which is a local (conditions on chains) to global (maximal element) principle, and on the other hand we have \nameref{thm:Knaster-Tarski}, a global fixed point theorem based on assumptions of the ambient space (completeness). The Bourbaki-Witt theorem is a ``midpoint'' between the two.

\begin{definition}[Chain-complete]\index{chain complete}
  A poset \(X\) is \emph{chain-complete} if \(X \neq \emptyset\) and every non-empty chain has a supremum.
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Any complete poset.
  \item Any finite poset.
  \item Given a vector space \(V\), \(\{A \subseteq V: A \text{ is linearly independent}\}\).
  \end{enumerate}
\end{eg}

\begin{definition}[Inflationary]\index{inflationary}
  A function \(f: X \to X\) is \emph{inflationary} if \(f(x) \geq x\) for all \(x\).
\end{definition}

\begin{theorem}[Bourbaki-Witt]\index{Bourbaki-Witt theorem}
  Suppose \(X\) is chain-complete and \(f: X \to X\) inflationary. Then \(f\) has a fixed point.
\end{theorem}

Bourbaki-Witt follows immediately from Zorn's lemma: take maximal \(x\) and since \(f(x) \geq x\), we must have equality.

However, intriguingly, we can prove Bourbaki-Witt \emph{without} axiom of choice: injecting \(\gamma(X)\) into \(X\) by explicitly set \(x_{\alpha + 1} = f(x_\alpha)\) and \(x_\alpha = \sup\{x_\beta: \beta < \alpha\}\) for a non-zero limit \(\alpha\) and derive a contradiction. We circumvent the issue of choice by exhibit an explicit upper bound.

\begin{note}
  In chapter 2, we never used axiom of choice except in remark that well-ordering is equivalent to the absence of decreasing sequece, and that \(\omega_1\) does not have a countable supremum.
\end{note}

In fact, it is easy to deduce Zorn's lemma from Bourbaki-Witt (with axiom of choice) so we can view it as the ``choice-free version of Zorn's lemma''.

\section{Predicate Logic}

We studied propositional logic in chapter 1 but it is not powerful enough to express objects outside of primitive propositions. In this chapter we will introduce predicate logic, which is more intricate but more powerful. Before that we will have an overview of the theory we will develop.

A mathematical \emph{structure} is a set with functions and relations defined on it. A function has an \emph{arity} associated to it, which is the number of arguments it take. For example, recall that a group is a set \(A\) equipped with functions \(m: A^2 \to A\) (arity \(2\)), and \(i: A \to A\) (arity \(1\)), and a constant \(e \in A\), which could be seen as a function of arity \(0\), such that
\begin{align*}
  & (\forall x, y \in A) (m(x, m(y, z)) = m(m(x, y), z)) \\
  & (\forall x \in A) (m(x, e) = x \land m(e, x) = x) \\
  & (\forall x \in A) (m(x, i(x)) = e \land m(i(x), x) = e)
\end{align*}

As another example, a poset is a structure with relation: it is a set \(A\) equipped with a predicate (i.e.\ relation) \((\leq) \subseteq A^2\) such that
\begin{align*}
  & (\forall x \in A) (x \leq x) \\
  & (\forall x, y, z \in A) ((x \leq y \land y \leq z) \implies (x \leq z)) \\
  & (\forall x, y \in A) ((x \leq y \land y \leq x) \implies (x = y))
\end{align*}

\begin{table}[ht]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    Propostional logic & Predicate logic & Example in groups \\ \hline
    language & language & group axioms \\ \hline
    valuation & structure & \(m, i, e\) \\ \hline
    model of \(S\) & same & structure in which each \(s \in S\) holds \\ \hline
    \(S \models t\) & same & group axioms \(\models m(e, e) = e\) \\ \hline
    \(S \yields t\) & same* & \\ \hline
  \end{tabular}
  \caption{Comparison of concepts in propositional and predicate logic}
\end{table}

The axioms and deduction rules in predicate logic is going to be more complicated. For example, it includes an axiom that says ``if \(p(x)\) holds for all \(x\) then we can substitute \(t\) for \(x\)''.

\subsection{Definitions}

\begin{definition}[Language]\index{language}
  A \emph{language} \(L(\Omega, \Pi, \alpha)\) is the set of \emph{formulæ}, defined by
  \begin{itemize}
  \item \emph{variables}\index{variable}: \(x_1, x_2, \dots\). We sometimes use \(x, y, \dots\),
  \item \emph{terms}: defined inductively by
    \begin{enumerate}
    \item each variable is an a term,
    \item if \(f \in \Omega, \alpha(f) = n\) and \(t_1, \dots, t_n\) are terms then \(ft_1, \dots t_n\) is a term. We usually write \(f(t_1, \dots, t_n)\).
    \end{enumerate}
    \begin{eg}
      In the language of groups, we have \(\Omega = (m, i, e)\), with arities \(2, 1, 0\) respectively. \(\Pi = \emptyset\).

      Some terms: \(x_1, m(x_1, x_1), e, m(e, e), m(x_1, i(x_1))\).
    \end{eg}
  \item \emph{atomic formulæ}: consists of
    \begin{enumerate}
    \item \(\bot\),
    \item \((s = t)\) for any terms \(s, t\),
    \item \(\phi(t_1, \dots, t_n)\) for any \(\phi \in \Pi, \alpha(\phi) = n\) and any terms \(t_1, \dots, t_n\).
    \end{enumerate}
  \item \emph{formulæ}\index{formula}: defined inductively by
    \begin{enumerate}
    \item each atomic formula is a formula,
    \item if \(p, q\) are formulæ then so is \((p \implies q)\),
    \item if \(p\) is a formula, \(x\) is a variable, then \((\forall x) p\) is a formula,
      \begin{eg}\leavevmode
        \begin{enumerate}
        \item group:
          \begin{align*}
            & (\forall x) (m(x, x) = e), \\
            & (\forall x) (m(x, x) = e) \implies (\exists y)(m(y, y) = x).
          \end{align*}
        \item poset: \((\forall x) (x \leq x)\).
        \end{enumerate}
      \end{eg}
    \end{enumerate}
  \end{itemize}
\end{definition}

\begin{note}\leavevmode
  \begin{enumerate}
  \item A formula is a string of symbols.
  \item Just as in chapter 1 we defined symbols such as \(\neg\), \(\land\) and \(\lor\) in terms of \(\bot\), we write \((\exists x) p\) for \(\neg (\forall x) (\neg p)\).
  \end{enumerate}
\end{note}

\begin{definition}[Closed]\index{closed}
  A term is \emph{closed} if it contains no variables.
\end{definition}

\begin{eg}
  \(e, m(e, e), m(e, m(e, e))\) are closed terms, but \(m(x, i(x))\) isn't.
\end{eg}

\begin{definition}[Bound \& free variable]\index{variable!bound}\index{variable!free}
  An occurrence of variable \(x\) in formula \(p\) is \emph{bound} if it is inside the brackets of a ``\(\forall x\)'' quantifier. Otherwise it is \emph{free}.
\end{definition}

\begin{eg}
  In \(m(x, x) = e \implies (\exists y) (m(y, y) = e)\), \(x\) is free and \(y\) is bounded.
\end{eg}

\begin{note}
  It is possible to have a variable that is both free and bound in a formula. For example,
  \[
    (m(x, x) = e) \implies (\forall x)(\forall y) (m(x, y) = m(y, x)).
  \]
  But promise to \emph{never} use it!
\end{note}

\begin{definition}[Sentence]\index{sentence}
  A \emph{sentence} is a formula without free variables.
\end{definition}

\begin{eg}
  \((\forall x) (m(x, e) = x)\).
\end{eg}

\begin{definition}[Substitution]\index{substitution}
  For a formula \(p\), a variable \(x\) and a term \(t\), the \emph{substitution} \(p[t/x]\) is obtained by replacing each free occurrence of \(x\) with \(e\).
\end{definition}

Do not worry too much about the word ``free'' in the above definition, it is there to prevent us from doing stupid things in stupid formula such as the bad example above where a variable is both free and bound. Just follow your common sense!

\begin{eg}
  If \(p\) is the statement \((\exists y) (m(y, y) = x)\) then \(p[t/x]\) is
  \[
    (\exists y) (m(y, y) = t).
  \]
\end{eg}

\subsection{Semantic Entailment}

\begin{definition}[Structure]\index{structure}
  An \emph{\(L\)-structure} is a non-empty set \(A\) equipped with
  \begin{enumerate}
  \item for each \(f \in \Omega\) with \(\alpha(f) = n\), a function \(f_A: A^n \to A\),
  \item for each \(\phi \in \Pi\) with \(\alpha(\phi) = n\), a relation \(\phi_A \in A^n\).
  \end{enumerate}
\end{definition}

See note on page~\pageref{note:empty structure} for why ``non-empty''.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Suppose \(L\) is the language of groups, then an \(L\)-structure is a set \(A\) with functions \(m_A: A^2 \to A, i_A: A \to A, e_A \in A\). Note that \(A\) need not be a group.
  \item Suppose \(L\) is the language of posets, then an \(L\)-structure is a set \(A\) with a relation \((\leq_A) \in A^2\).
  \end{enumerate}
\end{eg}

We want to define the \emph{interpretation} \(p_A \in \{0, 1\}\) of a sentence \(p\) in an \(L\)-structure \(A\). For example, \((\forall x) (m(x, x) = e)\) should be ``true in \(A\)'' if \(\forall a \in A, m_A(a, a) = e_A\). Informally this can be done by inserting ``\(\in A\)'' and subscripting \(A\), and saying it aloud. This recipe captures the essence of the definition of interpretation and is perfectly valid, except that it precludes, for example, the entire French community from studying predicate logic. Thus we rephrase it in the language common to all mathematicians:

\begin{definition}[Interpretation]\index{interpretation}
  For an \(L\)-structure \(A\), define \emph{interpretation} of \(A\) \(p_A \in \{0, 1\}\) for a sentence \(p\) recursively by
  \begin{enumerate}
  \item closed term: define \(t_A\) recursively by \((ft_1, \dots, f_n)_A = f_A(t_{1_A}, \dots, t_{n_A})\) for any \(f \in \Omega, \alpha(f) = n\) and closed terms \(t_1, \dots, t_n\).
    \begin{eg}
      \(m(e, i(e))_A = m_A(e_A, i_A(e_A))\). Note that \(e_A\) is already defined.
    \end{eg}
  \item atomic formulæ: define \(p_A \in \{0, 1\}\) for \(p\) atomic by
    \begin{enumerate}
    \item \(\bot_A = 0\),
    \item \((s = t)_A = \begin{cases} 1 & \text{if } s_A = t_A \\ 0 & \text{otherwise} \end{cases}\) for closed terms \(s, t\).
    \item \(\phi(t_1, \dots, t_n) = \begin{cases} 1 & \text{if } (t_{1_A}, \dots, t_{n_A}) \in \phi_A \\ 0 & \text{otherwise} \end{cases}\) for each \(\phi \in \Pi, \alpha(\phi) = n\) and closed terms \(t_1, \dots, t_n\).
    \end{enumerate}
  \item sentence: \(p_A\) defined inductively by
    \begin{enumerate}
    \item \((p \implies q)_A = \begin{cases} 0 & \text{if } p_A = 1, q_A = 0 \\ 1 & \text{otherwise} \end{cases}\)
    \item \(((\forall x) p)_A = \begin{cases} 1 & \text{if } p[\overline a/x]_{\overline A} = 1 \text{ for all } a \in A \\ 0 & \text{otherwise} \end{cases}\) where, for each \(a \in A\), add constant symbol \(\overline a\) to \(L\) obtaining \(L'\), and made an \(L'\)-structure \(\overline A\) by setting \(\overline a_{\overline A} = a\).
    \end{enumerate}
  \end{enumerate}
\end{definition}

If \(p\) has free vaiables, we can define \(p_A \subseteq A^{\#\text{free variables of \(p\)}}\). For example, if \(p\) is the formula \((\exists y) (m(y, y) = x)\), then
\[
  p_A = \{a \in A: \exists b \in A \text{ with } m_A(b, b) = e\}.
\]

\begin{definition}[Model]\index{model}
  If \(p_A = 1\), say \(p\) is \emph{true} is \(A\), or \(p\) \emph{holds} in \(A\), or \(A\) is a \emph{model} of \(p\).
\end{definition}

\begin{definition}[Semantic entailment]\index{semantic entailment}
  For \(T\) a \emph{theory} (set of sentences), say \(T\) \emph{semantically entails} \(p\), written \(T \models p\), if every model of \(T\) is a model of \(p\).
\end{definition}

\begin{definition}
  \(p\) is a \emph{tautology} if \(\emptyset \models p\) (or written \(\models p\)), i.e.\ \(p\) holds in every \(L\)-structure.
\end{definition}

\begin{eg}
  \(\models (\forall x) (x = x)\).
\end{eg}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Theory of groups: \(\Omega = \{m, i, e\}, \Pi = \emptyset\). Let \(T\) be the usual group axioms, i.e.
    \begin{align*}
      & (\forall x, y \in A) (m(x, m(y, z)) = m(m(x, y), z)) \\
      & (\forall x \in A) (m(x, e) = x \land m(e, x) = x) \\
      & (\forall x \in A) (m(x, i(x)) = e \land m(i(x), x) = e)
    \end{align*}
    Then an \(L\)-structure is a model of \(T\) if and only if \(T\) is a group. Note that there are two implications here (compare with, for example, a group is a model of the sentence representing associativity). We say \(T\) \emph{axiomatises the class of groups} or \emph{axiomatises the theory of groups}. Sometimes call the elements of \(T\) the \emph{axioms}\index{axiom} of \(T\).
  \item Theory of fields: \(\Omega = \{+, \times, -, 0, 1\}, \Pi = \emptyset\). Note that multiplicative inverse is not among them. \(T\) is
    \begin{align*}
      & \{ \text{abelian group under } (+, -, 0) \\
      & \times \text{ is commutative, associative, and distributive over } + \\
      & (\forall x) (1x = x) \\
      & \neg (1 = 0) \\
      & (\forall x) (\neg(x = 0)) \implies (\exists y)(xy = 1) \}
    \end{align*}
    Then \(T\) axiomatises the class of fields. Then \(T\) models ``inverses are unique'', i.e.
    \[
      T \models (\forall x) (\neg (x = 0)) \implies ((\forall y) (\forall z) ((yx = 1) \land (zx = 1) \implies (y = z))).
    \]
  \item Theory of posets: \(\Omega = \emptyset, \Pi = \{\leq\}\). \(T\) is
    \begin{align*}
      & \{ (\forall x) (x \leq x) \\
      & (\forall x) (\forall y) (\forall z) ((x \leq y \land y \leq z) \implies x \leq z) \\
      & (\forall x) (\forall y) ((x \leq y) \land (y \leq x) \implies x = y) \}
    \end{align*}
  \item Theory of graphs: \(\Omega = \emptyset, \Pi = \{a\}\) where \(a\) means ``is adjacent to''. \(T\) is
    \begin{align*}
      & \{ (\forall x) (\neg a(x, x)) \\
      & (\forall x) (\forall y) (a(x, y) \implies a(y, x)) \}
    \end{align*}
  \end{enumerate}
\end{eg}

\subsection{Syntactic Implication}

As before, we need some logical axioms. There are 7 of them: 3 from propositional logic, 2 for \(=\), 2 for \(\forall\).

\begin{enumerate}
\item \(p \implies (q \implies p)\) for any formulæ \(p, q\).
\item \((p \implies (q \implies r)) \implies ((p \implies q) \implies (p \implies r))\) for any formulæ \(p, q, r\).
\item \((\neg\neg p) \implies p\) for any formula \(p\).
\item \((\forall x) (x = x)\) for any variable \(x\).
\item \((\forall x) (\forall y) ((x = y) \implies (p \implies p[y/x]))\) for any variables \(x, y\) and formula \(p\) in which \(y\) does not occur bound.
\item \((\forall x) (p) \implies p[t/x]\) for any vairable \(x\), term \(t\) and formula \(p\) with no variable in \(t\) occurring bound in \(p\).
\item \(((\forall x) (p \implies q)) \implies (p \implies (\forall x) q)\) for any variable \(x\) and formulæ \(p, q\) with \(x\) not occurring free in \(p\).
\end{enumerate}

As deduction rules we have
\begin{enumerate}
\item moduls ponens: from \(p, p \implies q\) can deduce \(q\).
\item generalisation\index{generalisation}: from \(p\) can deduce \((\forall x) p\), if \(x\) does not occur free in any premise used to prove \(p\).
\end{enumerate}

\begin{definition}[Proof]\index{proof}
  For \(S \subseteq L, p \in L\), a \emph{proof} of \(p\) from \(S\) is a finite sentence of formulæ, ending with \(p\), such that each line is one of
  \begin{itemize}
  \item a logical axiom,
  \item a sentence of \(S\),
  \item following from earlier lines by modus ponens or generalisation.
  \end{itemize}
  Write \(S \yields p\) if there exists a proof of \(p\) from \(S\).
\end{definition}

\begin{note}\leavevmode
  \label{note:empty structure}
  \begin{enumerate}
  \item Each logical axiom is a tautology.
  \item If we allow the empty structure \(A\) (for a language with no constants), then \((\forall x) \bot \) holds in \(A\), and \(\bot\) deos not hold in \(A\), so
    \[
      ((\forall x) \bot) \implies \bot
    \]
    does not hold in \(A\), which is an instance of axiom 6. To resolve the issue, we can either obfuscate our axioms by adding more technical restrictions (of the form, for example, ``with \(x\) occurring bounded''), or simply ban empty structure.
  \end{enumerate}
\end{note}

\begin{eg}
  \(\{x = y, x = z\} \yields y = z\). The idea is to use axiom 5, with \(p\) being \(x = x\). But there are two quantifiers so we use axiom 6 to kill them.
  \begin{enumerate}
  \item \((\forall x) (\forall y) (x = y \implies (x = z \implies y = z))\), A5
  \item \((\forall x) (\forall y) (x = y \implies (x = z \implies y = z)) \implies (\forall y)(x = y \implies (x = z \implies y = z))\), A6
  \item \((\forall y) (x = y \implies (x = z \implies y = z))\), MP
  \item \((\forall y) (x = y \implies (x = z \implies y = z)) \implies (x = y \implies (x = z \implies y = z))\), A6
  \item \(x = y \implies (x = z \implies y = z)\), MP
  \item \(x = y\), hypothesis
  \item \(x = z \implies y = z\), MP
  \item \(x = z\), hypothesis
  \item \(y = z\), MP
  \end{enumerate}
\end{eg}

\begin{proposition}[Deduction theorem]\index{deduction theorem}
  Let \(S \subseteq L, p, q \in L\). Then \(S \yields (p \implies q)\) if and only if \(S \cup \{p\} \yields q\).
\end{proposition}

\begin{proof}\leavevmode
  \begin{itemize}
  \item \(\implies\): write down \(p\) and apply MP to obtain \(S \cup \{p\} \yields q\).
  \item As before, show \(S \yields p \implies t_i\) for each \(t_i\) in the proof of \(S \cup \{p\} \yields q\). The only new case is generalisation. So in proof of \(q\) from \(S \cup \{p\}\) we have line
    \begin{enumerate}
    \item \(r\)
    \item \((\forall x) r\)
    \end{enumerate}
    and have a proof of \((p \implies r)\) from \(S\), and we want \(S \yields (p \implies (\forall x) r)\). But in proof of \(r\) from \(S \cup \{p\}\), no premise had \(x\) free. Thus in proof of \((p \implies r)\) from \(S\), no proof had \(x\) free either. Hence \(S \yields (\forall x) (p \implies r)\) by generalisation. Now
    \begin{itemize}
    \item if \(x\) does not occur free in \(p\), have \(S \yields (p \implies (\forall x) r)\) by A6 and MP,
    \item if \(x\) does occur free in \(p\), proof of \(r\) from \(S \cup \{p\}\) cannot have used \(p\). So in fact \(S \yields (\forall x)r\), whence \(S \yields (p \implies (\forall x)r)\) by A1.
    \end{itemize}
  \end{itemize}
\end{proof}

\subsection{Gödel Completeness Theorem*}

\begin{proposition}[Soundness]\index{soundness}
  Let \(S \subseteq L, p \in L\). Then if \(S \yields p\) then \(S \models p\).
\end{proposition}

\begin{proof}
  Have proof of \(p\) from \(S\) and a model \(A\) of \(S\), want \(p_A = 1\). This is an easy induction down the lines of the proof.
\end{proof}

For adequacy, want if \(S \models p\) then \(S \yields p\), i.e.\ if \(S \cup \{\neg p\} \models \bot\) then \(S \cup (\neg p) \yields \bot\).

\begin{theorem}[Model existence lemma]\index{model existence lemma}
  \label{thm:model existence lemma}
  Let \(S \subseteq L\) be a set of sentences. Then if \(S\) is consistent then it has a model.
\end{theorem}

Note that some people call it the completeness theorem since it contains the majority of the work.

Unlike most other proofs we have met in tripos, this proof has not one, not two, but five key ideas:
\begin{enumerate}
\item To build a model out of a language, we first need a candidate structure. If you think about it carefully, we have no choice but to let \(A\) be a set of closed terms of \(L\), with ``obvious'' operations like \((1 + 1) +_A (1 + 1) = (1 + 1) + (1 + 1)\) in the example of fields.
\item Say \(S\) is the theory of fields, taking our above definition, \((1 + 1) + 1 \neq 1 + (1 + 1)\), but \(S \yields ((1 + 1) + 1 = 1 + (1 + 1))\). The solution is to quotient by
  \[
    s \sim t \text{ if } S \yields (s = t).
  \]
\item Suppose \(S\) is the theory of fields of characteristic \(2\) or \(3\), i.e.\ usual field axioms and \((1 + 1 = 0) \lor (1 + 1 + 1 = 0)\). Then \(S \nyields (1 + 1 = 0)\), so \([1 + 1] \neq [0]\). Also \(S \nyields (1 + 1 + 1 = 0)\), so \([1 + 1 + 1] \neq [0]\). Thus our structure does not satisfy \((1 + 1 = 0) \lor (1 + 1 + 1 = 0)\). Actually this is similar to the failure in attempting to define a valuation of a set \(S\) when we are proving model existence lemma for propositional logic: there are propositions implied by \(S\) but not in \(S\). Thus we need to extend \(S\) to be maximal consistent.
\item Suppose \(S\) is the theory of fields with a square root of \(2\), i.e.\ usual field axioms and \((\exists x) (xx = 1 + 1)\). In our constrution, maybe no closed term has \([tt] = [1 + 1]\). Thus \(S\) lacks ``witnesses''. Solution? For each \((\exists x) p\) in \(S\) add new constant \(c\) to language and add \(p[c/x]\) to \(S\).
\item Now our set may be no longer consistent, so loop back to step 3. But are we certain that the process will terminate?
\end{enumerate}

\begin{proof}
  Suppose we have \(S\) consistent contained in \(L_0 = L(\Omega, \Pi)\). Extend to maximal consistent \(S_1\) by Zorn's lemma. So for each sentence \(p \in L\), we have either \(p \in S_1\) or \((\neg p) \in S_1\). Thus \(S_1\) is complete (for every \(p\), either \(S_1 \yields p\) or \(S_1 \yields (\neg p)\)).

  Now add witnesses: for each \((\exists x) p \in S\), add new constant \(c\) and axiom \(p[c/x]\). We obtain \(T_1\), in language \(L_1 = L(\Omega \cup C_1, \Pi)\), where \(C_1\) is the set of all the \(c\)'s, that ``has witnesses'' for \(S_1\) (if \((\exists x)p \in S\), then some closed term \(t\) has \(p[t/x] \in T_1\)). Easy to check \(T_1\) is consistent.

  Now extend \(T_1\) to maximally consistent \(S_2\) in \(L_1\). Add witnesses, obtaining \(T_2\) in language \(L_2 = L(\Omega \cup C_1 \cup C_2, \Pi)\). Continue inductively.
  \[
    \begin{tikzcd}
      L_0 & L_1 & L_2 & \cdots \\
      S \ar[d, hook] \\
      S_1 \ar[r, squiggly] & T_1 \ar[d, hook] \\
      & S_2 \ar[r, squiggly] & T_2 \ar[d, hook] \\
      & & S_3 \ar[r, squiggly] & \cdots
    \end{tikzcd}
  \]

  Put \(\cl S = S_1 \cup S_2 \cup \dots\) in language \(\cl L = L(\cl \Omega, \Pi)\) where \(\cl \Omega = \Omega \cup C_1 \cup \cdots\). Check
  \begin{itemize}
  \item \(\cl S\) is consistent: if \(\cl S \yields \bot\) then some \(S_n \yields \bot\) as proofs are finite. Absurd.
  \item \(\cl S\) is complete: given sentence \(p \in \cl L\), have \(p \in L_n\) for some \(n\) as \(p\) contains only finitely many constants. So \(S_{n + 1} \yields p\) or \(S_{n + 1} \yields (\neg p)\).
  \item \(\cl S\) has witnesses (for itself): given \((\exists x) p \in \cl S\), have \((\exists x)p \in S_n\) for some \(n\). So \(p[t/x] \in T_n\) for some closed term \(t\) whence \(p[t/x] \in \cl S\).
  \end{itemize}

  On set of closed terms of \(\cl L\), define \(s \sim t\) if \(\cl S \yields (s = t)\), clearly an equivalence relation. Let the set of equivalence classes be \(A\). Make \(A\) into an \(\cl L\)-structure by setting
  \begin{itemize}
  \item \(f_A([t_1], \dots, [t_n]) = [ft_1, \dots, t_n]\) for each \(f \in \cl \Omega, \alpha(f) = n\), closed terms \(t_1, \dots, t_n\),
  \item \(\phi_A = \{([t_1], \dots, [t_n]): \cl S \yields \phi(t_1, \dots, t_n)\}\) for each \(\phi \in \Pi, \alpha(\phi) = n\), closed terms \(t_1, \dots, t_n\).
  \end{itemize}
  Claim that \(p_A = 1\) if and only if \(\cl S \yields p\) for each sentence \(p \in \cl L\) (then done since if \(A\) is a model of \(\cl S\) then it a model of \(S\)).

  \begin{proof}
    An easy induction:
    \begin{enumerate}
    \item atomic sentences:
      \begin{enumerate}
      \item \(\bot\): \(\bot_A = 0\) and \(\cl S \nyields \bot\).
      \item \(s = t\): \(\cl S \yields (s = t)\) if and only if \([s] = [t]\) by definition of \(\sim\), if and only if \(s_A = t_A\) by definition of operation on \(A\), if and only if \((s = t)_A = 1\).
      \item \(\phi(t_1, \dots, t_n)\): exactly the same.
      \end{enumerate}
    \item induction step:
      \begin{enumerate}
      \item \(p \implies q\): \(\cl S \yields (p \implies q)\) if and only if \(\cl S \yields (\neg p)\) or \(\cl S \yields q\) (only if: if not then \(\cl S \yields p, \cl S \yields (\neg q)\) (as \(\cl S\) is complete), whence \(\cl S \yields \neg(p \implies q)\)), if and only if \(p_A = 0\) or \(q_A = 1\) by induction, if and only if \((p \implies q)_A = 1\).
      \item \((\exists x) p\): \(\cl S \yields (\exists x) p\) if and only if \(\cl S \yields p[t/x]\) for some closed term \(t\) (only if: \(\cl S\) has witnesses), if and only if \(p[t/x]_A = 1\) for some closed term \(t\) by induction, if and only if \(((\exists x) p)_A = 1\) (if: \(A\) is the set of equivalence classes of closed terms).
      \end{enumerate}
    \end{enumerate}
  \end{proof}
\end{proof}

By remark before, have

\begin{corollary}[Adequacy]\index{adequacy}
  Let \(S \subseteq L, p \in L\). Then if \(S \models p\) then \(S \implies p\).
\end{corollary}

\begin{theorem}[Gödel completeness theorem for first-order logic]\index{completeness}\index{Gödel completeness theorem for first-order logic}
  \label{thm:Gödel completeness theorem}
  Let \(S\) be a set of sentences and \(p\) a sentence in language \(L\), then \(S \models p\) if and only if \(S \yields p\).
\end{theorem}

\begin{proof}\leavevmode
  \begin{itemize}
  \item \(\impliedby\): soundness.
  \item \(\implies\): adequacy.
  \end{itemize}
\end{proof}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item If \(L\) is countable (i.e.\ \(\Omega\) and \(\Pi\) are countable) then Zorn's lemma is not needed in the first step.
  \item ``First-order'' means that variables range over elements of our structure, not, for example, subsets thereof.
  \end{enumerate}
\end{remark}

\begin{theorem}[Compactness]\index{compactness theorem}
  Let \(S \subseteq L\) be a set of sentences. Then if every finite subset of \(S\) has a model then \(S\) has a model.
\end{theorem}

\begin{proof}
  Trivial if we replace \(\models\) with \(\yields\) as proof are finite.
\end{proof}

\begin{note}
  Unlike in propositional logic, there is no decidability theorem, since we don't know how to check if \(S \models t\).
\end{note}

Some consequences of compactness/completeness: let's think about axiomatisability of theories. We axiomatised the theory for groups, fields and graphs easily. Can we axiomatise the class of finite groups? In other words, we want some sentences \(S\) (in language of groups) such that a structure is a model for \(S\) if and only it is a finite group.

We may attempt to find some theorem that holds only for finite groups. For example, from IA Groups we may say that finiteness of conjugacy classes is a property of finite groups, but it also holds for the infinite group \(\Z\). We may go to IB Groups, Rings and Modules and even IID Representation Theory to find some more theorems, but they also holds for some infinite groups. This gives us the inkling that maybe we should look in the other direction. In fact,

\begin{corollary}
  The class of finite groups cannot be axiomatised (in language of groups).
\end{corollary}

\begin{remark}
  It is amazing that we can actually \emph{prove} this, as opposed to ``believing it might be true''.
\end{remark}

\begin{proof}
  Suppose \(S\) axiomatises finite groups. Add to \(S\) the sentences
  \begin{align*}
    & (\exists x_1) (\exists x_1) (\neg(x_1 = x_2)) \text{ (``order at least 2'')} \\
    & (\exists x_1) (\exists x_2) (\exists x_3) (\neg(x_1 = x_2) \land \neg(x_2 = x_3) \land \neg(x_3 = x_1)) \text{ (``order at least 3'')} \\
    & \quad \vdots
  \end{align*}
  Then every finite subset has a model (e.g.\ \(\Z/n\Z\) for \(n\) sufficiently large), but the set itself has no model, contradicting compactness.
\end{proof}

Similarly,

\begin{corollary}
  Let \(S\) be a theory in a language \(L\). Then if \(S\) has arbitrarily large finite models, then it has an infinite model.
\end{corollary}

\begin{proof}
  Add sentences as in the previous proof and apply compactness.
\end{proof}

The takeaway is: finiteness is not a first-order property.

\begin{corollary}[Upward Löwenheim-Skolem]\index{Löwenheim-Skolem theorem!upward}
  If a theory \(S\) has an infinite model then it has an uncountable model.
\end{corollary}

\begin{proof}
  Add uncountably many constants \(\{c_i\}_{i \in I}\) to the language and add to \(S\) the set of sentences ``\(\neg(c_i = c_j)\)'' for each distinct \(i, j \in I\). Then any finite subset has a model (e.g.\ any infinite model of \(S\)), so the whole set has a model by compactness.
\end{proof}

Similarly, we could find a model into which \(\powerset (\powerset(\R))\) injects, by letting it be the indexing set.

\begin{eg}
  We know there is an infinite field \(\Q\), thus there exists a field of the same size as \(\powerset (\powerset(\R))\).
\end{eg}

\begin{corollary}[Downward Löwenheim-Skolem]\index{Löwenheim-Skolem theorem!downward}
  Let \(S\) be a theory in a countable language \(L\). Then if \(S\) has a model then it has a countable model.
\end{corollary}

\begin{proof}
  The model constructed in \nameref{thm:model existence lemma} in \(\cl S\) is countable.
\end{proof}

Note that this theorem and its proof \emph{are} examinable.

\subsection{Peano Arithmetic}

We try to make the usual axioms of \(\N\) into a first-order theory.

\begin{definition}[Peano arithmetic]\index{Peano arithmetic}
  \emph{Peano arithmetic} (PA) or \emph{formal number theory} has language \(L\) consist of \(\Omega = \{0, s, + ,\times\}\) where \(\alpha(0) = 0\), \(\alpha(s) = 1\) is the \emph{successor}, \(\alpha(+) = \alpha(\times) = 2\). \(\Pi = \emptyset\). The axioms are
  \begin{enumerate}
  \item \((\forall x) \neg(s(x) = 0)\).
  \item \((\forall x)(\forall y) (s(x) = s(y) \implies x = y)\).
  \item \((\forall y_1)\cdots (\forall y_n) ((p[0/x] \land (\forall x) (p \implies p[s(x)/x])) \implies (\forall x) p)\) where the quantifiers in front are parameters, for each formula \(p\) and free variables \(x, y_1, \dots, y_n\).
  \item \((\forall x) (x + 0 = x)\).
  \item \((\forall x) (\forall y) (x + s(y) = s(x + y))\).
  \item \((\forall x) (x \times 0 = 0)\).
  \item \((\forall x)(\forall y) (x \times s(y) = s \times y + x)\).
  \end{enumerate}
\end{definition}

\begin{note}
  The 3rd axiom is the induction axiom. Our first guess would have been
  \[
    (p[0/x] \land (\forall x) (p \implies p[s(x)/x])) \implies (\forall x) p,
  \]
  but then we miss properties like \(x \geq y\) where \(y\) is chosen earlier.
\end{note}

PA has an infinite model \(\N\) so by upward Löwenheim-Skolem, it has an uncountable model, which is not isomorphic to \(\N\). Doesn't this contradict the fact that the usual axioms characterise \(\N\) uniquely?

The answer is no: axiom 3 is only ``first-order'' induction. Even in \(\N\) itself, it refers to only countably many subsets, as opposed to true induction, which talks about the uncountably many subsets of \(\N\).

Note that in PA the only constant is \(0\). We write \(1 = s(0), 2 = 1 + 1 = s(1)\) etc.

\begin{definition}[Definable]\index{definable}
  A subset \(S \subseteq \N\) is called \emph{definable} if there exists a formula \(p \in L\) and free variable \(x\) such that for all \(m \in \N\) we have \(m \in S\) if and only if \(p[m/x]\) holds in \(\N\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item The set of square numbers. \(p(x)\) is \((\exists x) (y \times y = x)\).
  \item The set of primes. \(p(x)\) is \(\neg (x = 0) \land \neg (x = 1) \land (\forall y) (y \divides x \implies y = 1 \lor y = x)\) where \(y \divides x\) means \((\exists z) (y \times z = x)\). 
  \item Powers of \(2\). \(p(x)\) is \((\forall x) ((y \divides x \land y \text{ prime}) \implies y = 2)\).
  \end{enumerate}
\end{eg}

\begin{ex}
  Write down the defining formula for the following sets:
  \begin{enumerate}
  \item powers of \(4\).
  \item powers of \(6\).
  \end{enumerate}
\end{ex}

The key question we are concerned with is: is PA a complete theory? In other words, for each sentence \(p\), is it true that PA \(\yields p\) or PA \(\nyields \neg p\)?

\begin{theorem}[Gödel incompleteness theorem]\index{Gödel incompleteness theorem}
  PA is not complete.
\end{theorem}

Take \(p\) with PA \(\nyields p\) and PA \(\nyields \neg p\). Then we have \(p\) or \(\neg p\) holds in \(\N\), although we cannot prove it. Thus there the conclusion is there exists a sentence \(p\) such that \(p\) is true in \(\N\) but PA \(\nyields p\).

Note that this \emph{doesn't} contradict \nameref{thm:Gödel completeness theorem} which says that if \(p\) is true in \emph{all} models of PA then PA \(\yields p\).

\section{Set Theory}

The aim of this chapter is to answer the question, what does ``the universe of set'' look like? The key starting point is to view set theory as just another first order theory. There are many formulations of set theory and we will take Zermelo-Fraenkel set theory.

\subsection{Zermelo-Fraenkel Set Theory}

\begin{definition}[Zermelo-Fraenkel set theory]\index{Zermelo-Fraenkel set theory}
  \emph{Zermelo-Fraenkel set theory} (ZF) has language \(L\) consisting of \(\Omega = \emptyset, \Pi = \{\in\}, \alpha(\in) = 2\) with the ZF axioms (to be stated below).
\end{definition}

There are 9 ZF axioms in total: 2 to get started, 4 to build things and the last 3 might not be the things we would have thought of at first.

\begin{axiom*}[Axiom of extension]
  \[
    (\forall x) (\forall y) ((\forall z) (z \in x \iff z \in y) \implies x = y).
  \]
\end{axiom*}
``If two sets have the same member, then they are equivalent.''

\begin{note}
  The converse is also true, which is an instance of logical axiom.
\end{note}

\begin{axiom*}[Axiom of separation]
  \[
    (\forall t_1) \cdots (\forall t_n) (\forall x) (\exists y) (\forall z) (z \in y \iff (z \in x \land p(z)))
  \]
  for each formula \(p(x)\) and free variables \(x, t_1, \dots, t_n\).
\end{axiom*}
``We can form a subset of a set.'' More precisely, given a set \(x\) and a property \(z\), we can form \(\{z \in x: p(z)\}\).

\begin{note}
  We do want parameters, e.g.\ to have \(\{z \in x: t \in z\}\) where \(t\) is chosen earlier.
\end{note}

\begin{axiom*}[Axiom of empty set]
  \[
    (\exists x) (\forall y) \neg (y \in x).
  \]
\end{axiom*}
``There is a set with no member.''

We write \(\emptyset\) for the unique (by axiom of extension) such set \(x\). This is just an abbreviation: \(p(\emptyset)\) means \((\exists x) ((\forall y) (\neg y \in x) \land p(x))\).

Similarly, we write \(\{z \in x: p(z)\}\) for sets formed by axiom of separation.

\begin{axiom*}[Axiom of pair set]
  \[
    (\forall x) (\forall y) (\exists z) (\forall t) (t \in z \iff t = x \lor t = y).
  \]
\end{axiom*}
``We can form \(\{x, y\}\).''

We write \(\{x, y\}\) for this set, and \(\{x\}\) for \(\{x, x\}\). Now we can defined an ordered pair:

\begin{definition}[Ordered pair]\index{ordered pair}
  An \emph{ordered pair} \((x, y)\) is \(\{\{x\}, \{x, y\}\}\).

  \(x\) is an ordered pair if \((\exists y) (\exists z) (x = (y, z))\).
\end{definition}

It is easy to check that \((x, y) = (t, u) \iff (x = t \land y = u)\) using axioms we have so far.

\begin{definition}[Function]\index{function}
  \(f\) is a \emph{function} if
  \begin{align*}
    &(\forall x) (x \in f \implies x \text{ an ordered pair}) \\
    \land & (\forall x) (\forall y) (\forall z) ((x, y) \in f \land (x, z) \in f \implies y = z).
  \end{align*}

  The \emph{domain} of a function \(f\), written \(x = \dom f\), is such that
  \[
    (f \text{ a function}) \land (\forall z) (z \in x \iff (\exists t) ((z, t) \in f)).
  \]

  Write \(f: x \to y\) for
  \[
    (f \text{ a function}) \land (x = \dom f) \land (\forall z) ((\exists t) (t, z) \in f) \implies z \in y.
  \]
\end{definition}

\begin{axiom*}[Axiom of union]
  \[
    (\forall x) (\exists y) (\forall z) (z \in y \iff (\exists t) (z \in t \land t \in x)).
  \]
\end{axiom*}
``We can form unions.''

\begin{axiom*}[Axiom of power set]
  \[
    (\forall x) (\exists y) (\forall z) (z \in y \iff z \subseteq x).
  \]
  where \(z \subseteq x\) means \((\forall t) (t \in z \implies t \in x)\).
\end{axiom*}
``We can form power sets.''

\begin{note}\leavevmode
  \begin{enumerate}
  \item We write \(\bigcup x\) and \(\powerset(x)\) for the two sets. We also write \(x \cup y\) for \(\bigcup \{x, y\}\) etc.
  \item No extra axiom is needed for intersections: we can form \(\bigcap x\) (with \(x \neq \emptyset\)) as a subset of \(y\) for any \(y \in x\), which can be done by axiom of separation.
  \item We can now form Cartesian product of sets \(x \times y\) as a suitable subset of \(\powerset(\powerset(x \cup y))\): since if \(t \in x, u \in y\) then \((t, u) = \{\{t\}, \{t, u\}\} \in \powerset(\powerset(x \cup y))\).
  \item Similarly we can form the set of all functions from \(x\) to \(y\), as a subset of \(\powerset(x \times y)\).
  \end{enumerate}
\end{note}

The axioms so far should be quite intuitive. The next three are more subtle. Note that so far a model \(V\) of ZF must be infinite. For example, write \(x^+ = x \cup \{x\}\), then it is easy to check \(\emptyset, \emptyset^+, \emptyset^{++}, \dots\) are all distinct. We often write \(0\) for \(\emptyset\), \(1\) for \(\emptyset^+\), \(2\) for \(\emptyset^{++}\) etc, so
\begin{align*}
  1 &= \{0\} \\
  2 &= \{0, 1\} \\
  3 &= \{0, 1, 2\} \\
  \vdots
\end{align*}
But this shows that \(V\) is infinite, which is not the question we are interested in. We want to know whether \(V \) has an infinite set, e.g.\ an \(x\) such that \(\emptyset \in x, \emptyset^+ \in x\) etc.

\begin{definition}[Successor set]\index{successor set}
  \(x\) is a \emph{successor set} if
  \[
    (\emptyset \in x) \land (\forall y) (y \in x \implies y^+ \in x).
  \]
\end{definition}

\begin{axiom*}[Axiom of infinity]
  \[
    (\exists x) (x \text{ a successor set}).
  \]
\end{axiom*}
``There is an infinite set.''

Note that any intersection of successor sets is a successor set, so there exists a least one. Call it \(\omega\). This will be our version in \(V\) of \(\N\). Therefore
\[
  (\forall x) (x \in \omega) \iff (\forall y) (y \text{ a successor set} \implies x \in y).
\]
Note that if \(x \subseteq \omega\) is a successor set then \(x = \omega\) by definition, i.e.
\[
  (\forall x) (x \subseteq \omega \land \emptyset \in x \land (\forall y) (y \in x \implies y^+ \in x)) \implies x = \omega.
\]
This is \emph{\(\omega\)-induction}\index{\(\omega\)-induction}. Note this is genuine induction in \(V\) over all subsets \(x \subseteq \omega\), as opposed to first order induction in PA.

It is also easy to check that
\begin{align*}
  & (\forall x) (x \in \omega) \implies \neg (x^+ = \emptyset) \\
  & (\forall x) (\forall y) (x \in \omega \land y \in \omega \land x^+ = y^+) \implies x = y
\end{align*}
Thus \(\omega\) satisfies (in \(V\)) all the usual axioms for the natural numbers.

Subsequently, we say \(x\) is \emph{finite} if \((\exists y) (y \in \omega \land x \text{ bijects with } y)\). Then \(x\) is \emph{countable} if \(x\) is finite or \(x\) bijects with \(\omega\). \(x\) is \emph{infinite} if it is not finite.

\begin{axiom*}[Axiom of foundation]
  \[
    (\forall x) (x \neq \emptyset \implies (\exists y) (y \in x \land (\forall z) (z \in x \implies \neg (z \in y)).
  \]
\end{axiom*}
``Sets are built up from simpler sets'', or every (non-empty) set has an \(\in\)-minimal member.

The intuition behind is like this: we want to disallow \(x \in x\) to avoid possible contradiction, \(x \in y \land y \in x\) to agree with our intuition that ``sets have a hierarchy'', and also infinite chains \(\dots \in x_3 \in x_2 \in x_1 \in x_0\). What is common to all of them is that they do not have a \(\in\)-minimal element: \(\{x\}\), \(\{x, y\}\) and \(\{x_0, x_1, \dots\}\) respectively do not have such an element in the above examples.

For our next axiom, we want if for each \(i \in I\) we have \(A_i\), then we can take \(\{A_i: i \in I\}\). But how do we know that \(\{A_i: i \in I\}\) is a set? One may say that ``\(i \mapsto A_i\)'' looks like a function, so the image is a set. What recall that functions are also sets, but is this rule a set?

This one is different from previous axioms we have. So far every axiom allows us to build a new set ``near'' the one in the universe we starting with, e.g.\ power set, union set. However, this one goes far out to \(V\) from \(I\).

Thus what we really want to say is ``the image of a set, under something that looks like a function, is a set.'' See \Cref{sec:classes} for a discussion on how to formalise this idea using classes.

\begin{axiom*}[Axiom of replacement]
  \begin{align*}
    & (\forall t_1) \cdots (\forall t_n) \underbrace{((\forall x) (\forall y) (\forall z) ((p \land p[z/y]) \implies y = z))}_{p \text{ a function-class}} \\
    \implies & \underbrace{((\forall x) (\exists y) (\forall z) (z \in y \iff (\exists t) (t \in x \land p[t/x, z/y])))}_{\text{image of \(x\) under \(p\) is a set}}
  \end{align*}
  for each formula \(p\), free variables \(x, y, t_1, \dots, t_n\).
\end{axiom*}
``The image of a set under a function-class is a set.''

Intuitively we think this axiom exactly as what the slogan says, but since classes are not part of the structure, formally we have to substitute the function-class with the (first order) rule.

Note that this holds also for partial functions.

\begin{eg}
  For any set \(x\), can form \(\{\{t\}: t \in x\}\), with function-class \(t \mapsto \{t\}\). This is a ``bad'' example as we don't actually need axiom of replacement to know this is a set. See later for ``good'' examples.
\end{eg}

Those are all the ZF axioms.

\begin{note}\leavevmode
  \begin{enumerate}
  \item Sometimes axiom of separation is called ``axiom of comprehension'' and axiom of foundation is called ``axiom of regularity''.
  \item ZF axioms do not include axiom of choice. ZF~\(+\)~AC is called ZFC where
  \end{enumerate}
\end{note}
\begin{axiom*}[Axiom of choice]
  \begin{align*}
    & (\forall f) (f \text{ a function} \land (\forall x) (x \in \dom f \implies \neg (f(x) = \emptyset)) \\
    \implies & (\exists g) (g \text{ a function} \land \dom g = \dom f \land (\forall x) (x \in \dom f \implies g(x) \in f(x)))).
  \end{align*}
\end{axiom*}
``Every family of (non-empty) sets has a choice function.''

\begin{remark}
  We have not proven ZF is consistent, i.e.\ there exists a model of ZF. Sadly, by one of Gödel incomplete theorem ZF~\(\nyields\)~``ZF has a model'', so no proof in ordinary maths (including ZF, ZFC etc).
\end{remark}

In this course, every theorem we prove about ZF will be preceded with the premise that, either explicitly or implicitly, it holds in a model of ZF. Thus incompleteness does not pose a problem to our theory, although to make some practical sense out of the theory, we better have some faith in the existence of such a model!

\subsection{Properties of ZF}

\begin{definition}[Transitive]
  \(x\) is \emph{transitive} if every member of a member of \(x\) is itself a member of \(x\):
  \[
    (\forall y) ((\exists z) (y \in z \land z \in x) \implies y \in x),
  \]
  i.e.\ \(\bigcup x = x\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(2 = \{\emptyset, \{\emptyset\}\}\) is transitive.
  \item \(\omega\) is transitive as \(n = \{0, 1, \dots, n - 1\}\) for all \(n \in \omega\).
  \end{enumerate}
\end{eg}

\begin{lemma}
  Every set \(x\) is contained in a transitive set.
\end{lemma}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item It officially says: let \((V, \in)\) be a model of ZF, then in \(V\) this statement holds, or equivalently, ZF~\(\yields\)~the statement.
  \item Any intersection of transitive sets is transitive, so we will know that there exists a \emph{least} transitive set containing \(x\), called the \emph{transitive closure}\index{transitive closure} of \(x\), written \(TC(x)\).
  \end{enumerate}
\end{remark}

\begin{proof}
  Consider \(x \cup (\bigcup x) \cup (\bigcup \bigcup x) \cup \dots\), which is the obvious step to take. This is a set by axiom of union applied to
  \[
    \{x, \bigcup x, \bigcup \bigcup x, \dots\},
  \]
  which is a set by axiom of replacement applied to the function-class
  \begin{align*}
    0 &\mapsto x \\
    1 &\mapsto \bigcup x \\
    2 &\mapsto \bigcup \bigcup x \\
    \vdots
  \end{align*}
  But why is this a function-class? We can't use recursion since that would be circular logic. Again we use the clever idea of attempts.

  Define ``\(f\) is an attempt'' to mean
  \begin{align*}
    & (f \text{ a function}) \land (\dom f \in \omega) \land (\dom f \neq \emptyset) \\
    \land & (f(0) = x) \land (\forall n) (n \in \dom f \land n \neq 0 \implies f(n) = \bigcup f(n - 1)).
  \end{align*}
  Then attempts exist, i.e.
   \[
    (\forall n \in \omega) (\exists f) (f \text{ attempt} \land n \in \dom f)
  \]
  and are unqiue wherever they are defined, i.e.
  \begin{align*}
    & (\forall m \in \omega) (\forall f) (\forall f') ((f, f' \text{ attempts} \land n \in \dom f \land n \in \dom f') \\
    \implies & f(n) = f'(n))
  \end{align*}
  by \(\omega\)-induction. So take \(p(y, z)\) to be
  \[
    (\exists f) (f \text{ an attempt} \land y \in \dom f \land f(y) = z).
  \]
\end{proof}

\begin{remark}
  This is a ``good'' use of axiom of replacement.
\end{remark}

Now let's take a look at axiom of foundation. THe slogan says ``sets are built out of simpler set'', but does it achieve what it claims to do, or are we just banning things randomly for no reason? Actually there exists a good test: if the slogan is true, then suppose \(p(y) \forall \in x\) implies \(p(x)\), we have \(p(x) \forall x\), 

\begin{theorem}[Principle of \(\in\)-induction]\index{\(\in\)-induction}
  Let \(p\) be a formula, free variables \(x, t_1, \dots, t_n\). Then
  \[
    (\forall t_1) \cdots (\forall t_n) ((\forall x) (\forall y) (y \in x \implies p(y)) \implies p(x)) \implies (\forall x) p(x)
  \]
  where \(p(y)\) means \(p[y/x]\), \(p(x)\) means \(p\).
\end{theorem}

\begin{proof}
  Given \(t_1, \dots, t_n\), have \(p(y) \forall y \in x \implies p(x)\), and suppose \((\forall x) p(x)\) is not true, so \((\exists x) (\neg p(x))\). We want to say: ``choose \(\in\)-minimal of \(\{x: \neg p(x)\}\)'', then contradiction. But this might not be a set, e.g.\ if \(p(x)\) is \(x \neq x\). This is where transitive closure comes in.

  Let \(t = TC(\{x\})\) so \(x \in t\) and \(\neg p(x)\). Let \(u = \{y \in t: \neg p(y)\}\) and let \(y\) be an \(\in\)-minimal element of \(u\). Then \(\neg p(y)\). But \((\forall z \in y) p(z)\) (as \(z \in y \implies z \in t\) and \(y\) is \(\in\)-minimal in \(n\)), contradiction.
\end{proof}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item We used existence of transitive closure in the proof, i.e.\ the lemma above.
  \item In fact, \(\in\)-induction is equivalent to the axiom of foundation, as we can deduce axiom of foundation from \(\in\)-induction (in the presence of the other axioms): say ``\(x\) is regular'' if
    \[
      (\forall y) (x \in y \implies y \text{ has an \(\in\)-minimal element}).
    \]
    Then axiom of foundation says every set is regular. To prove this by \(\in\)-induction, given \(y\) regular for all \(y \in x\), want \(x\) to be regular. For \(x \in z\), if \(x\) is minimal then done.If not, some \(y \in x\) has \(y \in z\). But \(y\) is regular so \(z\) has a minimal element.
  \end{enumerate}
\end{remark}

Now we have induction, what about recursion? We want ``\(f(x)\) defined in terms of the \(f(y)\) where \(y \in x\)''.

\begin{theorem}[\(\in\)-recursion theorem]\index{\(\in\)-recursion}
  Let \(G\) be a function-class everywhere defined. Then there is a function class \(F\) (i.e.\ \((x, y) \in F \iff p(x, y)\) for some formula \(p)\) such that
  \[
    (\forall x) (F(x) = G(F|_x)).
  \]
  Moreover, \(F\) is unique.
\end{theorem}

\begin{note}
  \(F|_x = \{(z, F(z)): z \in x\}\) is a set by axiom of replacement.
\end{note}

\begin{proof}
  Say ``\(f\) is an attempt'' if
  \[
    (f \text{ a function}) \land (\dom f \text{ transitive}) \land (\forall x) (x \in \dom f \implies f(x) = G(f|_x)).
  \]
  Note that \(f|_x\) is defined as \(\dom f\) is transitive. Then
  \[
    (\forall x) (f, f' \text{ attempts defined at } x \implies f(x) = f'(x))
  \]
  by \(\in\)-induction since if \(f\) and \(f'\) agree at all \(y \in x\) then they agree at \(x\). Also
  \[
    (\forall x) (\exists \text{ an attempt \(f\) defined at } x)
  \]
  by \(\in\)-induction. Indeed suppose \((\forall y \in x) (\exists \text{ an attempt defined at } x)\). So \(\forall y \in x\) there exists a unique attempt \(f_y\) defined of \(TC(\{y\})\). Put \(f = \bigcup_{y \in x} f_y\) and now put
  \[
    f' = f \cup \{(x, G(f|_x))\}.
  \]
  So done by taking \(q(x, y)\) to be
  \[
    (\exists f) (f \text{ an attempt} \land x \in \dom f \land f(x) = y).
  \]
  Uniqueness follows from \(\in\)-induction.
\end{proof}

\begin{note}
  \(\in\)-induction and \(\in\)-recursion proofs look very similar to induction and recursion from chapter 2.
\end{note}

What properties of the ``relation-class'' \(\in\) (i.e.\ the formula \(p(x, y) = x \in y\)) have we used?

\begin{enumerate}
\item \(p\) is well-founded: every non-empty set has a \(p\)-minimal element. We used it to make everything work.
\item \(p\) is local: \(\{y: p(y, x)\}\) is a set for each \(x\). We used this to build \(p\)-closure, i.e.\ transitive closure.
\end{enumerate}

So in fact we have \(p\)-induction and \(p\)-recursion for any \(p(x, y)\) that is well-founded and local. In particular, for a relation \(r\) on a set \(a\), trivially \(r\) is local (as \(a\) is a set), so to have \(r\)-induction and \(r\)-recursion, just need \(r\) to be well-founded. Thus with this view in mind, induction and recursion from chapter 2 are special cases of this.

Recall that in chapter 2, we spend effort on induction so as to prove subset collapse. Here something similar happens: can we ``model'' a relation by \(\in\)?

For example, let \(a = \{a_1, a_2, a_3\}\) and \(r = \{(a_1, a_2), (a_2, a_3)\}\). Can we build a set \(b\) with the same relations but using \(\in\)? i.e.\ can we find \(b = \{b_1, b_2, b_3\}\) and relation \(s\) defined by \(b_i s b_j \iff b_i \in b_j\), and \((a, r)\) is isomorphic to \((b, s)\)? Certainly yes. We put \(b_1 = \emptyset, b_2 = \{\emptyset\}, b_3 = \{\{\emptyset\}\}\). Then \(a_i r a_j \iff b_i s b_j\) for all \(i, j\). Moreover \(b\) is transitive.

Can we do this for all relations? Well not for all, since for example, axiom of foundation forbides the relation \(x r x\).

\begin{definition}[Extensionality]\index{extensionality}
  A relation \(r\) on a set \(a\) is \emph{extensional} if
  \[
    (\forall x, y \in a) ((\forall z \in a) (z r x \iff z r y) \implies x = y).
  \]
\end{definition}

\begin{eg}
  \(a\) in the example above the definition, the relation \(\in\) on any transitive set.
\end{eg}

The analogue of subset collapse is

\begin{theorem}[Mostowski's collapsing theorem]\index{Mostowski's collapsing theorem}
  \label{thm:Mostowski}
  Let \(r\) be a relation on a set \(a\) that is well-founded and extensional. Then there exists a transitive set \(b\) and bijection \(f: a \to b\) such that
  \[
    (\forall x, y \in a) (x r y \iff f(x) \in f(y)).
  \]
  Moreover \(b\) and \(f\) are unique.
\end{theorem}

\begin{proof}
  This is basically \(r\)-recursion: once the images of all elements relate to \(a_n\) are fixed, we have no choice for \(f(a_n)\) but let it be the set of images of all those things.

  Define \(f(x) = \{f(y): y r x\}\), which is a definition by \(r\)-recursion on the set \(a\), which should be the only sensible thing to try. Note that \(f\) is a function, not just a function-class, as it is an image of the set \(a\).

  Let \(b = \{f(x): x \in a\}\), which is a set by axiom of replacement. Then \(b\) is transitive by definition of \(f\), and \(f\) is surjective by definition of \(b\). If we can show \(f\) injective, then we also have \(x r y \iff f(x) \in f(y)\). We will show that
  \[
    (\forall x \in a) (\forall y) (f(y) = f(x) \implies y = x)
  \]
  by \(r\)-induction on \(x\). So given \(y\) with \(f(y) = f(x)\), want \(y = x\), with the assumption that
  \[
    (\forall t) (\forall u) ((t, u \in a \land t r x \land f(u) = f(t)) \implies u = t).
  \]
  From \(f(y) = f(x)\), we have
  \[
    \{f(u): u r y\} = \{f(t): t r x\}
  \]
  whence \(\{u: u r y\} = \{t: t r x\}\) by induction assumption. Thus \(x = y\) as \(r\) is extensional.

  For uniqueness, if \(f\) and \(f'\) are both suitable then \((\forall x \in a) (f(x) = f'(x))\) by \(r\)-induction.
\end{proof}

Now we can do something that is owed from chapter 2. We defined ordinals to be equivalent classes of well-orderings, with two well-orderings regarded the same if there is an order-isomorphisms between them. But a hiccup is that the set of all well-orderings do not form a set so ``equivalence class'' does not make sence. Now we can instead define it formally in the language of ZF.

\begin{definition}[von Neumann ordinal]\index{ordinal!von Neumann}
  An \emph{ordinal} or \emph{von Neumann ordinal} is a transitive set that is well-ordered by \(\in\).
\end{definition}

Note that by by axiom of foundation, we can say instead ``totally ordered by \(\in\)''.

\begin{eg}
  \(\emptyset\), \(\{\emptyset\}\), any \(n \in \omega\), \(\omega\) itself.
\end{eg}

\nameref{thm:Mostowski} tells us that any well-ordered \(X\) is order-isomorphic to a unique ordinal \(\alpha\). Say \(X\) has \emph{order-type} \(\alpha\).

\begin{remark}[Irrelevant remark]
  We know that for every ordinal \(\alpha\), have \(\{\beta: \beta < \alpha\}\) is a well-order of order-type \(\alpha\). Hence by definition of \(f\) in \nameref{thm:Mostowski},
  \[
    \alpha < \beta \iff \alpha \in \beta
  \]
  so \(\alpha = \{\beta: \beta < \alpha\}\),
  % i.e.\ they are not only order-isomorphic but are exactly the same thing.
  For example, \(\omega = \{0, 1, 2, \dots\}\).

  Thus the successor for ordinal is the same as the successor for set. For example,
  \begin{align*}
    \alpha^+ &= \alpha \cup \{\alpha\} \\
    \sup \{\alpha_i: i \in I\} &= \bigcup \{\alpha_i: i \in I\}
  \end{align*}
  although this might not be the most useful way to view things.
\end{remark}

\subsection{Picture of the Universe}

In this section we build the universe of sets, where everything in mathematics takes place\footnote{One might be tempted to think of this as a model of ZFC, or at least modulo some set vs class technicality, but there are many reasons not to do so, one of them being the violation of axiom of foundation. Curiously, ``universe'' may also in other context refer to the opposite, namely a model of ZFC (of course assuming consistency whereof).}\footnote{If you don't understand the previous footnote then don't worry and move on, since it's probably not intended for you!}, starting with \(\emptyset\) and taking power set many times.

\begin{definition}[von Neumann hierarchy]\index{von Neumann hierarchy}
  For each ordinal \(\alpha\), define set \(V_\alpha\) by recursion:
  \begin{align*}
    V_0 &= \emptyset \\
    V_{\alpha + 1} &= \powerset(V_\alpha) \\
    V_\lambda &= \bigcup_{\alpha < \lambda} V_\alpha \text{ for \(\lambda\) a non-zero limit}
  \end{align*}
\end{definition}

How do we know this is the whole universe? We want to show every set \(x\) belongs to some \(V_\alpha\).

\begin{lemma}
  Each \(V_\alpha\) is transitive.
\end{lemma}

\begin{proof}
  Induction on \(\alpha\):
  \begin{itemize}
  \item \(0\): done.
  \item successors: given \(x \in y \in V_{\alpha + 1}\), have \(y \in \powerset(V_\alpha)\) so \(x \in V_\alpha\) so \(x \subseteq V_\alpha\), i.e.\ \(x \in \powerset(V_\alpha) = V_{\alpha + 1}\).
  \item limits: any union of transitive sets is transitive.
  \end{itemize}
\end{proof}

\begin{lemma}
  \(V_\alpha \subseteq V_\beta\) whenever \(\alpha \leq \beta\).
\end{lemma}

\begin{proof}
  Induction on \(\beta\) with \(\alpha\) fixed:
  \begin{itemize}
  \item \(\beta = \alpha\): done.
  \item successors: given \(V_\alpha \subseteq V_\beta\), want \(V_\alpha \subseteq \powerset(V_\beta)\). But \(V_\beta \subseteq \powerset(V_\beta)\): \(x \in V_\beta\) implies \(x \subseteq V_\beta\) by transitivity of \(V_\beta\).
  \item limits: obvious.
  \end{itemize}
\end{proof}

\begin{theorem}
  \[
    (\forall x) (\exists \alpha) (x \in V_\alpha).
  \]
\end{theorem}

The slogan is ``the universe is the union of sets'', or the suggestive identity \(V = \bigcup_{\alpha \in ON} V_\alpha\) where \(ON\) is the class of ordinals. Note the subtlety hidden in the notation: you cannot take union of a family indexed by a proper class! (or more pedantically, nothing prevents you except that the result is not a set)

\begin{note}\leavevmode
  \begin{itemize}
  \item \(x \subseteq V_\alpha \iff x \in V_{\alpha + 1}\).
  \item If \(x \subseteq V_\alpha\), then there exists \emph{least} such \(\alpha\), which we call the \emph{rank}\index{rank} of \(x\).
  \end{itemize}
\end{note}

\begin{eg}
  \begin{align*}
    \rank(\emptyset) &= 0 \\
    \rank(\{\emptyset\}) &= 1 \\
    \rank(\omega) &= \omega
  \end{align*}
  and \(\rank(\alpha) = \alpha\) for all ordinal \(\alpha\) by induction.
\end{eg}

\begin{proof}
  We will show that \((\forall x) (\exists \alpha) (x \subseteq V_\alpha)\) by \(\in\)-induction. Given \(x\), for each \(y \in x\), we have \(y \subseteq V_\alpha\) for some \(\alpha\), so \(y \subseteq V_{\rank(y)}\), i.e.\ \(y \in V_{\rank(y) + 1}\). 
  Let \(\alpha = \sup\{\rank(y) + 1: y \in x\}\), then \(x \subseteq V_\alpha\).
\end{proof}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item What the proof says essentially is
    \[
      \rank(x) = \sup\{\rank(y) + 1: y \in x\},
    \]
    which is the right way to think about rank. For example, \(\rank(\{6\})\) is \(7\) as \(\rank(6) = 6\) since it is an ordinal.
  \item Most of maths takes place in \(V_{\omega + 10}\), except in this course when we discussed order-types!
  \end{enumerate}
\end{remark}

\section{Cardinals}

We will discuss ``sizes'' of sets in this chapter. We will work predomiantly under ZFC, insofar not refraining ourselves from comparing and contrasting results under ZF.

\subsection{Definitions}

We want to define \(\card x\) so that \(\card x = \card y\) if and only if \(x \biject x\). We cannot define it naïvely by
\[
  \card x = \{y: y \biject x\}
\]
as this may not be a set. But we do know \(x \biject \alpha\) for some ordinal \(\alpha\) so we can define \(\card x\) to be the least such \(\alpha\). It follows that \(\card x = \card y\) if and only if \(x \biject y\).

If we choose to work without axiom of choice, among all \(y\) that bijects with \(x\), we need to pick one. This seems impossible without choice, but we have the clever \emph{Scott trick}: define the \emph{essential rank} of \(x\) \(\operatorname{essrank}(x)\) to be the least rank of any \(y\) that bijects with \(x\), and then define \(\card x = \{y \subseteq V_{\operatorname{essrank}(n)}: y \biject x\}\).

\begin{definition}[Cardinal]\index{cardinal}
  \(m\) is a \emph{cardinal} or a \emph{cardinality} if \(m = \card x\) for some \(x\).
\end{definition}

For cardinals \(m\) and \(n\), say \(m \leq n\) if \(M\) injects into \(N\) for some \(M\) and \(N\) with \(\card M = m, \card N = n\) (which does not depend on the choice of \(M\) and \(N\)). Similarly, write \(m < n\) if \(m \leq n\) and \(m \neq n\). For example, \(\card \omega < \card \powerset(\omega)\).

Note that if \(m \leq n, n \leq m\) then \(m = n\) by Schröder-Berstein. So \(\leq\) is a partial order, and even a total order (by well-ordering). Note that in ZF \(\leq\) need not be a total order.

What do the cardinals look like? Of course there are the finite (i.e.\ boring) ones. Note that not all ordinals are cardinals as for example \(\omega \biject \omega + 1\).

\begin{definition}[Initial ordinal]\index{initial ordinal}
  An ordinal \(\alpha\) is \emph{initial} if for all \(\beta < \alpha\), \(\beta\) does not biject with \(\alpha\).
\end{definition}

\begin{eg}
  \(0, 1, 2, \dots, \omega, \omega_1, \gamma(X)\) for any set \(X\) are initial ordinals. However \(\omega^2\) is not initial as \(\omega^2 \biject \omega\).
\end{eg}

How do we get all the initial ordinals then? Obviously we have \(\omega = \omega_0, \omega_1 = \gamma(\omega_0), \omega_2 = \gamma(\omega_1), \dots\). Think a little longer and we find their supremum \(\omega_\omega = \sup \{\omega_n: n = 0, 1, \dots\}\) is also initial as otherwise...

Define \(\omega_\alpha\), for each ordinal \(\alpha\), recursively by
\begin{align*}
  \omega_0 &= \omega \\
  \omega_{\alpha + 1} &= \gamma(\omega_\alpha) \\
  \omega_\lambda &= \sup \{\omega_\alpha: \alpha < \lambda\} \text{ for \(\lambda\) a non-zero limit}
\end{align*}
Then every \(\omega_\alpha\) is initial by induction.

Also every infinite initial ordinal \(\delta\) is an \(\omega_\alpha\). Indeed, the \(\omega_\alpha\)'s are unbounded in the ordinals (e.g.\ \(\omega_\alpha \geq \alpha\) by induction) so there exists least \(\alpha\) with \(\omega_\alpha \geq \delta\), so \(\omega_\alpha = \delta\).

\begin{definition}[Aleph number]\index{aleph number}\index{\(\aleph_\alpha\)}
  Define the \emph{aleph number} for each ordinal \(\alpha\)
  \[
    \aleph_\alpha = \card(\omega_\alpha).
  \]
\end{definition}

Thus \(\aleph_\alpha\)'s are the cardinalities of all infinite sets (in ZF: of all infinite well-orderable sets).

\begin{eg}
  \(\card(\omega) = \aleph_0\), \(\card(\omega_1) = \aleph_1\).
\end{eg}

\subsection{Cardinal Arithmetics}

\begin{definition}[Cardinal arithmetic]
  For cardinals \(m\) and \(n\), let \(m = \card M, n = \card N\) for some \(M\) and \(N\). Define
  \begin{align*}
    m + n &= \card(M \sqcup N) \\
    mn &= \card(M \times N) \\
    m^n &= \card(M^N)
  \end{align*}
  where \(M \sqcup N\) is the disjoint union and
  \[
    M^N = \{f: f \text{ a function from } N \text{ to } M\}.
  \]
\end{definition}

\begin{note}
  They are independent of choice of \(M\) and \(N\) and thus well-defined.
\end{note}

We can also define the sum over an indexed family
\[
  \sum_{i \in I} m_i = \card( \bigsqcup_{i \in I} M_i).
\]
Note that axiom of choice is needed for this to be well-defined.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(\R \biject \powerset(\omega) \biject \{0, 1\}^\omega\) so \(\card(\R) = 2^{\aleph_0}\).
  \item How many real sequences are there? In IA Numbers and Sets we have to fiddle aroud but this course provides a slick proof:
    \[
      \card(\R^\omega) = (2^{\aleph_0})^{\aleph_0} = 2^{\aleph_0 \aleph_0} = 2^{\aleph_0}.
    \]
    We are using obvious facts like:
    \begin{enumerate}
    \item \(m + n = n + m\) as \(M \sqcup N \biject N \sqcup M\).
    \item \(mn = nm\) as \(M \times N \biject N \times M\).
    \item \((m^n)^p = m^{np}\) as \((M^N)^P \biject M^{N \times P}\).
    \item \(\aleph_0 \aleph_0 = \aleph_0\) as \(\omega \times \omega \biject \omega\).
    \end{enumerate}
  \end{enumerate}
\end{eg}

We know \(\aleph_0 \aleph_0 = \aleph_0\) but what about \(\aleph_1 \aleph_1\)? It turns out addition and multiplication of cardinals are trivially easy, thanks to

\begin{theorem}
  For all \(\alpha\),
  \[
    \aleph_\alpha \aleph_\alpha = \aleph_\alpha.
  \]
\end{theorem}

\begin{proof}
  We will show that \(\omega_\alpha \times \omega_\alpha \biject \omega_\alpha\) by induction. Since \(\omega_\alpha\) is an ordinal we naturally want to equip \(\omega_\alpha \times \omega_\alpha\) with a well-ordering. Product order doesn't work since it isn't a well-order. Recall that proof of \(\N \times \N \biject \N\) in IA Numbers and Sets: we traverse the half-lattice by following successive anti-diagonals. We use the same idea here, with anti-diagonals replaced by squares for easier of presentation.

  Define a well-ordering on \(\omega_\alpha \times \omega_\alpha\) by ``going up in squares'': put \((x, y) < (z, t)\) if
  \begin{itemize}
  \item either \(\max\{x, y\} < \max\{z, t\}\) (bigger square beats smaller square),
  \item or \(\max\{x, y\} = \max\{z, t\} = \beta\) (within a square) and one of
    \begin{itemize}
    \item \(y = t = \beta, x < z\),
    \item  or \(x = z = \beta, y < t\),
    \item or \(t = \beta, y < \beta\).
    \end{itemize}
  \end{itemize}
 This is obviously a well-ordering.

  Given \(r \in \omega_\alpha \times \omega_\alpha\), we have \(r \in \beta \times \beta\) for some \(\beta < \omega_\alpha\) (since \(\omega_\alpha\) is initial), so \(I_r \subseteq \beta \times \beta\) by definition of \(<\). But \(\beta \times \beta \biject \beta\) (or \(\beta\) is finite) by induction hypothesis (\(\omega_\alpha\) is initial). Thus \(I_r\) has order-type \(< \omega_\alpha\). Thus every proper initial segment of \((\omega, <)\) has order-type \(< \omega_\alpha\). Thus \((\omega, <)\) has order-type \(\leq \omega_\alpha\). Take cardinality, \(\aleph_\alpha \aleph_\alpha \leq \aleph_\alpha\). The other direction is trivial by, for example, the diagonal embedding.
\end{proof}

\begin{corollary}
  Let \(\alpha \leq \beta\). Then
  \[
    \aleph_\alpha + \aleph_\beta = \aleph_\alpha \aleph_\beta = \aleph_\beta.
  \]
\end{corollary}
So simply ``take the bigger one''. Cardinal addition and multiplication are boring!

\begin{proof}
  \[
    \aleph_\beta \leq \aleph_\beta + \aleph_\alpha \leq \aleph_\beta + \aleph_\beta = 2\aleph_\beta \leq \aleph_\alpha \aleph_\beta \leq \aleph_\beta \aleph_\beta = \aleph_\beta.
  \]
\end{proof}

\begin{eg}
  For any infinite set \(X\) we have \(X \biject X \sqcup X\) (in ZFC).
\end{eg}

However, cardinal exponentiation is much harder. Just a warning: exponentiation is different for cardinals and ordinals.

\begin{eg}
  For ordinals, \(\omega^\omega\) is countable as by definition,
  \[
    \omega^\omega = \sup\{\omega, \omega^2, \dots \}
  \]
  On the other hand, for cardinals, by Cantor's diagonal argument
  \[
    \aleph_0^{\aleph_0} \geq 2^{\aleph_0} > \aleph_0.
  \]
\end{eg}

To get an idea of how hard cardinal exponentiation is, \(2^{\aleph_0}\) might not even be an aleph in ZF. In ZFC, we can still ask the question if \(2^{\aleph_0} = \aleph_1\). Equivalently, if every \(S \subseteq \R\) is either countable or bijects with \(\R\).

This is the \emph{continuum hypothesis}\index{continuum hypothesis}, and has proven to be independent of ZFC. Depending on your philosophical view, this is not so intuitively obvious as the other axioms in ZF or ZFC.

Even today, not all implications about values of \(2^{\aleph_\alpha}\) are known. For example, if we are given that \(2^{\alpha_\alpha} = \aleph_{\alpha + 1}\) for \(\alpha = 0, 1, 2, \dots\), the best we can say, based on the results so far, is that \(2^{\aleph_\omega} \leq \aleph_{\omega_4}\).

\section{Gödel Incompleteness Theorem*}

The aim of this non-examinable section is to show PA is incomplete, i.e.\ there exists \(p\) such that PA~\(\nyields p\) and PA~\(\nyields \neg p\). It suffices to show that there exists \(p\), true in \(\N\), such that PA~\(\nyields p\). We are going to abbreviate ``true in \(\N\)'' as ``true'' and ``PA~\(\nyields p\)'' as ``not provable''.

We try to find a \(p\) saying ``I am not provable'', i.e.\ \(p\) such that \(p\) is true if and only if \(p\) is not provable. Then done: if \(p\) is false then PA~\(\yields p\), so \(p\) holds in every model of PA, in particular in \(\N\), absurd. Thus \(p\) is true so not provable.

The idea is to ``code up'' formulæ, proofs etc in PA, i.e.\ as natural numbers. At first glance it seems that we are doomed to fail since however we do it, ``\(p\) is not provable'' must be longer/more complicated than ``\(p\)''.

Recall that a subset \(S \subseteq \N\) is \emph{definable} if there exists formula \(p(x)\) (which means a formula \(p\) with free variable \(x\)) such that \(m \in S\) if and only if \(p(m)\) is true. Similarly, \(f: \N \to \N\) is \emph{definable} if there exists a formula \(p(x, y)\) such that \(f(m) = n\) if and only if \(p(m, n)\).

\begin{eg}
  \(f(n) = 2n\) is definable: take \(p(x, y)\) to be ``\(y = x + x\)''.
\end{eg}

We should take as fact

\begin{proposition}
  Any function given by an algorithm is definable.
\end{proposition}

\begin{eg}
  \(f(n) = 2^n\) is definable.
\end{eg}

\begin{proof}
  A reference can be found in P.\ T.\ Johnstone Chapter 4 and 9.
\end{proof}

The language of PA has symbols \(s, 0, +, \times, =, \bot, \implies, \forall\), the two parentheses, as well as countably many variables \(\{x_1, x_2, \dots\}\). It is possbile to reduce them just two symbols \(x\) and \(\cdot '\), so \(x_1\) is \(x\), \(x_2\) is \(x'\), \(x_3\) is \(x''\) etc. There is a total of 12 of symbols.

We can now code a formula by raising successive primes to the power of the successive symbols in \(p\). For example, if \(p\) is
\[
  (\forall x) (x = 0)
\]
then its code is
\[
  c(p) = 2^9 \cdot 3^8 \cdot 5^{11} \cdot 7^{10} \cdot 11^9 \cdot 13^{11} \cdot 17^5 \cdot 19^2 \cdot 23^{10}.
\]

Note that not every number codes a formula, for example \(2^7 \cdot 3^5\) is non sense.

``\(m\) codes a formula'' is definable as there exists an algorithm.

\begin{notation}
  Write \(S_m\) for the formula coded by \(m\), and \(S_m = \bot\) if \(m\) does not code a formula.
\end{notation}

Note that ``\(m\) codes an axiom'' (logical or PA axiom) is definable. Also ``\(\ell, m, n\) code formula, with \(S_n\) following from \(S_\ell\) and \(S_m\) by modus ponens'' is definable, same for generalisation.

Now move on to proofs. We code a sequence of statements by
\[
  S(p_1, \dots, p_n) = 2^{c(p_1)} \cdot 3^{c(p_2)} \cdots (n\text{th prime})^{c(p_n)}.
\]
Thus \(\theta(m, n) = \) ``\(m\) codes a proof of \(S_n\)'' is definable. Then \(\phi(n) = \) ``\(n\) codes a provable statement'' is definable since \(\phi(n) \iff (\exists m) \theta(m, n)\). Note that this is \emph{not} by algorithm, but because we can find a formula!

Here comes in the clever part. Consider \(\chi(n) = \) ``\(n\) codes formula \(S_n\) with one free variable, and \(S_n(n)\) is not provable''. This is clearly definable, say by formula \(p(x)\) (\(p(n)\) is true if and only if \(\chi(n)\) where \(p\) is a formula of PA).

Let \(N = c(p)\). Then \(\chi(N)\) asserts that: \(N\) codes a formula with one free variable (so far this is true, since \(N\) codes \(p(x)\)), and this formula, with variable set to \(N\) (namely \(p[N/x]\)) is not provable. So \(p(N)\) is true if and only if \(p(N)\) is not provable. Done!

We have thus shown

\begin{theorem}[Gödel incompleteness theorem]\index{Gödel incompleteness theorem}
  PA is not complete.
\end{theorem}

But maybe PA is too weak. Could we add some clever sentences \(p\) to PA to make it complete? Maybe, for example, the \(p\) used in the proof above. The answer is no: just run the same proof with PA replaced by PA~\(\cup \{p\}\).

However, we can certainly extend PA to a complete theory, in an almost trivial way by adding to the axioms
\[
  T = \{p: p \text{ true in } \N\}.
\]
Why does proof of the theorem fails?

We have to rewind all the way to the beginning --- it can only be the case that \(T\) is not definable, i.e.

\begin{theorem}
  \[
    \{m: m \text{ codes all true statements}\}
  \]
  is not definable.
\end{theorem}

The slogan is ``truth is not definable''.

Another objection is why doesn't our proof of the incompleteness theorem (in particular, that \(p\) is true) formalise into a proof in PA that \(p\) is true? The answer is that we assumed the existence of a model of PA (namely \(\N\)), i.e.\ PA is consistent, which by completeness is \(\operatorname{con}(\text{PA}) = \) ``\(\bot\) is not provable''. Thus \(\text{PA} \cup \operatorname{con}(\text{PA}) \yields p\). So by deduction theorem, Gödel incompleteness theorem can be reformulated as

\begin{theorem}
  \[
    \text{PA }\nyields \operatorname{con}(\text{PA}).
  \]
\end{theorem}

How about ZF? Certainly ZF~\(\yields \operatorname{con}(\text{PA})\) (note that con(PA) means slightly different things than before: it now means that for all \(n \in \omega\), \(n\) does not code a proof of \(\bot\)). This is because ZF~\(\yields\) ``PA has a model'' (namely \(\omega\)).

But copying proof of incompleteness theorem gives

\begin{theorem}
  ZF is not complete.
\end{theorem}

And by the same reasoning above,

\begin{theorem}
  \[
    ZF \nyields con(ZF).
  \]
\end{theorem}

\appendix

\section{Classes}
\label{sec:classes}

\(x \mapsto \{x\}\) for all \(x\) looks like a function, but isn't because the ``domain'' is too big: every function \(f\) has a domain \(\dom f\) (defined as a suitable subset of \(V \cap f\)) and this ``function'' would have domain \(V\), absurd as there is no universal set, i.e.\ \(\neg (\exists x) (\forall y) (y \in x)\) (Russel's paradox).

\begin{definition}[Class]\index{class}
  For an \(L\)-structure \(V\), a collection \(C\) of elements of \(V\) is called a \emph{class} if there is a formula \(p\), free variables \(x\) (parameterised), such that \(x \in C\) if and only if \(p(x)\) holds in \(V\).
\end{definition}

Here ``collection'' is simply a subset, in the true maths world. But to avoid confusion with subset in the sense of ZF we give it an alias.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(V\) is a class. Take \(p(x)\) to be \(x = x\).
  \item For any \(t\), \(\{x: t \in x\}\) is a class. Take \(p(x)\) to be \(t \in x\). This shows that we need parameter \(t\).
  \item Every set \(y\) is a class. Take \(p(x)\) to be \(x \in y\).
  \end{enumerate}
\end{eg}

\begin{definition}[Proper class]\index{class!proper}
  If \(C\) is not a set (in \(V\)), i.e.\ \(\neg (\exists y) (\forall x) (x \in y \iff p(x))\), say \(C\) is a \emph{proper class}.
\end{definition}

\begin{eg}
  \(V\) is a proper class, as is \(\{x: x \text{ infinite}\}\).
\end{eg}

\begin{definition}[Function-class]\index{function-class}
  A \emph{function-class} is a collection \(F\) of ordered pairs from \(V\) such that for each formula \(p\), free vaiables \(x, y\) (parameterised), we have
  \begin{enumerate}
  \item \((x, y) \in F\) if and only if \(p(x, y)\),
  \item if \((x, y) \in F, (x, z) \in F\) then \(y = z\).
  \end{enumerate}
\end{definition}

\begin{eg}
  \(x \mapsto \{x\}\) is a function-class. Take \(p(x, y)\) to be \(y = \{x\}\).
\end{eg}

\printindex
\end{document}

% logic is the interplay of syntax and semantics
% set: stuff with sets, universe of sets

% Contents

% 1: Propositional logic
% 2: Well-ordering and ordinals
% 3: Posets and Zorn's Lemma
% 4: Predicate logic
% 5: Set theory
% 6: Cardinals

% Reading:
% Johnstone, Notes on logic and set theory
% van Dalen, Logic and structure
% Hainal & Hamburger, Set theory
% F orster, Logic, induction and sets
