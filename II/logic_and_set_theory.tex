\documentclass[a4paper]{article}

\def\npart{II}

\def\ntitle{Logic and Set Theory}
\def\nlecturer{I.\ B.\ Leader}

\def\nterm{Lent}
\def\nyear{2018}

\input{header}

\begin{document}

\input{titlepage}

\tableofcontents

\section{Propositional Logic}

Let \(P\) be a set of \emph{primitive propositions}. Unless otherwise stated,
\[
  P = \{p_1, p_2, \dots \}.
\]

\begin{definition}[Language]\index{language}
  The \emph{language} or \emph{set of propositions} \(L = L(P)\) is defined inductively by
  \begin{enumerate}
  \item \( p \in P, p \in L\),
  \item \(\bot \in L\) (reads ``false''),
  \item if \(p, q \in L\) then \((p \implies q) \in L\).
  \end{enumerate}
\end{definition}

\begin{eg}
  \((p_1 \implies \bot)\), \(((p_1 \implies p_2) \implies (p_1 \implies p_3))\), \(((p_1 \implies \bot) \implies \bot)\) are elements of \(L\).
\end{eg}

\begin{note}\leavevmode
  \begin{enumerate}
  \item Each proposition is a finite union string of symbols from the alphabet \((, ), \implies, p_1, p_2, \dots\).
  \item ``Inductively defined'' means more precisely that we set
    \begin{align*}
      L_1 &= P \cup \{\bot\} \\
      L_{n + 1} &= L_n \cup \{(p \implies q): p, q \in L_n\}
    \end{align*}
    and then set \(L = L_1 \cup L_2 \cup \dots\). \(L_n\) can be seen as ``things born by time \(n\)''.
  \item Each proposition is built up \emph{uniquely} from (1), (2) and (3). For example, \(((p_1 \implies p_2) \implies (p_1 \implies p_3))\) came from \((p_1 \implies p_2)\) and \((p_1 \implies p_3)\).
  \end{enumerate}
\end{note}

Note that we often omit outer brackets or use different brackets for clarity.

We can now define for example, \(\neg p\) (reads ``not \(p\)'') as an abbreviation for \(p \implies \bot\), \(p \lor q\) (reads ``\(p\) or \(q\)'') for \((\neg p) \implies q\), \(p \land q\) (reads \(p\) and \(q\)'') for \(\neg (p \implies (\neg q))\).

\subsection{Semantic Entailment}

\begin{definition}[Valuation]\index{valuation}
  A \emph{valuation} is a function \(v: L \to \{0, 1\}\) such that
  \begin{enumerate}
  \item \(v(\bot) = 0\),
  \item \(v(p \implies q) = \begin{cases} 0 & \text{if } v(p) = 1, v(q) = 0 \\ 1 & \text{otherwise} \end{cases}\) for all \(p, q \in L\).
  \end{enumerate}
\end{definition}

\begin{remark}
  On \(\{0, 1\}\), we could define a constant \(\bot\) by \(\bot = 0\) and an operation \(\implies\) by
  \[
    (a \implies b) =
    \begin{cases}
      0 & \text{if } a = 1, b = 0 \\
      1 & \text{otherwise}
    \end{cases}
  \]
  Then a valuation is a function \(L \to \{0, 1\}\) that preserves the structure (\(\bot\) and \(\implies\)), i.e.\ it is a homomorphism.
\end{remark}

\begin{proposition}\leavevmode
  \begin{enumerate}
  \item If \(v\) and \(v'\) are valuations with \(v(p) = v'(p)\) for all \( \in P\), then \(v = v'\).
  \item For any \(w: P \to \{0, 1\}\), there exists a valuation \(v\) with \(v(p) = w(p)\) for all \(p \in P\).
  \end{enumerate}
\end{proposition}

In other words, a valuation is determined by its values on \(P\) and any values will do.

\begin{proof}\leavevmode
  \begin{enumerate}
  \item We have for all \(p \in L_1\), \(v(p) = v'(p)\). But if \(v(p) = v'(p)\) and \(v(q) = v'(q)\) then \(v(p \implies q) = v'(p \implies q)\) so \(v = v'\) on \(L_2\). Continue inductively, we have \(v = v'\) on \(L_n\) for all \(n\).
  \item Set \(v(p) = w(p)\) for all \(p \in P\) and \(v(\bot) = 0\). This defines \(v\) on \(L_1\). Having defined \(v\) on \(L_2\), use \(v(p \implies q) = \begin{cases} 0 & \text{if } v(p) = 1, v(q) = 0 \\ 1 & \text{otherwise} \end{cases}\) to define \(v\) on \(L_{n + 1}\).
  \end{enumerate}
\end{proof}

\begin{eg}
  In a valuation given by
  \begin{align*}
    v(p_1) &= 1 \\
    v(p_2) &= 1 \\
    v(p_n) &= 0 \text{ for all } n \geq 3
  \end{align*}
  we have \(v(\underbrace{(p_1 \implies p_2)}_{1} \implies \underbrace{p_3}_{0}) = 0\).
\end{eg}

\begin{definition}[Tautology]\index{tautology}
  \(p\) is a \emph{tautology}, written \(\models p\) if \(v(p) = 1\) for all valuations \(p\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(p \implies (q \implies p)\). ``A true statement is implied by anything''. Alternatively, we could make a truth table
    \begin{table}[h]
      \centering
      \begin{tabular}{c|c|c|c}
        \(v(p)\) & \(v(q)\) & \(v(q \implies p)\) & \(v(p \implies (q \implies p))\) \\\hline
        1 & 1 & 1 & 1 \\
        1 & 0 & 1 & 1 \\
        0 & 1 & 0 & 1 \\
        0 & 0 & 1 & 1
      \end{tabular}
      \caption{Truth table}
    \end{table}
  \item \((\neg \neg p) \implies p\), i.e.\ \(((p \implies \bot) \implies \bot) \implies p\). ``Law of excluded middle''.
  \item \((p \implies (q \implies r)) \implies ((p \implies q) \implies (p \implies r))\). This is an example where writing down a truth table is not so desirable. Instead, this is not a tautology only if we have \(v\) with
    \begin{align*}
      v(p \implies (q\implies r)) &= 1 \\
      v((p \implies q) \implies (q \implies r)) &= 0
    \end{align*}
    so \(v(p \implies q) = 1, v(p \implies r) = 0\) whence \(v(p) = 1, v(r) = 0\), so also \(v(q) = 1\). But then \(v(q \implies r) = 0\) so \(v(p \implies (q \implies r)) = 0\). Absurd.
  \end{enumerate}
\end{eg}

\begin{definition}[Entailment]\index{entailment}
  For \(S \subseteq L, t \in L\), we say \(s\) \emph{entails} or \emph{semantically implies} \(t\), written \(S \models t\), if \(v(s) = 1\) for all \(s \in S\) then \(v(t) = 1\) for each valuation \(v\).
\end{definition}

This says whenever all of \(S\) is true, \(t\) is true as well.

\begin{eg}
  \(\{p \implies q, q \implies r\} \models (p \implies r)\). Indeed, suppose not. So have \(v\) with \(v(p \implies q) = v(q \implies r) = 1, v(p \implies r) = 0\). Then \(v(p) = 1, v(r) = 0\), whence \(v(q) = 0\) (from \(v(q \implies r) = 1\)), so \(v(p \implies q) = 0\). Absurd.
\end{eg}

\begin{definition}[Model]\index{model}
  If \(v(t) = 1\), we say \(t\) is \emph{true in \(v\)} or that \(v\) is a \emph{model} of \(t\).

  For \(S \subseteq L\), \(v\) is a \emph{model} of \(S\) if \(v(s) = 1\) for all \(s \in S\).
\end{definition}

Using this terminology, \(S \implies t\) says that every model of \(S\) is a model of \(t\).

\begin{note}
  \(\models t\) is equivalent to \(\emptyset \models t\).
\end{note}

\subsection{Syntactic Implication}

For a notion of ``proof'', we'll need axioms and deduction rules. As axioms, we'll take
\begin{enumerate}
\item \(p \implies (q \implies p)\) for all \(p, q \in L\).
\item \((p \implies (q \implies r)) \implies ((p \implies q) \implies (p \implies r))\) for all \(p, q, r \in L\).
\item \((\neg \neg p) \implies p\) for all \(p \in L\).
\end{enumerate}

\begin{note}
  We have already checked that these are all tautologies. Sometimes we say 3 axiom schemes to mean 3 infinite sets of axioms.
\end{note}

As deduction rules, we'll take just \emph{modus ponens}: from \(p\) and \((p \implies q)\) we can deduce \(q\).

\begin{definition}[Proof]\index{proof}
  For \(S \subseteq L\) and \(t \in L\), a \emph{proof} of \(t\) from \(S\) consists of a finite sequence \(t_1, \dots, t_n\) of propositions, with \(t_n = t\) such that for every \(i\), the proposition \(t_i\) is an axiom, or a member of \(S\), or there exists \(j, k < i\) with \(t_j = (t_k \implies t_i)\).

  We say \(S\) is the \emph{hypotheses} or \emph{premises} and \(t\) is the \emph{conclusion}.
\end{definition}

\begin{definition}
  If there is a proof of \(t\) from \(S\), say \(S\) \emph{proves} or \emph{syntactically implies} \(t\), written \(S \yields t\). If \(\emptyset \yields t\), say \(t\) is a \emph{theorem}, written \(\yields t\).
\end{definition}

\begin{eg}
  \(\{p \implies q, q \implies r\} \yields p \implies r\)
  \begin{enumerate}
  \item \((q \implies r) \implies (p \implies (q \implies r))\), A1
  \item \(q \implies r\), hypothesis
  \item \(p \implies (q \implies r)\), MP
  \item \((p \implies (q \implies r)) \implies ((p \implies q) \implies (p \implies r))\), A2
  \item \((p \implies q) \implies (p \implies r)\), MP
  \item \(p \implies q\), hypothesis
  \item \(p \implies r\), MP
  \end{enumerate}
\end{eg}

\begin{eg}
  \(\yields p \implies p\)
  \begin{enumerate}
  \item \(p \implies ((p \implies p) \implies p)\), A1
  \item \((p \implies ((p \implies p) \implies p)) \implies ((p \implies (p \implies p)) \implies (p \implies p))\), A2
  \item \((p \implies (p \implies p)) \implies (p \implies p)\), MP
  \item \(p \implies (p \implies p)\), A1
  \item \(p \implies p\), MP
  \end{enumerate}
\end{eg}

The following theorem allows us to prove things much more easily:

\begin{theorem}[Deduction theorem]\label{deduction theorem}
  Let \(S \subseteq L\) and \(p, q \in L\). Then \(S \yields p \implies q\) if and only if \(S \cup \{p\} \yields q\).
\end{theorem}

\begin{proof}\leavevmode
  \begin{itemize}
  \item \(\impliedby\): Given a proof of \(p \implies q\) from \(S\), append the lines
    \begin{enumerate}
    \item \(p\), hypothesis
    \item \(q\), MP
    \end{enumerate}
    to obtain a proof of \(q\) from \(S \cup \{p\}\).
  \item \(\implies\): Let \(t_1, \dots, t_n = q\) be a proof of \(q\) from \(S \cup \{p\}\). We'll show that \(S \yields p \implies t_i\) for all \(i\). Split into cases
    \begin{itemize}
    \item \(t_i\) is an axiom: write down
      \begin{enumerate}
      \item \(t_i \implies (p \implies t_i)\), A1
      \item \(t_i\), axiom
      \item \(p \implies t_i\), MP
      \end{enumerate}
    \item \(t_i \in S\): identical as above.
    \item \(t_i = p\): write down the proof \(p \implies p\).
    \item \(t_i\) is obtained by MP: there exist \(j, k < i\) such that \(t_k = (t_j \implies t_i)\). By induction \(S \yields p \implies t_j\) and \(S \yields p \implies t_k\). Now write down
      \begin{enumerate}
      \item \((p \implies (t_j \implies t_i)) \implies ((p \implies t_j) \implies (t \implies t_i))\), A1
      \item \(p \implies (t_j \implies t_i)\), known
      \item \((p \implies t_j) \implies (p \implies t_i)\), MP
      \item \(p \implies t_j\), known
      \item \(p \implies t_i\), MP
      \end{enumerate}
    \end{itemize}
    and we can conclude \(S \yields p \implies t_i\) for all \(i\).
  \end{itemize}
\end{proof}

\begin{eg}
  In order to show \(\{p \implies q, q \implies r\} \yields p \implies r\), it suffices to show \(\{p \implies q, q \implies r, p\} \yields r\) by Deduction theorem, which is easy by using MP twice.
\end{eg}

Now we have two turnstiles \(\models\) and \(\yields\), how are they related? The aim of the rest of the chapter is to prove

\begin{theorem}[Completeness theorem]
  \(S \models t\) if and only if \(S \yields t\).
\end{theorem}

We break this down into two directions:
\begin{itemize}
\item \(\implies\): adequacy
\item \(\impliedby\): soundness
\end{itemize}

The easy part is

\begin{proposition}[Soundness]\index{soundness}
  If \(S \yields t\) then \(S \models t\).
\end{proposition}

\begin{proof}
  Given \(v\) that models \(s\) and a proof \(t_1, \dots, t_n = t\) of \(S \yields t\), we will show that \(v(t_i) = 1\) for all \(i\).

  If \(t_i\) is an axiom they \(v(t_i) = 1\) since it is tautology. If \(t_i\) is a hypothesis then \(v(t_i) = 1\) by assumption. Finally, if \(t_i\) is obtained by MP, say from \(t_j \implies t_i\), since \(v(t_j) = 1\) and \(v(t_j \implies t_i) = 1\) by induction, \(v(t_i) = 1\).
\end{proof}

Note that soundness holds whenever our axioms are tautologies.

To prove adequacy, which is a bit harder, we need a few lemmas.

\begin{definition}[Consistency]\index{consistency}
  \(S\) is \emph{inconsistent} if \(S \yields \bot\). Otherwise \(S\) is \emph{consistent}.
\end{definition}

\begin{theorem}[Model existence lemma]
  Let \(S \subseteq L\) be consistent, then \(S\) has a model.
\end{theorem}

The idea is to would like to define a valuation \(v\) by \(v(p) = 1\) if and only if \(p \in S\). As \(1\) is preserved under \(\implies\), a more sensible aim is \(v(p) = 1\) if and only if \(S \yields p\).

But maybe neither \(S \yields p\) nor \(S \yields \neg p\). So we want to ``grow'' \(S\) to contain one of \(p\) or \(\neg p\) for each \(p \in L\) (while remaining consistent).

\begin{proof}
  Claim that for any consistent \(S \subseteq L\), \(S \cup \{p\}\) or \(S \cup \{\neg p\}\) is consistent:

  \begin{proof}
    If not, then \(S \cup \{p\} \yields \bot\) and \(S \cup \{\neg p\} \yields \bot\). But then \(S \yields (p \implies \bot)\) by deduction theorem, i.e.\ \(S \yields \neg p\). Then \(S \yields \bot\). Absurd.
  \end{proof}

  Now as \(L\) is countable, we can list \(L\) as \(t_1, t_2, \dots \). Put \(S_0 = S\). Set \(S_1 = S_0 \cup \{t_1\}\) or \(S_0 \cup \{\neg t_1\}\) such that \(S_1\) is consistent. Then Let \(S_2 = S_1 \cup \{t_2\}\) or \(S_1 \cup \{\neg t_2\}\) such that \(S_2\) is consistent and continue inductively. Let \(\cl S = S_0 \cup S_1 \cup \dots\). Then \(\cl S \supseteq S\) and \(\cl S\) is consistent (as each \(S_n\) is consistent and proofs are finite). For all either \(p \in L\) we have \(p \in \cl S\) or \(\neg p \in \cl S\). Also \(\cl S\) is \emph{deductively closed}, meaning that if \(\cl S \yields p\) then \(p \in \cl S\). Indeed if \(p \notin \cl S\) then \(\neg p \in \cl S\), so \(\cl S \yields p, \cl S \yields (\neg p)\), whence \(\cl S \yields \bot\). Absurd.

  Define a valuation
  \begin{align*}
    v: L &\to \{0, 1\} \\
    p &\mapsto
        \begin{cases}
          1 & p \in \cl S \\
          0 & \text{otherwise}
        \end{cases}
  \end{align*}
  Indeed, \(v(\bot) = 0\) as \(\bot \notin \cl S\). For \(v(p \implies q)\):
  \begin{itemize}
  \item if \(v(p) = 1, v(q) = 0\), we have \(p \in \cl S, q \notin \cl S\), and we want \(v(p \implies q) = 0\), i.e.\ \((p \implies q) \notin \cl S\). But if \((p \implies q) \in \cl S\) then \(\cl S \yields q\), \(q \in \cl S\). Absurd.
  \item if \(v(q) = 1\), we have \(q \in \cl S\), and we want \(v(p \implies q) \in \cl S\), i.e.\ \((p \implies q) \in \cl S\). But \(\yields q \implies (p \implies q)\) so \(\cl S \yields (p \implies q)\).
  \item if \(v(p) = 0\), we have \(p \implies \cl S\). Then \((\neg p) \in \cl S\). We want \((p \implies q) \in \cl S\). Thus we need \((p \implies \bot) \yields (p \implies q)\), which by Deduction theorem is equivalent to \(\{p \implies \bot, p\} \yields q\). Thus suffices to show that \(\bot \yields q\). But we have \(\yields (\neg \neg q) \implies q\), and \(\yields (\bot \implies (\neg \neg q))\). Thus \(\yields (\bot \implies q)\), i.e.\ \(\bot \implies q\). Done.
  \end{itemize}
\end{proof}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item Sometimes this is called Completeness theorem.
  \item What would happen if \(P\) is uncountable? In fact, the result still holds if \(P\) is uncountable. See Chapter 3.
  \end{enumerate}
\end{remark}

By remark before the above theorem, we now have

\begin{corollary}[Adequacy]\index{adequacy}
  Let \(S \subseteq L, t \in L\). Then if \(S \models t\) then \(S \yields t\).
\end{corollary}

\begin{theorem}[Completeness theorem]\index{Completeness theorem}
  Let \(S \subseteq L, t \in L\). Then \(S \yields t\) if and only if \(S \models t\).
\end{theorem}

\begin{proof}
  By soundness and adequacy.
\end{proof}

Some consequences:

\begin{corollary}[Compactness Theorem]
  Let \(S \subseteq L, t \in L\) with \(S \models t\). Then there exists a finite \(S' \subseteq S\) with \(S' \models t\).
\end{corollary}

\begin{proof}
  Trivial if we replace \(\models\) with \(\yields\) as proofs are finite.
\end{proof}

Specialising to \(t = \bot\), this theorem says that if \(S\) has no model then some finite \(S' \subseteq S\) has no model. Equivalently,

\begin{corollary}[Compactness Theorem, equivalent form]
  Let \(S \subseteq L\). If every finite finite subset of \(S\) has a model then \(S\) has a model.
\end{corollary}

\begin{proof}
  This is equivalent to the previous corollary because \(S \models t\) if and only if \(S \cup \{\neg t\}\) has no model and \(S' \models t\) if and only if \(S' \cup \{\neg p\}\) has no model.
\end{proof}

\begin{corollary}[Decidability Theorem]
  There is an algorithm to determine (in finite time) whether or not, for a given \(S \subseteq L, t\in L\), we have \(S \yields t\).
\end{corollary}

\begin{remark}
  Highly non-obvious.
\end{remark}

\begin{proof}
  Trivial to decide if \(S \models t\), just by drawing a truth table.
\end{proof}

\section{Well-orderings and Ordinals}

\subsection{Definitions}

\begin{definition}[Total order]\index{total order}
  A \emph{total order} or \emph{linear order} on a set \(X\) is a relation \(<\) on \(X\) that is
  \begin{enumerate}
  \item irreflexive: for all \(x\), not \(x < x\),
  \item transitive: for all \(x, y, z\), \(x < y, y < z\) implies \(x < z\),
  \item trichotomous: for all  \(x, y\), \(x < y, x = y\) or \(y < x\).
  \end{enumerate}
\end{definition}

\begin{note}
  Two of 3 cannot hold: if \(x < y, y < x\) then \(x < x\), absurd.
\end{note}

\begin{notation}
  We write \(x \leq y\) if \(x < y\) or \(x = y\). Write \(y > x\) if \(x < y\) etc.

  In terms of \(\leq\), a total order is
  \begin{enumerate}
  \item reflexive: for all \(x\), \(x \leq x\),
  \item transitive: for all \(x, y, z\), \(x \leq y, y \leq z\) implies \(x \leq z\),
  \item antisymmetric: for all \(x, y\), \(x \leq y, y \leq\) implies \(x = y\),
  \item trichotomous: for all \(x, y\), \(x \leq y\) or \(y \leq x\).
  \end{enumerate}
\end{notation}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(\N\) with usual order\footnote{In this course \(0 \in \N\). Write \(\N^+\) for \(\N \setminus \{0\}\).}.
  \item \(\Q\) and \(\R\) with usual order.
  \item \(\N^+\) with divisibility is \emph{not a total order} as for example, \(2\) and \(3\) are not related.
  \item Given a set \(S\), the power set \(\mathcal P(S)\) with \(x \leq y\) if \(x \subseteq y\) is \emph{not} a total order for \(|S| > 1\).
  \end{enumerate}
\end{eg}

\begin{definition}[Well-ordering]\index{well-ordering}
  A total order is a \emph{well-ordering} if every non-empty subset has a least element: for all \(S \subseteq X\), if \(X \neq \emptyset\) then exists \(x \in S\) such that \(x \leq y\) for all \(y \in S\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(\N\) with usual order.
  \item \(\Z\) with usual order is \emph{not} a well-ordering. Similar for \(\Q\) and \(\R\).
  \item \(\{x \in \Q: x \geq 0\}\) is \emph{not} a well-ordering. For example, \(\{x \in \Q: x > 0\}\) does not have a least element.
  \item \(\{1 - 1/n: n = 2, 3, \dots\}\) is a well-ordering. This can be thought of \(\N\) squashed into \([0, 1]\).
  \item \(\{1 - 1/n: n = 2, 3, \dots\} \cup \{1\}\) is a well-ordering.
  \item In fact, we can take the union of 5 with any real larger than \(1\) and still have a well-ordering.
  \item \(\{1 - 1/n: n = 2, 3, \dots\} \cup \{2 - 1/n: n = 2, 3, \dots\}\), i.e.\ two copies of 5, is still a well-ordering.
  \end{enumerate}
\end{eg}

\begin{remark}
  \(X\) is well-ordered if and only if there is no \(x_1 > x_2 > x_3 > \dots\) in \(X\). Indeed, if there is such a sequence then \(S = \{x_1, x_2, \dots\}\) has no least element.
\end{remark}

\begin{corollary}
  If \(S \subseteq X\) has no least element, then for each \(x \in S\) there exists \(x' \in S\) with \(x' < x\). Thus we have \(x > x' > x'' > \dots\).
\end{corollary}

\begin{definition}[Order isomorphism]\index{order isomorphism}
  Total orders \(X\) and \(Y\) are \emph{isomorphic} if there exists a bijection \(f: X \to Y\) that is order-preserving, i.e.\ for all \(x < x'\), \(f(x) < f(x')\).
\end{definition}

\begin{eg}
  1 and 6 above are isomorphic. 7 and 8 are isomorphic. 6 and 7 are not isomorphic: for example, one has a greatest element and the other one doesn't.
\end{eg}

\begin{proposition}[Proof by induction]\index{proof by induction}
  Let \(X\) be a well-ordering and \(S \subseteq X\) be such that if \(y \in S\) for all \(y < x\) then \(x \in S\) for each \(x \in X\), then \(S = X\).

  Equivalently, if \(p(x)\) is a property such that for all \(x\), if \(p(y)\) for all \(y < x\) then \(p(x)\), then \(p(x)\) for all \(x \in X\).
\end{proposition}

\begin{proof}
  If \(S \neq X\) then let \(x\) be the least element in \(X \setminus S\). Then \(x \notin X\). But \(y \in S\) for all \(y < x\). Absurd.
\end{proof}

An application:

\begin{proposition}
  Let \(X\) and \(Y\) be isomorphic well-orderings. Then there is a \emph{unique} isomorphism from \(X\) to \(Y\).
\end{proposition}

\begin{remark}
  This is false for total orders in general. For example, From \(\Z\) to \(\Z\) we could take identity or \(x \mapsto x - 5\).
\end{remark}

\begin{proof}
  Let \(f, g\) be isomorphisms. We will show \(f(x) = g(x)\) for all \(x \in X\) by induction. Thus we may assume \(f(y) = g(y)\) for all \(y < x\) and want \(f(x) = g(x)\).

  Let \(a\) be the least element of \(Y \setminus \{f(y): y \in X\}\), which is non-empty. Then we must have \(f(x) = a\): if \(f(x) > a\) then some \(x' > x\) has \(f(x') = a < f(x)\), contradicting \(f\) being order-preserving. Same holds for \(g\). Thus \(f(x) = g(x)\).
\end{proof}

\begin{definition}[initial segment]\index{initial segment}
  In a total order \(X\), an \emph{initial segment} \(I\) is a subset of \(X\) such that \(x \in I, y < x\) implies \(y \in I\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item For any \(x \in X\), set \(I_x = \{y \in X: y < x\}\).
  \item Not every initial segment is of this form. For example, in \(\R\) take \(\{x: x \leq 3\}\), or in \(\Q\), take \(\{x: x^2 < 2 \text{ or } x < 0\}\).
  \end{enumerate}
\end{eg}

\begin{note}
  In a well-ordering, every proper initial segment \(I\) is of the form \(I_x\) for some \(x\). Indeed, let \(x\) be the least element of \(X \setminus I\). Then \(y < x\) implies \(y \in I\) (by definition of \(y\)). Also if \(y \in I\) then must have \(y < x\): if \(y = x\) or \(y > x\) then \(x \in I\) which is a contradiction.
\end{note}

The aim to show every subset of a well-ordered \(X\) is isomorphic to an initial segment.

\begin{note}
  This is false for total orders. For example, \(\{1, 5, 9\} \subseteq \Z\), or \(\Q \subseteq \R\).
\end{note}

Given \(Y \subseteq X\), intuitively we want to map the smallest element of \(Y\) to the smallest element of \(X\) and continue this way. But how do we show every element of \(Y\) is mapped to somewhere? Instead, we should work backwards: given  \(y \in Y\), map \(y\) to the smallest element in \(X\) that is not mapped to.

\begin{theorem}[Definition by recursion]\index{definition by recursion}
  Let \(X\) be well-ordering, \(Y\) any set and \(G: \mathcal P(X \times Y) \to Y\). Then there exists \(f: X \to Y\) such that \(f(x) = G(f|_{I_x})\) for all \(x \in X\). Moreover \(f\) is unique.
\end{theorem}

\begin{note}\leavevmode
  \begin{enumerate}
  \item For \(f: A \to B\) and \(C \subseteq A\), the \emph{restriction} of \(f\) to \(C\) is
    \[
      f|_C = \{(x, f(x)): x \in C\}.
    \]
  \item Slogan: to define \(f(x)\), make use of \(f|_{I_x}\), i.e.\ the values of \(f(y)\) for \(y < x\).
  \end{enumerate}
\end{note}

\begin{proof}
  First we show existence. Define ``\(h\) is an attempt'' to mean \(h: I \to Y\) where \(I \subseteq X\) is some initial segment, and for all \(x \in I\) we have \(h(x) = G(h|_{I_x})\). Note that if \(h\) and \(h'\) are both attempts defined at \(x\) then \(h(x) = h'(x)\): by induction on \(x\), if \(h(y) = h'(y)\) for all \(y < x\), then \(h(x) = h'(x)\).

  Also for all \(x \in X\) there exists an attempt defined at \(X\), by induction on \(x\). Indeed we want an attempt defined at \(x\), given that for all \(y < x\) there exists an attempt defined at \(y\). So for each \(y < x\) we have a unique attempt \(h_y\) defined on \(\{z: z\leq y\}\) (unique by what we just showed). Let
  \[
    h = \bigcup_{y < x} h(y),
  \]
  an attempt defined on \(I_x\) (which is single-valued by uniqueness) so
  \[
    h' = h \cup \{(x, G(h))\}
  \]
  is an attempt defined at \(x\). Now set \(f(x) = y\) if there exists an attempt \(h\) defined at \(x\) with \(h(x) = y\) (also single-valued).

  For uniqueness, if \(f\) and \(f'\) are both suitable then \(f(x) = f'(x)\) for all \(x \in X\) (by induction on \(X\)) --- since if \(f(y) = f'(y)\) for all \(y < x\) then \(f(x) = f'(x)\).
\end{proof}

A typical application:

\begin{proposition}[Subset collapse]
  Let \(X\) be well-ordered, \(Y \subseteq X\). Then \(Y\) is isomorphic to an initial segment of \(X\). Moreover, the initial segment is unique.
\end{proposition}

\begin{proof}
  To have an isomorphism \(f: Y \to I \subseteq X\), we need precisely that for all \(x \in Y\), \(f(x) = \min X \setminus \{f(y): y < x\}\). So done (existence and uniqueness) by the previous theorem. Note that \(X \setminus \{f(y): y < x\} \neq \emptyset\), because \(f(y) \leq y\) for all \(y\) by induction so \(x \notin \{f(y): y < x\}\).
\end{proof}

A note to the pedantic: in proving the set \(X \setminus \{f(y): y < x\}\) is non-empty, we seem to use a circular argument by assuming \(f\) exists. But this is just a shorthand for the longer version: define
\[
  f(x) =
  \begin{cases}
    \min X \setminus \{f(y): y < x\} & \text{if } X \setminus \{f(y): y < x\} \neq \emptyset \\
    \text{cabbage} & \text{otherwise}
  \end{cases}
\]
and then proceed to show \(f(x) \neq \text{cabbage}\) for all \(x \in X\).

In particular, a well-ordered \(X\) cannot be isomorphic to a proper initial segment of \(X\), by uniqueness in subset collapse.

So far we have proved that if two well-orderings are isomorphic there is a unique isomorphism, and that a subset of a well-ordering is isomorphic to a (unique) initial segment. The question now is, how do different general well-orderings relate to each other?

\begin{definition}
  Say \(X \leq Y\) if \(X\) is isomorphic to an initial segment of \(Y\).
\end{definition}

\begin{eg}
  Let \(X = \N\), \(Y = \{1 - 1/n: n = 2, 3, \dots\} \cup \{1\}\), then \(X \leq Y\).
\end{eg}

What we would hope is that there is a total order on the set of all well-orderings. Firstly we have

\begin{theorem}
  Let \(X, Y\) be well-orderings, then \(X \leq Y\) or \(Y \leq X\).
\end{theorem}

\begin{proof}
  Suppose \(Y \nleq X\), to obtain \(f: X \to Y\) that is an isomorphic with an initial segment of \(Y\), need for all \(x \in X\),
  \[
    f(x) = \min Y \setminus \{f(y): y < x\}.
  \]
  (we can't have \(Y = \{f(y): y < x\}\) as then \(Y\) is isomorphic to \(I_x\)). Done by the theorem.
\end{proof}

\begin{proposition}
  Let \(X, Y\) be well-orderings with \(X \leq Y\) and \(Y \leq X\) then \(X\) and \(Y\) are isomorphic.
\end{proposition}

\begin{proof}
  Let \(f\) be an isomorphism from \(X\) to an initial segment of \(Y\) and \(g\) from \(Y\) to \(X\). Then \(g \compose f: X \to X\) is an initial segment of \(X\) (as an initial segment of an initial segment is an initial segment). so \(g \compose f = \id\) by uniqueness in subset collapse. Similarly \(f \compose g = \id_Y\) . Thus \(X\) is isomorphic to \(Y\).
\end{proof}

\subsection{Constructing well-orderings}

So far we have very few examples of well-orderings, so we wish to build new well-orderings from old.

\begin{notation}
  Write \(X < Y\) if \(X \leq Y\) but \(X\) is not isomorphic to \(Y\). Equivalently, \(X < Y\) if and only if \(X\) is isomorphic to a proper initial segment of \(Y\).
\end{notation}

\begin{eg}
  If \(X = \N\), \(Y = \{1 - 1/n: n = 1, \dots, \} \cup \{1\}\) then \(X < Y\).
\end{eg}

We can produce new well-orderings by
\begin{itemize}
\item add a bigger element: a simple yet bona fide way to make a bigger well-ordering is, given a well-ordering \(X\), choose \(x \notin X\) and set \(x > y\) for all \(y \in X\). This is a well-ordering on \(X \cup \{x\}\), written \(X^+\). Clearly \(X < X^+\).
\item put some together: let \((X, <_X)\) and \((Y, <_Y)\) be well-orderings. Say \(Y\) \emph{extends} \(X\) if \(X \subseteq Y\), \(<_X, <_Y\) agree on \(X\), and \(X\) is an initial segment of \((Y, <_Y)\).
\end{itemize}

A family of well-orderings \(\{X_i: i \in I\}\) are \emph{nested} if for all \(i, j \in I\), \(X_i\) extends \(X_j\) or \(X_j\) extends \(X_i\).

\begin{proposition}
  \label{prop:nested well-orderings}
  Let \(\{X_i: i \in I\}\) be a nested family of well-orderings. Then there exists well-ordering \(X\) with \(X \geq X_i\) for all \(i\).
\end{proposition}

\begin{proof}
  Let \(X = \bigcup_{i \in I} X_i\), with \(x < y\) if there exists \(i\) such that \(x, y \in X_i\) and \(x <_i y\), where \(<_i\) is the well-ordering on \(X_i\). Then \(<\) is a well-defined total order on \(X\). Given \(S \subseteq X\) non-empty, choose \(i\) with \(S \cap X_i \neq \emptyset\). Then \(S \cap X_i\) has a minimal element, which must also be a minimal element of \(S\) as \(X_i\) is an initial segment of \(X\). Also \(X \geq X_i\) for all \(i\).
\end{proof}

\subsection{Ordinals}

We have shown that well-orderings can be compared, but are they totally ordered? This is a question that is not yet very meaningful, since we can have isomorphic well-orderings that are not equal. Now we employ a technique commonly used in studying collection of abstract mathematical objects --- we identify well-orderings that are isomorphic as the same and work with equivalence classes of them.\footnote{Technically, we are working with proper classes instead of sets, for example, by considering the collection of all singletons. See later.}

\begin{definition}[Ordinal]\index{ordinal}
  An \emph{ordinal} is a well-ordered set, with two well-ordered sets regarded as the same if they are isomorphic.
\end{definition}

\begin{definition}[Order-type]\index{order-type}
  If \(X\) is a well-ordering corresponding to ordinal \(\alpha\), say \(X\) has \emph{order-type} \(\alpha\).
\end{definition}

\begin{eg}
  With slight abuse of notation, for each \(k \in \N\), write \(k\) for the order-type of the (unique) well-ordering of a set of size \(k\), and write \(\omega\) for the order-type of \(\N\). So in \(\R\), \(\{1, 3, 7\}\) has order-type \(3\), and \(\{1 - 1/n: n = 2, 3, \dots\}\) has order-type \(\omega\).
\end{eg}

\begin{notation}
  For \(X\) of order-type \(\alpha\) and \(Y\) of order-type \(\beta\), write \(\alpha \leq \beta\) if \(X \leq Y\). This is well-defined. Similarly \(\alpha < \beta\) and so on.
\end{notation}

Equipped with these definitions, we now know for all \(\alpha, \beta\), \(\alpha \leq \beta\) or \(\beta \leq \alpha\) and if \(\alpha \leq \beta, \beta \leq \alpha\) then \(\alpha = \beta\), i.e.\ ordinals are total ordered. But are they well-ordered?

\begin{theorem}
  Let \(\alpha\) be an ordinal. Then the ordinals \(< \alpha\) form a well-ordered set with order-type \(\alpha\).
\end{theorem}

For example, the ordinals \(< \omega\) are \(0, 1, 2, \dots\).

\begin{proof}
  Let \(X\) have order-type \(\alpha\). The well-orderings \(< X\) are precisely (up to isomorphisms) the proper initial segments of \(X\), i.e.\ the \(I_x\) for \(x \in X\). But these are isomorphic to \(X\) itself via \(I_x \mapsto x\).
\end{proof}

\begin{notation}
  We often write \(I_\alpha = \{\beta \text{ ordinal}: \beta < \alpha\}\) for this special well-ordered set with order-type \(\alpha\).
\end{notation}

\begin{proposition}
  \label{prop:set of ordinals is well-ordered}
  Let \(S\) be a non-empty set of ordinals. Then \(S\) has a least element.
\end{proposition}

\begin{proof}
  Choose \(\alpha \in S\). If \(\alpha\) is minimal in \(S\) then done. If not, then \(S \cap I_\alpha \neq 0\), so we have a minimal element of \(S \cap I_\alpha\), which is therefore minimal in \(S\).
\end{proof}

Given the proposition, it is very tempting to conclude that all well-orderings form a well-order. But there is one technicality that we haven't checked, that well-orders are defined on a set. Unfortunately,

\begin{theorem}[Burali-Forti Paradox]\index{Burali-Forti Paradox}
  The ordinals do not form a set.
\end{theorem}

\begin{proof}
  Suppose not. Let \(X\) be the set of all ordinals. Then \(X\) is a well-ordering, say of order-type \(\alpha\). So \(X\) is isomorphic to \(I_\alpha\), a \emph{proper} initial segment of \(X\). Absurd.
\end{proof}

This is saying that the collection of all well-orderings is too big to be a set, and thus to be a well-ordering. However, this does not prevent us from working locally with a set of well-orderings.

Recall the two ways of constructing well-orderings. Given \(\alpha\), we have \(\alpha^+ > \alpha\). Also if \(\{\alpha_i: i \in I\}\) is a set of ordinals, then there exists \(\alpha\) with \(\alpha \geq \alpha_i\) for all \(i\), by applying \Cref{prop:nested well-orderings} to the nested family \(\{I_{\alpha_i}: i \in I\}\).

In fact, there is a least upper bound for \(\{\alpha_i: i \in I\}\) --- by applying \Cref{prop:set of ordinals is well-ordered} to the set
\[
  \{\beta \leq \alpha: \beta \text{ an upper bound of } \alpha_i\}.
\]
This is denoted \(\sup_{i \in I} \alpha_i\).

\begin{eg}
  \(\sup \{2, 4, \dots\} = \omega\).
\end{eg}

\subsection{Some ordinals}

\Cref{tab:ordinals} shows some ordinals in increasing order. In each row from left to right, adjacent values are successors to each other. The pattern in each row is the ``obvious'' one that the reader should be able to infer. The beginning entry of a row is the supremum of all entries in the previous row.

{%localise the effect
  \renewcommand{\arraystretch}{2.5}
\begin{table}[h!]
  \centering
  \begin{tabular}{cccccccc}
    \(0\) & \(1\) & \(2\) & \(\dots\) \\
    \(\omega\) & \(\omega + 1\) & \(\omega + 2\) & \(\dots\) \\
    \(\omega 2\) & \(\omega2 + 1\) & \(\omega2 + 2\) & \(\dots\) & \(\omega3\) & \(\dots\) & \(\omega4\) & \(\dots\) \\
    \(\omega^2\) & \(\omega^2 + 1\) & \(\dots\) & \(\omega^2 + \omega\) & \(\dots\) & \(\omega^2 + \omega2\) & \(\dots\) \\
    \(\omega^22\) & \(\dots\) & \(\omega^23\) & \(\dots\) & \(\omega^24\) & \(\dots\) \\
    \(\omega^3\) & \(\dots\) & \(\omega^4\) & \(\dots\) & \(\omega^5\) & \(\dots\) \\
    \(\omega^\omega\) & \(\omega^\omega + 1\) & \(\dots\) & \(\omega^\omega + \omega\) & \(\dots\) & \(\omega^\omega2\) & \(\dots\) & \(\omega^\omega3\) \\
    \(\omega^{\omega + 1}\) & \(\dots\) & \(\omega^{\omega + 2}\) & \(\dots\) & \(\omega^{\omega + 3}\) & \(\dots\) \\
    \(\omega^{\omega2}\) & \(\dots\) & \(\omega^{\omega 3}\) & \(\dots\) \\
    \(\omega^{\omega^\omega}\) & \(\dots\) & \(\omega^{\omega^{\omega^\omega}}\) & \(\dots\) \\
    \(\varepsilon_0\) & \(\varepsilon_0 + 1\) & \(\dots\) & \(\varepsilon_0 + \omega\) & \(\dots\) & \(\varepsilon_0 + \omega^\omega\) & \(\dots\) \\
    \(\varepsilon_02\) & \(\dots\) & \(\varepsilon_0\omega\) & \(\varepsilon_0\omega^\omega\) & \(\dots\) \\
    \(\varepsilon_0^2\) & \(\dots\) & \(\varepsilon_0^3\) & \(\dots\) & \(\varepsilon_0^4\) & \(\dots\) \\
    \(\varepsilon_0^\omega\) & \(\dots\) & \(\varepsilon_0^{\omega^\omega}\) & \(\dots\) \\
    \(\varepsilon_0^{\varepsilon_0}\) & \(\dots\) & \(\varepsilon_0^{\varepsilon_0^{\varepsilon_0}}\) & \(\dots\) \\
    \(\varepsilon_1\) & \(\dots\)
  \end{tabular}
  \caption{Some ordinals}
  \label{tab:ordinals}
\end{table}
}


Some points to notice:
\begin{itemize}
\item we write \(\omega2 = \sup\{\omega + 1, \omega + 2, \dots\}\). The rationale for this unintuitive notation will soon be clear.
\item everything in this table so far is countable, as they are built from operations such as union, subset, cartesian product on countable sets.
\end{itemize}

Is there an uncountable ordinal? In other words, is there an uncountable well-ordered set?

For example, we can well-order \(\N\) and \(\Q\), but what about \(\R\)? Unfortunately, no. We are always going to fail if we try to put a well-ordering on \(\R\). But

\begin{theorem}
  There is an uncountable ordinal.
\end{theorem}

\begin{proof}
  The idea is to take the supremum of all countable ordinals, but first we have to check that it is a set, meaning that we can build it from existing sets using rules such as intersection, cartesian product, images of functions etc.

  Let
  \[
    R = \{A \in \mathcal P(\N \times \N): A \text{ is a well-ordering of a subset of } \N\}.
  \]
  Let \(S\) be the image of \(R\) under the function ``order-type'', i.e.\ \(S\) is the set of all order-types of well-orderings of \(\N\) (or subsets thereof). It is the set of all countable ordinals.

  Let \(\omega_1 = \sup S\). Then \(\omega_1\) is uncountable: if not then \(\omega_1 \in S\) so \(\omega_1\) would be the greatest member of \(S\), which contradicts \(\omega_1 < \omega_1^+\). Note that by construction \(\omega_1\) is the \emph{least uncountable ordinal}.
\end{proof}

\(\omega_1\) has some strange properties, for example
\begin{enumerate}
\item \(\omega_1\) is uncountable, but for any \(\alpha < \omega\), we have \(\{\beta: \beta < \alpha\}\) countable.\footnote{It would perhaps be less surprising if one considers that given \(\alpha < \omega\), \(\{\beta: \beta < \alpha\}\) is finite.}
\item If \(\alpha_1, \alpha_2, \dots < \omega_1\) is a sequence, then it is \emph{bounded} in \(\omega_1\): \(\sup\{\alpha_1, \alpha_2, \dots\}\) is countable so \(< \omega_1\).
\end{enumerate}

\begin{theorem}[Hartogs' lemma]\index{Hartogs' lemma}
  For any set \(X\), there is an ordinal that does not inject into \(X\).
\end{theorem}

\begin{proof}
  Same proof as above, with \(\mathcal P(X, X)\) in place of \(\mathcal P(\N, \N)\).
\end{proof}

\begin{notation}
  We often write \(\gamma(X)\) for least such ordinal. For example, \(\gamma(\omega) = \omega_1\).
\end{notation}

\subsection{Successors and Limits}

Given an ordinal \(\alpha\), does \(\alpha\) has a greatest element?

If yes, say \(\beta\) is greatest. Then \(\gamma < \beta\) or \(\gamma = \beta\) implies \(\gamma < \alpha\) and \(\gamma < \alpha\) implies \(\gamma < \beta\) or \(\gamma = \beta\) (as we can't have \(\gamma > \beta\)). So \(\alpha = \beta^+\). Call \(\alpha\) a \emph{successor}\index{successor}.

If no, then for every \(\beta < \alpha\), then there exists \(\gamma < \alpha\) such that \(\gamma > \beta\). Thus \(\alpha = \sup\{\beta: \beta < \alpha\}\) (note that this is false in general without the absence of greatest element hypothesis, e.g.\ \(\omega + 5\)). Call \(\alpha\) a \emph{limit}\index{limit}.

\begin{eg}
  \(5\) and \(\omega + 5\) are successors. \(\omega\) and \(\omega + \omega\) are limits. \(0\) is a limit by definition.
\end{eg}

\subsection{Ordinal arithmetics}

Missed a lecture

\begin{definition}[Ordinal multiplication (inductive)]\index{ordinal multiplication}
  Define \(\alpha\beta\) recursively by
  \begin{itemize}
  \item \(\alpha 0 = 0\),
  \item \(\alpha(\beta^+) = \alpha\beta + \alpha\),
  \item \(\alpha\lambda = \sup\{\alpha\gamma: \gamma < \lambda\}\) for \(\lambda\) a non-zero limit,
  \end{itemize}
\end{definition}

\begin{eg}
  \begin{align*}
    \omega 1 &= \omega 0 + \omega = 0 + \omega = \omega \\
    \omega 2 &= \omega 1 + \omega = \omega + \omega \\
    \omega\omega &= \sup \{\omega\gamma: \gamma < \omega\} = \sup \{0, \omega, \omega + \omega, \dots\} \\
    2 \omega &= \sup \{2\gamma: \gamma < \omega\} = \omega
  \end{align*}
  In particular this shows multiplication is not commutative.
\end{eg}

\begin{definition}[Ordinal multiplication (synthetic)]\index{ordinal multiplication}
  \(\alpha\beta\) is the order-type of \(\alpha \times \beta\), with \((x, y) < (z, w)\) if either \(y < w\) or \(y = w\) and \(x < z\).
\end{definition}

We can check that the definitions agree and associativity of multiplication etc.

\begin{definition}[Ordinal exponentiation]\index{ordinal exponentiation}
  Define \(\alpha^\beta\) recursively by
  \begin{itemize}
  \item \(\alpha^0 = 1\),
  \item \(\alpha^{\beta^+} = \alpha^\beta \cdot \alpha\),
  \item \(\alpha^\lambda = \sup\{\alpha^\gamma: \gamma < \lambda\}\) for \(\lambda\) a non-zero limit.
  \end{itemize}
\end{definition}

\begin{eg}
  \begin{align*}
    \omega^1 &= \omega^0 \cdot \omega = 1 \cdot \omega = \omega \\
    \omega^2 &= \omega^1 \cdot \omega = \omega \cdot \omega \\
    2^\omega &= \sup\{2^\gamma: \gamma < \omega\} = \omega
  \end{align*}
  Note that \(2^\omega\) is countable.
\end{eg}

Similarly we can define towers and other arithmetic operations inductively. It is left as an exercise.

\section{Posets and Zorn's Lemma}

\subsection{Partial orders}

\begin{definition}[Poset]\index{poset}
  A \emph{partially ordered set} or \emph{poset} is a pair \((X, \leq)\) where \(X\) is a set and \(\leq\) is a relation on \(X\) that is
  \begin{enumerate}
  \item reflexive: for all \(x\), \(x \leq x\),
  \item transitive: for all \(x, y, z\), \(x \leq y, y \leq z\) implies \(x \leq z\),
  \item antisymmetry: for all \(x, y\), \(x \leq y, y \leq x\) implies \(x = y\).
  \end{enumerate}
\end{definition}

\begin{notation}
  Write \(x < y\) if \(x \leq y, x \neq y\).

  In terms of \(<\), a poset is
  \begin{enumerate}
  \item irreflexive: for all \(x\), not \(x < x\),
  \item transitive: for all \(x, y, z\), \(x < y, y < z\) implies \(x < z\).
  \end{enumerate}
\end{notation}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Any total order.
  \item \(\N^+\) with ``divides''.
  \item For any set \(S\), \(\mathcal P(S)\) with \(x \leq y\) if \(x \subseteq y\).
  \item Any \(X \subseteq \mathcal P(S)\) with same relation as above. This specialises to, for example, all subspaces of a given vector space.
  \item We can draw a \emph{Hasse diagram} for a poset \(X\): it consists of a drawing of elemnents of \(X\), with an upward line from \(x\) to \(y\) if \(y\) covers \(x\), meaning \(y > x\) and no \(z\) such that \(y > z > x\). For example
    \[
      \begin{tikzcd}
        c \ar[dr, dash] & & & & e \ar[dl, dash] \\
        & b \ar[dr, dash] & & d \ar[dl, dash] \\
        & & a
      \end{tikzcd}
    \]
    Hasse diagrams can be useful to visualise a poset (e.g.\ \(\N\)), or useless (e.g.\ \(\Q\)).
  \item In
    \[
      \begin{tikzcd}
        & c \ar[dl, dash] \ar[dr, dash] \\
        b \ar[ddr, dash] & & c \ar[d, dash] \\
        & & d \ar[dl, dash] \\
        & a
      \end{tikzcd}
    \]
    \(b\) and \(d\) are unrelated so there is no sense of ``height'' or ``rank''.
  \item
    \[
      \begin{tikzcd}
        & c \ar[dl, dash] \ar[dr, dash] \\
        b \ar[d, dash] \ar[drr, dash] & & e \ar[d, dash] \ar[dll, dash] \\
        a & & d
      \end{tikzcd}
    \]
  \item A set in which no two elements are related is a poset.
  \end{enumerate}
\end{eg}

\begin{definition}[Chain]\index{chain}
  In a poset \(X\), a \emph{chain} is a set \(S \subseteq X\) that is totally ordered: for all \(x, y \in S\), \(x \leq y\) or \(y \leq x\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Any subset of 1 above.
  \item In 2, \(\{1, 2, 4, 8, 16\}\).
  \item In 5, \(\{a, b, c\}\) or \(\{a, c\}\) but not \(\{b, d\}\).
  \item In 8, only singletons and \(\emptyset\).
  \end{enumerate}
\end{eg}

\begin{note}
  Chains can be uncountable, e.g.\ \((\R, \leq)\).
\end{note}

\begin{definition}[Anti-chain]\index{anti-chain}
  Give a poset \(X\), \(S \subseteq X\) is an \emph{anti-chain} if no two elements are related: for all \(x, y \in S\), \(x \neq y\) implies that not \(x < y\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item In 2: the set of primes.
  \item In 5, \(\{c, e\}\) or \(\{c, d\}\), or \(\{b\}\).
  \item In 8, every subset.
  \end{enumerate}
\end{eg}

\begin{definition}[Upper bound]\index{upper bound}
  Give a poset \(X\), \(S \subseteq X\), an \emph{upper bound} for \(S\) is any \(x \in X\) such that \(x \geq y\) for all \(y \in S\).
\end{definition}

\begin{definition}[Least upper bound]\index{least upper bound}\index{supremum}
  Say \(X\) is a \emph{least upper bound} or \emph{supremum} for \(S\) if \(x\) is an upper bound for \(S\) and \(x \leq y\) for every upper bound \(y\) for \(S\). Write \(x = \sup S\) or \(x = \bigvee S\), the ``join'' of \(S\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item In \(\R\), \(\{x: x^2 < 2\}\) has \(7\) as an upper bound and \(\sqrt 2\) as a supremum. This shows that \(\sup S\) need not be in \(S\).
  \item In \(\R\), the set \(\Z\) has no upper bound.
  \item In \(\Q\), \(\{x: x^2 < 2\}\) has \(7\) as an upper bound but no supremum.
  \item In 5, \(\{a, b\}\) has upper bounds \(b\) and \(c\) and supremum \(b\).
  \item In 5, \(\{b, d\}\) has no upper bound.
  \item In 7, \(\{b, d\}\) has upper bounds \(c, b, e\) but no supremum.
  \end{enumerate}
\end{eg}

\begin{definition}[Completeness]\index{completeness}
  A poset is \emph{complete} if every subset has a supremum.
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \((\R, \leq)\) is not complete as \(\Z\) has no supremum. Thus completeness in posets is different to that from analysis.
  \item \([0, 1]\) is complete.
  \item \((0, 1)\) is not complete as \((0, 1)\) itself has no supremum.
  \item \(\mathcal P(S)\) is always complete --- \(\{A_i\}_{i \in I}\) has supremum \(\bigcup_{i \in I} A_i\).
  \end{enumerate}
\end{eg}

\begin{definition}[Order-preserving map]\index{order-preserving map}
  A function \(f: X \to X\) where \(X\) is a poset is \emph{order-preserving} if \(f(x) \leq f(y)\) for all \(x \leq y\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item On \(\N\), \(f(x) = x + 1\).
  \item On \([0, 1]\), \(f(x) = \frac{1 + x}{2}\), ``halve to the distance to \(1\)''.
  \item On \(\mathcal P(S)\), \(f(A) = A \cup \{i\}\) for some fixed \(i \in S\).
  \end{enumerate}
\end{eg}

From above not every order-preserving function has a fixed point. But just as in Contraction Mapping Theorem, we can add condition to the space to make this happen. Unsurprisingly, this condition is completeness:

\begin{theorem}[Knaster-Tarski fixed point theorem]\index{Knaster-Tarski fixed point theorem}
  \label{thm:Knaster-Tarski}
  Let \(X\) be a complete poset. Then every order-preserving function \(f: X \to X\) has a fixed point.
\end{theorem}

\begin{proof}
  Let \(E = \{x \in X: x \leq f(x)\}\) and \(s = \sup E\). To show \(f(s) = s\), we show both \(s \leq f(s)\) and \(s \geq f(x)\).
  \begin{itemize}
  \item \(s \leq f(s)\): suffices to show \(f(s)\) is an upper bound for \(E\) (as \(s\) is the least upper bound). But
    \[
      x \in E \implies x \leq s \implies f(x) \leq f(s) \implies x \leq f(x) \leq f(s).
    \]
  \item \(s \geq f(s)\): suffices to show \(f(s) \in E\) (as \(s\) is an upper bound). We know \(s \leq f(s)\), so \(f(s) \leq f(f(s))\) since \(f\) is order preserving.
  \end{itemize}
\end{proof}

\begin{note}
  In any complete poset \(X\), we have a greatest element, namely \(\sup X\). We also have a least element, namely \(\sup \emptyset\).
\end{note}

A typical application of Knaster-Tarski is

\begin{theorem}[Schröder-Berstein theorem]\index{Schröder-Berstein theorem}
  Let \(A, B\) be sets such that there is an injection \(f: A \to B\) and injection \(g: B \to A\), then there exists a bijection from \(A\) to \(B\).
\end{theorem}

\begin{proof}
  Seek partitions \(A = P \cup Q, B = R \cup S\) such that \(f(P) = R, g(S) = Q\). Then done by seting \(h = \begin{cases} f & \text{on } R \\ g^{-1} & \text{on } Q \end{cases}\).

  Note that we are done once we fix \(P\): \(R = f(P), S = B \setminus f(P), Q = g(B \setminus f(P))\). i.e.\ we seek \(P \subseteq A\) such that
  \[
    A \setminus (g(B \setminus f(P))) = P.
  \]
  Define
  \begin{align*}
    \theta: \mathcal P(A) &\to \mathcal P(A) \\
    P &\mapsto A \setminus (g(B \setminus f(P)))
  \end{align*}
  Then since \(\mathcal P(A)\) is complete, \(\theta\) is order-preserving (since it takes complement twice), there exists a fixed point by Knaster-Tarski.
\end{proof}

\subsection{Zorn's Lemma}

\begin{definition}
  An element \(x\) in a poset \(X\) is \emph{maximal} if there exists no \(y \in X\) such that \(y > x\).
\end{definition}

\begin{eg}
  In example 5 before, \(c, e\) are both maximal.
\end{eg}

Posets need not have a maximal element, for example \(\N, \Q, \R\) with the ususal order. We notice something in common: in each of thoses cases, there exists a chain without an upper bound.

\begin{theorem}[Zorn's lemma]\index{Zorn's lemma}
  Let \(X\) be a (non-empty) set in which every chain has an upper bound, then \(X\) has a maximal element.
\end{theorem}

\begin{proof}
  Suppose not, then for each \(x \in X\) there exists \(x' \in X\) with \(x' > x\). Also for any chain \(C\) we have an upper bound \(u(C)\). Pick \(x \in X\). Define \(x_\alpha \in X\) for each \(\alpha \in \gamma(X)\) recursively by
  \begin{align*}
    x_0 &= x \\
    x_{\alpha + 1} &= x_\alpha' \\
    x_{\lambda} &= u(\{x_\alpha: \alpha < \lambda\}) \text{ for \(\lambda\) a nonzero limit}
  \end{align*}
  Then \(\alpha \mapsto x_\alpha\) is an injection \(\gamma(X) \to X\). Absurd.
\end{proof}

A typical application of Zorn's lemma: does every vector space \(V\) have a basis? Recall that a basis is a linearly independent (no non-trival finite relation) spanning (every element is a finite linear combination thereof) set.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Let \(V = \R[X]\) be the space of all real polynomials. Then \(\{X^i\}_{i \in \N}\) is a basis.
  \item Let \(V\) be the set of all real sequences with pointwise addition. We might guess
    \begin{align*}
      \ell_1 &= (1, 0, 0, \dots) \\
      \ell_2 &= (0, 1, 0, \dots) \\
      \vdots
    \end{align*}
    is a basis. Unfortunately they are linearly independent but not spanning, e.g.\ \((1, 1, 1, \dots)\) is not in the span. It is actually easy to check that there is no countable basis. It also turns out that there is no \emph{explicit} basis.
  \item \(\R\) as a \(\Q\)-vector space has a basis called a \emph{Hamel basis}.
  \end{enumerate}
\end{eg}

\begin{theorem}
  Every vector space has a basis.
\end{theorem}

\begin{proof}
  We seek a maximal linearly independent set. Let \(V\) be a vector space and
  \[
    X = \{A \subseteq V: A \text{ linearly independent}\}
  \]
  ordered by \(\subseteq\). If we can find a maximal element of \(X\), then done: if \(M\) is not spanning then choose \(x \notin \generation M\) and then \(M \cup \{x\}\) is linearly independent. Absurd.

  We have \(X \neq \emptyset\) as \(\emptyset \in X\). Given a chain \(\{A_i: i \in I\}\) in \(X\), put \(A = \bigcup_{i \in I} A_i\). Then \(A \supseteq A_i\) for all \(i\), so just need to check \(A \in X\), i.e.\ \(A\) is linearly independent. Suppose not, so
  \[
    \sum_{i = 1}^n \lambda_ix_i = 0
  \]
  for some \(x_i \in A\), \(\lambda_i\) not all \(0\). We have \(x_1 \in A_{i_1}, \dots, x_n \in A_{i_n}\) for some \(i_1, \dots, i_n \in I\). But \(A_{i_1}, \dots, A_{i_n} \subseteq A_{i_k}\) for some \(k\) (as \(A_{i_1}, \dots, A_{i_n}\) are nested), contradicting \(A_{i_k}\) linearly independent.
\end{proof}

\begin{note}
  The only ``actual math'' (i.e.\ linear algebra) in the proof was the ``then done'' part.
\end{note}

Another application of Zorn's lemma: completeness theorem when the primitive language is uncountable.

\begin{theorem}[Completeness theorem]\index{Completeness theorem}
  Let \(S \subseteq L(P)\) where \(P\) is any set. Then \(S\) is consistent implies that \(S\) has a model.
\end{theorem}

\begin{proof}
  We seek a maximal consistent \(\cl S \supseteq S\). Then done: for each \(t \in L(P)\) haave \(\cl S \cup \{t\}\) or \(\cl S \cup \{\neg t\}\) consistent, whence \(t \in \cl S\) or \(\neg t \in \cl S\). By maximality of \(\cl S\), and now define
  \begin{align*}
    v(t) =
    \begin{cases}
      1 & \text{if } t \in \cl S \\
      0 & \text{if } t \notin \cl S
    \end{cases}
  \end{align*}

  Let
  \[
    X = \{T \subseteq L(P): T \text{ consistent}, T \supseteq S\}
  \]
  ordered by \(\subseteq\). Then \(X \neq \emptyset\) as \(S \in X\). Given a non-empty chain \(\{T_i: i \in I\}\) in \(X\), take \(T = \bigcup_{i \in I} T_i\), then \(T \supseteq T_i\) for all \(i\) so just need \(T \in X\). We have \(S \subseteq T\) (as \(I \neq \emptyset\)) and \(T\) is consistent: suppose \(T \yields \bot\). Then \(\{t_1, \dots, t_n\} \yields \bot\) for some \(t_1, \dots, t_n \in T\) (as proofs are finite). Since \(t_1 \in T_{i_1}, \dots, t_n \in T_{i_n}\) for some \(i_1, \dots, i_n \in I\), but \(T_{i_1}, \dots, T_{i_n} \subseteq T_{i_k}\) for some \(k\) (as they are nested), \(T_{i_k} \yields \bot\). Absurd.
\end{proof}

One final application:

\begin{theorem}[Well-ordering principle]\index{well-ordering principle}
  Every set can be well-ordered.
\end{theorem}

\begin{remark}
  This is very surprising for, for example, \(\R\), until you remember Hartogs' lemma.
\end{remark}

\begin{proof}
  Let \(S\) be the set. Let
  \[
    X = \{(A, R): A \subseteq S, R \text{ a well-ordering of } A\}
  \]
  ordered by
  \[
    (A, R) \leq (A', R') \text{ if } (A', R') \text{ extends } (A, R).
  \]
  \(X \neq \emptyset\) as \((\emptyset, \emptyset) \in X\). Given a chain \(\{(A_i, R_i): i \in I\}\), we have
  \[
    (\bigcup_{i \in I} A_i, \bigcup_{i \in I} R_i) \in X
  \]
  extending each \((A_i, R_i)\) (from chapter 2). Thus by Zorn's lemma, \(X\) has a maximal element \((A, R)\). Must have \(A = S\): if not, choose \(x \in S \setminus A\) and ``take successor'': well-order \(A \cup \{x\}\) by setting \(x > a\) for all \(a \in A\), contradicting the maximality of \((A, R)\).
\end{proof}

\begin{remark}
  Proof of Zorn's lemma was easy because we knew ordinals, recursion  and Hartog's lemma.
\end{remark}

\subsection{Zorn's lemma and Axiom of choice}

In the proof of Zorn's lemma, we chose for each \(x \in X\) an \(x' > x\) --- i.e.\ we made infinitely many arbitrary choices (note that this has nothing to do with Hartog's lemma. We made infinitely many choices even by the time we get to \(x_\omega\)). We did the same in IA Numbers and Sets, in proving that the countable union of countable sets is countable: we chose for each set in the family an ordering whereof.

In terms of ``rules for building sets'', this is appealing to \emph{axiom of choice}, which says that we may choose an element of each set in a family of non-empty sets. More precisely,

\begin{theorem}[Axiom of choice]\index{axiom of choice}
  If \(\{A_i: i \in I\}\) is a family of non-empty sets then it has a \emph{choice function}, i.e.\ a function \(f: I \to \bigcup_{i \in I} A_i\) such that \(f(i) \in A_i\) for all \(i\).
\end{theorem}

This is of different character to the other set-building rules, such as union, power set etc in that the object whose existence is asserted is not uniquely specified by its properties, unlike, for example, union of sets. Thus often one points out when one has used Axiom of choice.

\begin{remark}
  Axiom of choice is trivial if \(|I| = 1\) (\(A \neq \emptyset\) means by definition that there exists \(x \in A\)). By induction, it is true for \(I\) finite. However, it turns out that, for general \(I\), axiom of choice \emph{cannot} be deduced from the other set-theoretic rules.
\end{remark}

In Zorn's lemma, we used axiom of choice. Is there a proof of Zorn's lemma without axiom of choice? No, because we can deduce axiom of choice from Zorn's lemma.

\begin{proof}[Proof oz axiom of choice from Zorn's lemma]
  Given a family \(\{A_i: i \in I\}\) of non-empty sets, a \emph{partial choice function} is an \(f: J \to \bigcup_{i \in I} A_i\) where \(J \subseteq I\) such that \(f(j) \in A_j\) for all \(j \in J\). Let
  \[
    (J, f) \leq (J', f') \text{ if } J \subseteq J' \text{ and } f'|_J = f.
  \]
  This poset is non-empty as \((\emptyset, \emptyset)\) is an element. Given a chain \(\{(J_q, f_q)\}_{q \in Q}\), we have \(\bigcup_{q \in Q} (J_q, f_q)\) as an upper bound. Thus by Zorn's lemma there exists a maximal element \((J, f)\). We must have \(J = I\), as if not we choose \(i \in I \setminus J, x \in A_i\), and put \(J' = J \cup \{i\}, f' = f \cup \{(i, x)\}\). Absurd.
\end{proof}

In conclusion, Zorn's lemma \(\Leftrightarrow\) axiom of choice (in the presence of the set-building rules).

Actually, there is a three-way equivalence: we have shown Zorn's lemma implies well-ordering principle, and well-ordering principle implies axiom of choice trivially (\(\bigcup_{i \in I} A_i\) is well-ordered and let \(f(i)\) be least element of \(A_i\)). Therefore
\[
  \text{Zorn's lemma } \Leftrightarrow \text{ axiom of choice } \Leftrightarrow \text{ well-ordering principle}.
\]

\begin{ex}
  Show that axiom of choice implies well-ordering principle directly.
\end{ex}

\begin{note}
  Zorn's lemma is hard to prove from first principles because we need theory of ordinals, recursions and Hartogs' lemma, not because of its equivalence with axiom of choice.
\end{note}

\subsection{*Bourbaki-Witt theorem}

On one hand we have Zorn's lemma, which is a local (conditions on chains) to global (maximal element) principle, and on the other hand we have \nameref{thm:Knaster-Tarski}, a global fixed point theorem based on assumptions of the ambient space (completeness). The Bourbaki-Witt theorem is a ``midpoint'' between the two.

\begin{definition}[Chain-complete]\index{Chain complete}
  A poset \(X\) is \emph{chain-complete} if \(X \neq \emptyset\) and every non-empty chain has a supremum.
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Any complete poset.
  \item Any finite poset.
  \item Given a vector space \(V\), \(\{A \subseteq V: A \text{ is linearly independent}\}\).
  \end{enumerate}
\end{eg}

\begin{definition}[Inflationary]\index{inflationary}
  A function \(f: X \to X\) is \emph{inflationary} if \(f(x) \geq x\) for all \(x\).
\end{definition}

\begin{theorem}[Bourbaki-Witt]\index{Bourbaki-Witt theorem}
  Suppose \(X\) is chain-complete and \(f: X \to X\) inflationary. Then \(f\) has a fixed point.
\end{theorem}

Bourbaki-Witt follows immediately from Zorn's lemma: take maximal \(x\) and since \(f(x) \geq x\), we must have equality.

However, intriguingly, we can prove Bourbaki-Witt \emph{without} axiom of choice: injecting \(\gamma(X)\) into \(X\) by explicitly set \(x_{\alpha + 1} = f(x_\alpha)\) and \(x_\alpha = \sup\{x_\beta: \beta < \alpha\}\) for a non-zero limit \(\alpha\) and derive a contradiction. We circumvent the issue of choice by exhibit an explicit upper bound.

\begin{note}
  In chapter 2, we never used axiom of choice except in remark that well-ordering is equivalent to the absence of decreasing sequece, and that \(\omega_1\) does not have a countable supremum.
\end{note}

In fact, it is easy to deduce Zorn's lemma from Bourbaki-Witt (with axiom of choice) so we can view it as the ``choice-free version of Zorn's lemma''.

\section{Predicate logic}

We studied propositional logic in chapter 1 but it is not powerful enough to express objects outside of primitive propositions. In this chapter we will introduce predicate logic, which is more intricate but more powerful. Before that we will have an overview of the theory we will develop.

A mathematical \emph{structure} is a set with functions and relations defined on it. A function has an \emph{arity} associated to it, which is the number of arguments it take. For example, recall that a group is a set \(A\) equipped with functions \(m: A^2 \to A\) (arity \(2\)), and \(i: A \to A\) (arity \(1\)), and a constant \(e \in A\), which could be seen as a function of arity \(0\), such that
\begin{align*}
  & (\forall x, y \in A) (m(x, m(y, z)) = m(m(x, y), z)) \\
  & (\forall x \in A) (m(x, e) = x \land m(e, x) = x) \\
  & (\forall x \in A) (m(x, i(x)) = e \land m(i(x), x) = e)
\end{align*}

As another example, a poset is a structure with relation: it is a set \(A\) equipped with a predicate (i.e.\ relation) \((\leq) \subseteq A^2\) such that
\begin{align*}
  & (\forall x \in A) (x \leq x) \\
  & (\forall x, y, z \in A) ((x \leq y \land y \leq z) \implies (x \leq z)) \\
  & (\forall x, y \in A) ((x \leq y \land y \leq x) \implies (x = y))
\end{align*}

\begin{table}[ht]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    Propostional logic & Predicate logic & Example in groups \\ \hline
    language & language & group axioms \\ \hline
    valuation & structure & \(m, i, e\) \\ \hline
    model of \(S\) & same & structure in which each \(s \in S\) holds \\ \hline
    \(S \models t\) & same & group axioms \(\models m(e, e) = e\) \\ \hline
    \(S \yields t\) & same* & \\ \hline
  \end{tabular}
  \caption{Comparison of concepts in propositional and predicate logic}
\end{table}

The axioms and deduction rules in predicate logic is going to be more complicated. For example, it includes an axiom that says ``if \(p(x)\) holds for all \(x\) and \(t\) is an instance of \(t\) then \(p(t)\)''.

\subsection{Definitions}

\begin{definition}[Language]
  A \emph{language} \(L(\Omega, \Pi, \alpha)\) is the set of \emph{formulae}, defined by
  \begin{itemize}
  \item \emph{variables}: \(x_1, x_2, \dots\). We sometimes use \(x, y, \dots\),
  \item \emph{terms}: defined inductively by
    \begin{enumerate}
    \item each variable is an a term,
    \item if \(f \in \Omega, \alpha(f) = n\) and \(t_1, \dots, t_n\) are terms then \(ft_1, \dots t_n\) is a term. We usually write \(f(t_1, \dots, t_n)\).
    \end{enumerate}
    \begin{eg}
      In the language of groups, we have \(\Omega = (m, i, e)\), with arities \(2, 1, 0\) respectively. \(\Pi = \emptyset\).

      Some terms: \(x_1, m(x_1, x_1), e, m(e, e), m(x_1, i(x_1))\).
    \end{eg}
  \item \emph{atomic formulae}: consists of
    \begin{enumerate}
    \item \(\bot\),
    \item \((s = t)\) for any terms \(s, t\),
    \item \(\phi(t_1, \dots, t_n)\) for any \(\phi \in \Pi, \alpha(\phi) = n\) and any terms \(t_1, \dots, t_n\).
    \end{enumerate}
  \item \emph{formulae}: defined inductively by
    \begin{enumerate}
    \item each atomic formula is a formula,
    \item if \(p, q\) are formulae then so is \((p \implies q)\),
    \item if \(p\) is a formula, \(x\) is a variable, then \((\forall x) p\) is a formula,
      \begin{eg}\leavevmode
        \begin{enumerate}
        \item group:
          \begin{align*}
            & (\forall x) (m(x, x) = e), \\
            & (\forall x) (m(x, x) = e) \implies (\exists y)(m(y, y) = x).
          \end{align*}
        \item poset: \((\forall x) (x \leq x)\).
        \end{enumerate}
      \end{eg}
      \begin{note}\leavevmode
        \begin{enumerate}
        \item A formula is a string of symbols.
        \item Just as in chapter 1 we defined symbols such as \(\neg\), \(\land\) and \(lor\) in terms of \(\bot\), we write \((\exists x) p\) for \(\neg (\forall x) (\neg p)\).
        \end{enumerate}
      \end{note}
    \end{enumerate}
  \end{itemize}
\end{definition}

\begin{definition}[Closed]\index{closed}
  A term is \emph{closed} if it contains no variables.
\end{definition}

\begin{eg}
  \(e, m(e, e), m(e, m(e, e))\) are closed terms, but \(m(x, i(x))\) isn't.
\end{eg}

\begin{definition}[Bound \& free variable]\index{bound}\index{free}
  An occurrence of variable \(x\) in formula \(p\) is \emph{bound} if it is inside the brackets of a ``\(\forall x\)'' quantifier. Otherwise it is \emph{free}.
\end{definition}

\begin{eg}
  In \(m(x, x) = e \implies (\exists y) (m(y, y) = e)\), \(x\) is free and \(y\) is bounded.
\end{eg}

\begin{note}
  It is possible to have a variable that is both free and bound in a formula. For example,
  \[
    (m(x, x) = e) \implies (\forall x)(\forall y) (m(x, y) = m(y, x)).
  \]
  But promise to \emph{never} use it!
\end{note}

\begin{definition}[Sentence]\index{sentence}
  A \emph{sentence} is a formula without free variables.
\end{definition}

\begin{eg}
  \((\forall x) (m(x, e) = x)\).
\end{eg}

\begin{definition}[Substitution]\index{substitution}
  For a formula \(p\), a variable \(x\) and a term \(t\), the \emph{substitution} \(p[t/x]\) is obtained by replacing each free occurrence of \(x\) with \(e\).
\end{definition}

Do not worry too much about the word ``free'', it is there to prevent us from doing stupid things in stupid formula such as the bad example above where a variable is both free and bound. Just follow your common sense!

\begin{eg}
  If \(p\) is the statement \((\exists y) (m(y, y) = x)\) then \(p[t/x]\) is
  \[
    (\exists y) (m(y, y) = t).
  \]
\end{eg}

\subsection{Semantic entailment}

\begin{definition}[\(L\)-structure]\index{L-structre@\(L\)-structure}
  An \emph{\(L\)-structure} is a non-empty set \(A\) equipped with
  \begin{enumerate}
  \item for each \(f \in \Omega\) with \(\alpha(f) = n\), a function \(f_A: A^n \to A\),
  \item for each \(\phi \in \subset\) with \(\alpha(\phi) = n\), a relation \(\phi_A \in A^n\).
  \end{enumerate}
\end{definition}

See later for why ``non-empty''.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Suppose \(L\) is the language of groups, then an \(L\)-structure is a set \(A\) with functions \(m_A: A^2 \to A, i_A: A \to A, e_A \in A\). Note that \(A\) need not be a group.
  \item Suppose \(L\) is the language of posets, then an \(L\)-structure is a set \(A\) with a relation \((\leq_A) \in A^2\).
  \end{enumerate}
\end{eg}

We want to define the \emph{interpretation} \(p_A \in \{0, 1\}\) of a sentence \(p\) in structure \(A\). For example, \((\forall x) (m(x, x) = e)\) should be ``true in \(A\)'' if \(\forall a \in A, m_A(a, a) = e_A\). Informally this can be done by inserting ``\(\in A\)'' and subscripting \(A\), and saying it aloud.

\begin{definition}[Interpretation]\index{interpretation}
  For an \(L\)-structure \(A\), define \emph{interpretation} of \(A\) \(p_A \in \{0, 1\}\) for a sentence \(p\) recursively by
  \begin{enumerate}
  \item closed term: define \(t_A\) recursively by \((ft_1, \dots, f_n)_A = f_A(t_{1_A}, \dots, t_{n_A})\) for any \(f \in \Omega, \alpha(f) = n\) and closed terms \(t_1, \dots, t_n\).
    \begin{eg}
      \(m(e, i(e))_A = m_A(e_A, i_A(e_A))\). Note that \(e_A\) is already defined.
    \end{eg}
  \item atomic formulae: define \(p_A \in \{0, 1\}\) for \(p\) atomic by
    \begin{enumerate}
    \item \(\bot_A = 0\),
    \item \((s = t)_A = \begin{cases} 1 & \text{if } s_A = t_A \\ 0 & \text{otherwise} \end{cases}\) for closed terms \(s, t\).
    \item \(\phi(t_1, \dots, t_n) = \begin{cases} 1 & \text{if } (t_{1_A}, \dots, t_{n_A}) \in \phi_A \\ 0 & \text{otherwise} \end{cases}\) for each \(\phi \in \Pi, \alpha(\phi) = n\) and closed terms \(t_1, \dots, t_n\).
    \end{enumerate}
  \item sentence: \(p_A\) defined inductively by
    \begin{enumerate}
    \item \((p \implies q)_A = \begin{cases} 0 & \text{if } p_A = 1, q_A = 0 \\ 1 & \text{otherwise} \end{cases}\)
    \item \(((\forall x) p)_A = \begin{cases} 1 & \text{if } p[\overline a/x]_A = 1 \text{ for all } a \in A \\ 0 & \text{otherwise} \end{cases}\) where, for each \(a \in A\), add constant symbol \(\overline a\) to \(L\) obtaining \(L'\), and made an \(L'\)-structure by setting \(\overline a_A = a\).
    \end{enumerate}
  \end{enumerate}
\end{definition}

If \(p\) has free vaiables, we can define \(p_A \subseteq A^{\#\text{free variables of \(p\)}}\). For example, if \(p\) is the formula \((\exists y) (m(y, y) = x)\), then
\[
  p_A = \{a \in A: \exists b \in A \text{ with } m_A(b, b) = e\}.
\]



  





\printindex

\iffalse
logic is the interplay of syntax and semantics
set: stuff with sets, universe of sets

Contents

1: Propositional logic
2: Well-ordering and ordinals
3: Posets and Zorn's Lemma
4: Predicate logic
5: Set theory
6: Cardinals

Reading:
Johnstone, Notes on logic and set theory
van Dalen, Logic and structure
Hainal & Hamburger, Set theory
Forster, Logic, induction and sets
\fi

\end{document}
